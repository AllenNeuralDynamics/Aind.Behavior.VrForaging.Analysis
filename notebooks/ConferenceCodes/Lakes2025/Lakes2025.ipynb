{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib import patches as mpatches\n",
    "import sys\n",
    "sys.path.append('../../../src/')\n",
    "\n",
    "import os\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from aind_vr_foraging_analysis.utils.plotting import plotting_friction_experiment as f\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "pdf_path = r'Z:\\scratch\\vr-foraging\\sessions'\n",
    "base_path = r'Z:\\scratch\\vr-foraging\\data'\n",
    "\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "from statsmodels.formula.api import glm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Modelling libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "color1='#d95f02'\n",
    "color2='#1b9e77'\n",
    "color3='#7570b3'\n",
    "color4='#e7298a'\n",
    "odor_list_color = [color1, color2, color3]\n",
    "color_dict = {0: color1, 1: color2, 2: color3}\n",
    "color_dict_label = {'Ethyl Butyrate': color1, 'Alpha-pinene': color2, 'Amyl Acetate': color3, \n",
    "                    '2-Heptanone' : color2, 'Methyl Acetate': color1, 'Fenchone': color3, '2,3-Butanedione': color4,\n",
    "                    'Methyl Butyrate': color1, }\n",
    "\n",
    "# Define exponential function\n",
    "def exponential_func(x, a, b):\n",
    "    return a * np.exp(b * x)\n",
    "\n",
    "def format_func(value, tick_number):\n",
    "    return f\"{value:.0f}\"\n",
    "\n",
    "velocity_path = r'C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\experiments\\batch 4 - manipulating cost of travelling and global statistics\\results'\n",
    "data_path = r'../../../data/'\n",
    "results_path = r'C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\Conferences\\Lakes 2025\\figures'\n",
    "\n",
    "palette = {\n",
    "    'control': 'grey',  # Red\n",
    "    'friction_high': '#6a51a3',  # Purple\n",
    "    'friction_med': '#807dba',  # Lighter Purple\n",
    "    'friction_low': '#9e9ac8',  # Lightest Purple\n",
    "    'distance_extra_short': 'crimson',  # Blue\n",
    "    'distance_short': 'pink',  # Lighter Blue\n",
    "    'distance_extra_long': '#fd8d3c',  # Yellow\n",
    "    'distance_long': '#fdae6b'  # Lighter Yellow\n",
    "}\n",
    "\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99baf9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all():\n",
    "    # Recover and clean batch 4 dataset\n",
    "    # batch4 = pd.read_csv(data_path + 'batch_4.csv') # if you want the original dataset\n",
    "    batch4 = pd.read_csv(os.path.join(data_path, 'batch_4_fixed_interpatch.csv'))\n",
    "\n",
    "    # These mice are in the dataset but didn't perform the manipulation\n",
    "    batch4 = batch4[(batch4['mouse'] != 754573)&(batch4['mouse'] != 754572)&(batch4['mouse'] != 745300)&(batch4['mouse'] != 745306)&(batch4['mouse'] != 745307)]\n",
    "\n",
    "    batch4[\"session\"] = batch4[\"session\"].apply(lambda x: str(x).split('_')[-1])\n",
    "\n",
    "    ## Micr with weird behavior\n",
    "    batch4 = batch4.loc[(batch4.mouse != 754577)&(batch4.mouse != 754575)]\n",
    "\n",
    "    # Import data from batch3\n",
    "    batch3 = pd.read_csv(os.path.join(data_path,  'batch_3.csv'))\n",
    "    batch3 = batch3.loc[(batch3.mouse != 715866)]\n",
    "\n",
    "    # Merge both datasets\n",
    "    summary_df = pd.concat([batch3, batch4], ignore_index=True)\n",
    "\n",
    "    summary_df= summary_df.loc[~summary_df.patch_label.isin(['patch_delayed', 'patch_no_reward', 'patch_single', 'delayed', 'single', 'no_reward', 'PatchZB'])]\n",
    "\n",
    "    summary_df['patch_label'] = summary_df['patch_label'].replace({'Alpha pinene': '60','Alpha-pinene': '60', 'Methyl Butyrate': '90', 'Ethyl Butyrate': '90', 'Amyl Acetate': '0',  '2,3-Butanedione': 'slow', '2-Heptanone': 'slow',  'Methyl Acetate':'fast', 'Fenchone':'0'})\n",
    "    summary_df['experiment'] = summary_df['experiment'].replace({'base': 'control'})\n",
    "    \n",
    "    summary_df = summary_df.loc[(summary_df['patch_label'] == '90')|(summary_df['patch_label'] == '60')]\n",
    "    \n",
    "    return summary_df\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'site_number'  # Options: 'cumulative_rewards', 'trial', 'time'\n",
    "max_value = 30  # Maximum value for the x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48ef0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the summary_df to only keep patches they visit\n",
    "summary_df = summary_df.loc[((summary_df.site_number == 0) & (summary_df.is_choice == 1)) | (summary_df.site_number != 0)]\n",
    "summary_df = summary_df.loc[summary_df.engaged == 1]\n",
    "\n",
    "# Group by mouse, experiment, and patch_label to calculate the number of unique patches visited\n",
    "patch_df = summary_df.groupby(['mouse', 'experiment','session',  'patch_label']).agg({'patch_number': 'nunique'}).reset_index()\n",
    "\n",
    "# Merge the patch_df back with summary_df to calculate the number of patches attempted\n",
    "final_df = pd.merge(summary_df, patch_df, on=['mouse', 'session', 'experiment', 'patch_label'], how='left', suffixes=('', '_attempted'))\n",
    "\n",
    "# Group by mouse, site_number, experiment, and patch_label to calculate the number of patches visited and attempted\n",
    "final_df = final_df.groupby(['mouse', variable,  'session', 'experiment', 'patch_label']).agg({'patch_number': 'nunique', 'patch_number_attempted': 'mean', }).reset_index()\n",
    "\n",
    "# Calculate the fraction of patches visited\n",
    "final_df['fraction_visited'] = final_df['patch_number'] / final_df['patch_number_attempted']\n",
    "\n",
    "dictionary = {'0': color3, '60': color2, '90': color1}\n",
    "palette = {\n",
    "    '0': 'Purples',  # Amyl Acetate\n",
    "    '60': 'Greens',  # Alpha-pinene\n",
    "    '90': 'Oranges',  # Ethyl Butyrate\n",
    "}\n",
    "new_df = final_df.groupby(['mouse','experiment', 'session', variable, 'patch_label']).fraction_visited.mean().reset_index()\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "for ax, patch_label in zip(axes.flatten(), new_df.patch_label.unique()):\n",
    "    sns.lineplot(data=new_df.loc[(new_df.patch_label == patch_label)&(new_df.experiment == \"control\")&(new_df.site_number >0)], x=variable, y='fraction_visited', hue = 'mouse', ci=None, ax=ax, alpha = 0.1, legend=False, palette = palette[patch_label])\n",
    "    \n",
    "    sns.lineplot(data=new_df.loc[(new_df.patch_label == patch_label)&(new_df.experiment == \"control\")&(new_df.site_number >0)], x=variable, y='fraction_visited', ci=None, ax=ax, legend=False, color = dictionary[patch_label], linewidth=3)\n",
    "\n",
    "    ax.set_xlim(0, max_value)\n",
    "    ax.set_xlabel('Odor site number')\n",
    "    ax.set_ylabel('Fraction visited')\n",
    "    ax.set_xticks(ticks=[1,10,20,30], labels=['1', '10', '20', '30'], rotation=0, ha='center')\n",
    "    ax.set_yticks(ticks=[0,0.5,1], labels=['0', '0.5', '1'])\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_path, f'fraction_visited_vs_{variable}_hue_patch_label.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eca2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = final_df.groupby(['mouse','experiment', 'session', variable, 'patch_label']).fraction_visited.mean().reset_index()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), sharey=True)\n",
    "sns.lineplot(data=new_df.loc[(new_df.experiment == \"control\")&(new_df.site_number >0)], x=variable, y='fraction_visited', ci=None, ax=ax, hue='patch_label', legend=False, palette= dictionary, linewidth=3)\n",
    "ax.set_xlim(0, max_value)\n",
    "ax.set_xlabel('Odor site number')\n",
    "ax.set_ylabel('Fraction visited')\n",
    "plt.xticks(ticks=[1,10,20,30], labels=['1', '10', '20', '30'], rotation=0, ha='center')\n",
    "plt.yticks(ticks=[0,0.5,1], labels=['0', '0.5', '1'])\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_path, f'fraction_visited_vs_{variable}.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec680d",
   "metadata": {},
   "source": [
    "### Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1fcfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aind_vr_foraging_analysis.utils.parsing import data_access\n",
    "\n",
    "date_string = \"2025-8-5\" # YYYY-MM-DD\n",
    "mouse = '798279' # mouse ID\n",
    "\n",
    "# This section will look at all the session paths that fulfill the condition\n",
    "session_paths = data_access.find_sessions_relative_to_date(\n",
    "    mouse=mouse,\n",
    "    date_string=date_string,\n",
    "    when='on'\n",
    ")\n",
    "\n",
    "# Iterate over the session paths and load the data\n",
    "for session_path in session_paths:\n",
    "    print(f\"Loading {session_path.name}...\")\n",
    "    try:\n",
    "        all_epochs, stream_data, data = data_access.load_session(\n",
    "            session_path\n",
    "        )\n",
    "        odor_sites = all_epochs.loc[all_epochs['label'] == 'OdorSite']\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {session_path.name}: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969bea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_collection(\n",
    "    reward_sites: pd.DataFrame,\n",
    "    continuous_data: pd.DataFrame,\n",
    "    aligned: str = 'index',\n",
    "    cropped_to_length: str = 'window',\n",
    "    window: list = [-0.5, 2],\n",
    "    taken_col: str = \"filtered_velocity\",\n",
    "    continuous: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Crop the snippets of speed traces that are aligned to different epochs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reward_sites : pd.DataFrame\n",
    "        DataFrame containing the reward sites information (odor sites)\n",
    "    continuous_data : pd.DataFrame\n",
    "        DataFrame containing the continuous data (encoder, sniffing, etc)\n",
    "    mouse : str\n",
    "        Mouse name\n",
    "    session : str\n",
    "        Session name\n",
    "    aligned : str\n",
    "        Column name to align the snippets\n",
    "    window : tuple\n",
    "        Time window to crop the snippets\n",
    "    taken_col: string\n",
    "        name of the column that you want to segment the data from. Default is 'filtered_velocity'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trial_summary : pd.DataFrame\n",
    "        DataFrame containing the snippets of speed traces aligned to different epochs\n",
    "\n",
    "    \"\"\"\n",
    "    trial_summary = pd.DataFrame()\n",
    "    samples_per_second = np.around(np.mean(continuous_data.index.diff().dropna()), 3)\n",
    "    \n",
    "    # Iterate through reward sites and align the continuous data to whatever value was chosen. If aligned is used, it will align to any of the columns with time values.\n",
    "    # If align is empty, it will align to the index, which in the case of the standard reward sites is the start of the odor site.\n",
    "    for start_reward, row in reward_sites.iloc[:-1].iterrows():\n",
    "        if cropped_to_length == 'sniff':\n",
    "            # window[0] = -1\n",
    "            # window[1] = row['odor_duration']\n",
    "            window[0] = 0\n",
    "            window[1] = row['next_index'] - start_reward   \n",
    "        elif cropped_to_length == 'patch':    \n",
    "            window[0] = row['time_since_entry']\n",
    "            window[1] = row['exit_epoch']\n",
    "        elif cropped_to_length == 'epoch':\n",
    "            window[0] = 0\n",
    "            window[1] = row['duration_epoch']\n",
    "        elif cropped_to_length == 'choose':\n",
    "            window[0] = row[window[0]]\n",
    "            window[1] = row[window[1]]\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        trial_average = pd.DataFrame()\n",
    "        if aligned != 'index':\n",
    "            trial = continuous_data[(continuous_data.index >= row[aligned] + window[0]) & (continuous_data.index < row[aligned] + window[1])][taken_col]\n",
    "            trial.index -= row[aligned]\n",
    "            time_reference = row[aligned]\n",
    "        else:\n",
    "            trial = continuous_data.loc[\n",
    "                start_reward + window[0] : start_reward + window[1], taken_col\n",
    "            ]\n",
    "\n",
    "            trial.index -= start_reward\n",
    "            time_reference = start_reward\n",
    "        \n",
    "        if continuous == True:\n",
    "            # Assuming trial.values, window, and samples_per_second are defined\n",
    "            # Calculate the maximum number of intervals that can fit within the available data points\n",
    "            max_intervals = len(trial.values) * samples_per_second\n",
    "\n",
    "            # Calculate the actual stop value based on the maximum possible intervals\n",
    "            actual_stop = min(window[1], window[0] + max_intervals)\n",
    "\n",
    "            # Generate the time range with the adjusted stop value\n",
    "            times = np.arange(window[0], actual_stop, samples_per_second)\n",
    "            if len(times) != len(trial.values):\n",
    "                # print('Different timing than values, ', len(times), len(trial.values))\n",
    "                trial = trial.values[:len(times)]\n",
    "            else:\n",
    "                trial = trial.values\n",
    "            trial_average[\"times\"] = times\n",
    "\n",
    "        else:\n",
    "            trial_average[\"times\"] = trial.index     \n",
    "            trial = trial.values    \n",
    "             \n",
    "        \n",
    "        trial_average['time_reference'] = time_reference\n",
    "        \n",
    "        if len(trial) == len(trial_average[\"times\"]):\n",
    "            if \"filtered_velocity\" == taken_col:\n",
    "                trial_average[\"speed\"] = trial\n",
    "            else:\n",
    "                trial_average[taken_col] = trial\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        # Rewrites all the columns in the reward_sites to be able to segment the chosen traces in different values\n",
    "        for column in reward_sites.columns:\n",
    "            trial_average[column] = np.repeat(row[column], len(trial))\n",
    "        \n",
    "        trial_summary = pd.concat([trial_summary, trial_average], ignore_index=True)\n",
    "\n",
    "    return trial_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd936c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_with_velocity(\n",
    "    active_site: pd.DataFrame,\n",
    "    stream_data: pd.DataFrame,\n",
    "    save = False,\n",
    "    color_dict_label: dict = {\n",
    "        \"Ethyl Butyrate\": \"#d95f02\",\n",
    "        \"Alpha-pinene\": \"#1b9e77\",\n",
    "        \"Amyl Acetate\": \"#7570b3\",\n",
    "    },\n",
    "    with_velocity: bool = True,\n",
    "    barplots: bool = True,\n",
    "):\n",
    "    \n",
    "\n",
    "    # sort by odor label, then by original site for stability\n",
    "    df_sorted = active_site.sort_values([\"patch_label\", \"patch_number\"]).reset_index(drop=True)\n",
    "\n",
    "    # re-enumerate \"site\" but keep repetitions grouped\n",
    "    df_sorted[\"patch_number\"] = df_sorted.groupby([\"patch_label\", \"patch_number\"]).ngroup() + 1\n",
    "    active_site = df_sorted.copy()\n",
    "    \n",
    "    test_df = active_site.groupby('patch_number').agg({'time_since_entry': 'min', 'patch_onset': 'mean','exit_epoch' : 'max'})\n",
    "    test_df.reset_index(inplace=True)\n",
    "    test_df.fillna(15, inplace=True)   \n",
    "    \n",
    "    trial_summary = trial_collection(test_df, stream_data.encoder_data, aligned='patch_onset', cropped_to_length='patch')\n",
    "    n_patches = active_site.patch_number.nunique()\n",
    "    n_max_stops = active_site.site_number.max() + 1\n",
    "    fig, ax1 = plt.subplots(figsize=(15+ n_max_stops/2, n_patches/2))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    max_speed = np.quantile(trial_summary['speed'],0.99)\n",
    "    for index, row in active_site.iterrows():\n",
    "        if row['label'] == 'InterPatch':\n",
    "            color = '#b3b3b3'\n",
    "        elif row['label'] == 'InterSite':\n",
    "            color = '#808080'\n",
    "        elif row['label'] == 'PostPatch':\n",
    "            color = '#b3b3b3'\n",
    "            \n",
    "        if row['label'] == 'OdorSite':\n",
    "            if row['site_number'] == 0:\n",
    "                ax1.scatter(-20, row.patch_number, color=color_dict_label[row.patch_label], marker='s', s=60, edgecolor='black', linewidth=0.0)\n",
    "\n",
    "            if row[\"is_reward\"] == 1 and row[\"is_choice\"] == True:\n",
    "                color = \"steelblue\"\n",
    "            elif row[\"is_reward\"] == 0 and row[\"is_choice\"] == True:\n",
    "                color = \"pink\"\n",
    "            else:\n",
    "                color = 'yellow'\n",
    "                \n",
    "        if barplots:\n",
    "            ax1.barh(int(row['patch_number']), left=row.time_since_entry, height=0.85, width=row.duration_epoch, color=color,  linewidth=0.5)\n",
    "        \n",
    "        if with_velocity:\n",
    "            if row['time_since_entry'] <0:\n",
    "                current_trial = trial_summary[trial_summary['patch_number'] == row['patch_number']]\n",
    "\n",
    "                ax2.plot(current_trial['times'], (current_trial['speed']+10)*0.75+(max_speed*(row['patch_number']))+max_speed/1.8, color='black', linewidth=1.5, alpha=0.8)\n",
    "                ax2.set_ylim(0, max_speed*(active_site['patch_number'].max()+2))\n",
    "\n",
    "    ax1.set_xlabel(\"Time (s)\")\n",
    "    ax1.set_ylabel(\"Patch number\")\n",
    "    sns.despine()\n",
    "    ax1.set_ylim(-1, max(active_site.patch_number) + 1)\n",
    "    \n",
    "    if active_site.groupby('patch_number').time_since_entry.min().min() < -50:\n",
    "        time_left = -50\n",
    "    else:\n",
    "        time_left = active_site.groupby('patch_number').time_since_entry.min().min()\n",
    "    \n",
    "    if active_site.groupby('patch_number').time_since_entry.max().max() > 300:\n",
    "        time_right = 250\n",
    "    else:\n",
    "        time_right = active_site.groupby('patch_number').time_since_entry.max().max()\n",
    "      \n",
    "    ax1.set_xlim(time_left, time_right)\n",
    "    \n",
    "    # Create legend\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax1.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "    \n",
    "    if save:\n",
    "        save.savefig(fig)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac243b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "color1 = '#d95f02'\n",
    "color2 = '#1b9e77'\n",
    "color3 = '#7570b3'\n",
    "\n",
    "color_dict_label = {'InterSite': '#808080',\n",
    "'InterPatch': '#b3b3b3', 'PatchZ': '#d95f02',\n",
    "'PatchZA': '#d95f02', 'PatchZB': '#d95f02', \n",
    "'PatchB': '#d95f02','PatchA': '#1b9e77',\n",
    "'PatchC': '#7570b3',\n",
    "'Alpha-pinene': '#1b9e77', \n",
    "'Methyl Butyrate': '#7570b3', \n",
    "'Amyl Acetate': '#d95f02', \n",
    "'Fenchone': '#7570b3', \n",
    "'Dipropyl sulfide': '#7570b3',\n",
    "'Dypropil sulfide': '#7570b3',\n",
    "'Hexanal': '#1b9e77',\n",
    "'Pentyl acetate': '#d95f02',\n",
    "'S': color1,\n",
    "'D': color2,\n",
    "'N': color3,   \n",
    "'Do': color1,\n",
    "'odor_0': color3,\n",
    "'odor_60': color2,\n",
    "'odor_90': color1,\n",
    "'A': color1,\n",
    "'B': color2,\n",
    "'C': color3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs.patch_label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4f2c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs = all_epochs.loc[all_epochs.patch_number < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dfe852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf as pdf\n",
    "with pdf.PdfPages(os.path.join(results_path, f'{mouse}_raster.pdf')) as save:\n",
    "    raster_with_velocity(all_epochs, stream_data, color_dict_label=color_dict_label,  with_velocity=False, save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d00cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf as pdf\n",
    "with pdf.PdfPages(os.path.join(results_path, f'{mouse}_raster_velocity.pdf')) as save:\n",
    "    raster_with_velocity(all_epochs, stream_data, color_dict_label=color_dict_label,  with_velocity=True, save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d79e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = r\"C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\manuscript\\results\\figures\"\n",
    "mice = [\"mouse1\", \"mouse2\", \"mouse3\"]  # replace with your mouse names\n",
    "file_patterns = [\n",
    "    \"velocity_last_visit_stop_{}.pdf\",\n",
    "    \"velocity_length_bin_{}.pdf\",\n",
    "    \"velocity_last_visit_choice{}.pdf\"\n",
    "]\n",
    "\n",
    "\n",
    "mice = ['754570','754579','754567','754580','754559','754560','754577','754566','754570','754571','754574','754575', '754582','745302','745305','745301', '789911', '789913', '789919', '789918', '789908', '788641']\n",
    "with open(\"index.html\", \"w\") as f:\n",
    "    f.write(\"<html><body><h1>VR Foraging PDFs</h1><ul>\\n\")\n",
    "    for mouse in mice:\n",
    "        for pattern in file_patterns:\n",
    "            filename = pattern.format(mouse)\n",
    "            full_path = os.path.join(folder, filename).replace(\"\\\\\", \"/\")\n",
    "            url = \"file:///\" + full_path.replace(\" \", \"%20\")\n",
    "            f.write(f'<li><a href=\"{url}\" target=\"_blank\">{filename}</a></li>\\n')\n",
    "    f.write(\"</ul></body></html>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95cc3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4c6bb7a",
   "metadata": {},
   "source": [
    "## Different model plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8029a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(r\"C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\manuscript\\data\\simulation_data_df.csv\")\n",
    "# all_data = pd.read_csv(r\"C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\manuscript\\data\\simulation_data_separate_odors.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b259be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.rename(columns={'rewards_in_patch': 'cumulative_rewards',\n",
    "                              'time_in_patch':'site_number',\n",
    "                              'failures_in_patch': 'cumulative_failures',\n",
    "                              'patch_id': 'patch_label',\n",
    "                              'patch_entry_time': 'patch_number',\n",
    "                              'prob_reward': 'reward_probability',\n",
    "                              'simulation':'session'}, inplace=True)\n",
    "\n",
    "all_data['patch_number'].interpolate(method='linear', inplace=True)\n",
    "all_data['patch_number'] = all_data.groupby('session')['patch_number'].apply(\n",
    "    lambda x: x.ne(x.shift()).cumsum() - 1  # Detect changes and assign numbers\n",
    ").reset_index(drop=True)\n",
    "\n",
    "all_data['shift_is_choice'] = np.where(all_data['patch_label'] == -1, 0, 1) # Use the interpatch to recover is_choice\n",
    "all_data['is_choice'] = all_data['shift_is_choice'].shift(-1)\n",
    "all_data  = all_data.loc[all_data['patch_label'] != -1]\n",
    "all_data['is_choice'] = all_data['is_choice'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f866e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique mice\n",
    "max_number = 12 # range\n",
    "step = 2 # bin size\n",
    "full_x = np.arange(0, max_number + 1)  # Cumulative Rewards: 0 to 11\n",
    "full_y = np.arange(0, max_number + 1)  \n",
    "\n",
    "mice = all_data['strategy'].unique()\n",
    "n_mice = len(mice)\n",
    "variable = 'leave'\n",
    "vmax=0.6\n",
    "# Grid size (adjust as needed)\n",
    "cols = 4  # Number of columns in the grid\n",
    "rows = -(-n_mice // cols)  # ceiling division\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(3.5 * cols, 3.25 * rows), constrained_layout=True, sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, mouse in enumerate(mice):\n",
    "    ax = axes[i]\n",
    "    mouse_df = all_data[all_data['strategy'] == mouse]\n",
    "\n",
    "    # Count number of samples per bin\n",
    "    counts = mouse_df.groupby(['cumulative_rewards', 'consecutive_failures']).is_choice.count().unstack()\n",
    "\n",
    "    # Compute mean (probability) per bin\n",
    "    probs = mouse_df.groupby(['cumulative_rewards', 'consecutive_failures']).is_choice.mean().unstack()\n",
    "\n",
    "    # # Mask out bins with fewer than 5 samples\n",
    "    # probs[counts < 5] = np.nan\n",
    "\n",
    "    if variable == 'stop':\n",
    "        plot = probs\n",
    "        title = 'Probability of stopping'\n",
    "    else:\n",
    "        plot = 1 - probs\n",
    "        title = 'Probability of leaving'\n",
    "    plot = plot.astype(float)\n",
    "    plot = plot.fillna(np.nan)  # or use .fillna(0) if you prefer\n",
    "        \n",
    "    last_hm = sns.heatmap(plot, ax=ax, cmap='YlGnBu', cbar=False, vmax=vmax)\n",
    "    ax.invert_yaxis()\n",
    "    # ax.set_ylabel('Cumulative Rewards')\n",
    "    # ax.set_xlabel('Consecutive Failures')\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, ha='right')\n",
    "    ax.set_xticklabels(ax.get_xticks().astype(int))\n",
    "    ax.set_yticklabels(ax.get_yticks().astype(int))\n",
    "    \n",
    "    # Set ticks to be centered in the square\n",
    "    ax.set_yticks(np.arange(0, max_number, step) + 0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(0, max_number, step) + 0.5, minor=False)\n",
    "    ax.set_xticklabels([str(x) for x in np.arange(0, max_number, step)])\n",
    "    ax.set_yticklabels([str(y) for y in np.arange(0, max_number, step)])\n",
    "    ax.tick_params(axis='x', labelbottom=True)\n",
    "    ax.tick_params(axis='y')\n",
    "    ax.tick_params(labelbottom=True, labelleft=True)\n",
    "\n",
    "    ax.set_xlim(0, max_number-1)\n",
    "    ax.set_ylim(1, max_number-1)\n",
    "    ax.set_title(f'Mouse {mouse}')\n",
    "    ax.set_xlabel('Consecutive Failures')\n",
    "    ax.set_ylabel('Cumulative Rewards')\n",
    "# Hide unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "cbar = fig.colorbar(last_hm.collections[0], ax=axes[:n_mice], orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label(title)\n",
    "# plt.savefig(os.path.join(results_path, f'model_grid_strategy_x_consecfailures_y_cumrewards_hue_{variable}_.pdf'), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aind.Behavior.VrForaging.Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
