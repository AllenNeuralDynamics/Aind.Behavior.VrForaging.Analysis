{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../src/')\n",
    "\n",
    "import os\n",
    "from typing import Dict\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "import csv \n",
    "import glob\n",
    "\n",
    "from aind_vr_foraging_analysis import utils\n",
    "from aind_vr_foraging_analysis.utils import parse, processing, plotting_utils as plotting, AddExtraColumns\n",
    "import datetime\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "colors = sns.color_palette()\n",
    "odor_list_color = [colors[8], colors[0], colors[2], colors[4]]\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import find_peaks\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to identify peaks and troughs\n",
    "#neds to be modified to filter peaks when signal is bad\n",
    "def identify_peaks_and_troughs(data, width_peaks=5, prominence_peaks=0.1, width_troughs=3, prominence_troughs=0.1):\n",
    "    data = data.dropna()\n",
    "    data = data[~data.index.duplicated(keep='first')]\n",
    "    data = data.sort_index()\n",
    "    data_values = data.values.squeeze()\n",
    "    peaks, _ = find_peaks(data_values, width=width_peaks, prominence=prominence_peaks)\n",
    "    troughs, _ = find_peaks(-data_values, width=width_troughs, prominence=prominence_troughs)\n",
    "    troughs = troughs[troughs > peaks[0]]\n",
    "    peak_times = data.index[peaks]\n",
    "    trough_times = data.index[troughs]\n",
    "    return peak_times, trough_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to align sniff peaks with rewards\n",
    "def align_sniff_peaks_with_rewards(stream_data, reward_sites, width_peaks=5, prominence_peaks=0.1, width_troughs=3, prominence_troughs=0.1):\n",
    "    sniff_aligned = reward_sites.copy()\n",
    "    peak_times, trough_times = identify_peaks_and_troughs(stream_data.breathing, width_peaks, prominence_peaks, width_troughs, prominence_troughs)\n",
    "    first_peaks = [np.searchsorted(peak_times, start_time) for start_time in sniff_aligned.index]\n",
    "    first_sniff_peak_start_time = [peak_times[fp] for fp in first_peaks]\n",
    "    sniff_aligned['first_sniff_peak'] = first_sniff_peak_start_time\n",
    "    sniff_aligned = sniff_aligned.set_index('first_sniff_peak')\n",
    "    sniff_aligned.index.name = 'times'\n",
    "    return sniff_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing session 717716_20240711T104507: 'odor_label'\n",
      "Error processing session 717716_20240712T092200: \"None of ['Seconds'] are in the columns\"\n",
      "                    session odor_label  odor_site  peak_count  peak_frequency  \\\n",
      "0    717716_20240710T110945     ODOR_B        0.0          22        6.929186   \n",
      "1    717716_20240710T110945       NULL        1.0          37        1.503392   \n",
      "2    717716_20240710T110945       NULL        2.0          32        1.300231   \n",
      "3    717716_20240710T110945       NULL        3.0          50        2.031611   \n",
      "4    717716_20240712T093131       NULL        0.0          41        0.291431   \n",
      "..                      ...        ...        ...         ...             ...   \n",
      "859  717716_20240803T105420     ODOR_C       90.0          12        7.782020   \n",
      "860  717716_20240803T105420     ODOR_C       94.0          13        8.430522   \n",
      "861  717716_20240803T105420     ODOR_C       97.0          10        6.485017   \n",
      "862  717716_20240803T105420     ODOR_C      102.0          10        6.485017   \n",
      "863  717716_20240803T105420     ODOR_C      106.0          10        6.485017   \n",
      "\n",
      "     epoch_duration  peak_count_after_1s  \n",
      "0          3.174976                    7  \n",
      "1         24.611008                    5  \n",
      "2         24.611008                    4  \n",
      "3         24.611008                    6  \n",
      "4        140.684992                    9  \n",
      "..              ...                  ...  \n",
      "859        1.542016                    8  \n",
      "860        1.542016                    8  \n",
      "861        1.542016                    6  \n",
      "862        1.542016                    6  \n",
      "863        1.542016                    6  \n",
      "\n",
      "[864 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the path to the mouse folder\n",
    "mouse_folder_path = Path(f'/Volumes/aind/scratch/vr-foraging/data/{mouse}')\n",
    "\n",
    "# Function to process a single session and return peaks_df\n",
    "def process_session(session_path):\n",
    "    # Extract mouse_id from the first 6 numbers in the file name\n",
    "    mouse = session_path.name[:6]\n",
    "    # Extract session from the first 8 numbers after mouse_id\n",
    "    session = session_path.name[6:14]\n",
    "    try:\n",
    "\n",
    "        data = parse.load_session_data(session_path)\n",
    "        reward_sites, active_site, config = parse.parse_dataframe(data)\n",
    "        reward_sites = AddExtraColumns(reward_sites, active_site, run_on_init=True).reward_sites\n",
    "        active_site = AddExtraColumns(reward_sites, active_site, run_on_init=False).add_time_previous_intersite_interpatch()\n",
    "        color_dict_label = {}\n",
    "        dict_odor = {}\n",
    "        list_patches = parse.TaskSchemaProperties(data).patches\n",
    "        for i, patches in enumerate(list_patches):\n",
    "            color_dict_label[patches['label']] = odor_list_color[i]\n",
    "            dict_odor[i] = patches['label']\n",
    "        stream_data = parse.ContinuousData(data)\n",
    "        encoder_data = stream_data.encoder_data\n",
    "\n",
    "        active_site['next_intersite'] = active_site.index.to_series().shift(-1)\n",
    "        reward_sites = active_site.loc[active_site['label'] == 'RewardSite']\n",
    "        reward_sites['time_in_odor_site'] = reward_sites.next_intersite - reward_sites.index\n",
    "        plot_df = reward_sites[['time_in_odor_site', 'odor_label', 'active_patch']]\n",
    "        label_dict = {**{\n",
    "            \"InterSite\": '#808080',\n",
    "            \"InterPatch\": '#b3b3b3'}, **color_dict_label}\n",
    "        sniff_aligned = align_sniff_peaks_with_rewards(stream_data, reward_sites)\n",
    "        trial_summary_breathing = plotting.trial_collection(\n",
    "            sniff_aligned[['has_choice', 'visit_number', 'odor_label', 'odor_sites', 'time_in_odor_site']], \n",
    "            stream_data.breathing, \n",
    "            mouse, \n",
    "            session, \n",
    "            window=(-2, 8), \n",
    "            taken_col='data'\n",
    "        )\n",
    "        \n",
    "        peaks_data = []\n",
    "        for odor_label in trial_summary_breathing['odor_label'].unique():\n",
    "            odor_df = trial_summary_breathing[trial_summary_breathing['odor_label'] == odor_label]\n",
    "            for site in odor_df['odor_sites'].unique():\n",
    "                site_df = odor_df[odor_df['odor_sites'] == site]\n",
    "                signal = site_df.set_index('times')['data']\n",
    "                odor_end_time = odor_df['time_in_odor_site'].unique()[0]\n",
    "                x_start = 0\n",
    "                x_end = odor_end_time\n",
    "                filtered_signal = signal[(signal.index >= x_start) & (signal.index <= x_end)]\n",
    "                if filtered_signal.empty:\n",
    "                    continue\n",
    "                peak_times, _ = find_peaks(filtered_signal, width=5, prominence=0.1)\n",
    "                if len(peak_times) > 0:\n",
    "                    peak_times_indices = filtered_signal.index[peak_times]\n",
    "                    peak_count = len(peak_times_indices)\n",
    "                    epoch_duration = x_end - x_start\n",
    "                    peak_frequency = peak_count / epoch_duration if epoch_duration > 0 else 0\n",
    "                    peaks_data.append({\n",
    "                        'session': session_path.name,\n",
    "                        'odor_label': odor_label, \n",
    "                        'odor_site': site, \n",
    "                        'peak_count': peak_count,\n",
    "                        'peak_frequency': peak_frequency,\n",
    "                        'epoch_duration': epoch_duration\n",
    "                    })\n",
    "                    peak_count_after_1s = sum(peak <= 1 for peak in peak_times_indices)\n",
    "                    peaks_data[-1]['peak_count_after_1s'] = peak_count_after_1s\n",
    "\n",
    "        return pd.DataFrame(peaks_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_path.name}: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of error\n",
    "\n",
    "# Iterate through all sessions and aggregate results\n",
    "all_peaks_data = []\n",
    "for session_dir in os.listdir(mouse_folder_path):\n",
    "    session_path = mouse_folder_path / session_dir\n",
    "    if session_path.is_dir():\n",
    "        session_peaks_df = process_session(session_path)\n",
    "        if not session_peaks_df.empty:\n",
    "            all_peaks_data.append(session_peaks_df)\n",
    "\n",
    "# concatenate all session data into a single DataFrame\n",
    "if all_peaks_data:\n",
    "    summary_peaks_df = pd.concat(all_peaks_data, ignore_index=True)\n",
    "else:\n",
    "    summary_peaks_df = pd.DataFrame()  # Handle the case where no data was processed\n",
    "\n",
    "# Print the summary DataFrame\n",
    "print(summary_peaks_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save df to csv in /Users/nehal.ajmal/Documents/aindproject/results\n",
    "summary_peaks_df.to_csv(f'/Users/nehal.ajmal/Documents/aindproject/results/{mouse}_peaks_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odor_label\n",
      "NULL      7.217949\n",
      "ODOR_A    8.192771\n",
      "ODOR_B    7.166667\n",
      "ODOR_C    7.055556\n",
      "Name: peak_count_after_1s, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#average peak count after 1s for each odor label\n",
    "average_peak_count_after_1s = summary_peaks_df.groupby('odor_label')['peak_count_after_1s'].mean()\n",
    "print(average_peak_count_after_1s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vr_foraging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
