{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make velocity traces for every session\n",
    "import sys\n",
    "sys.path.append('../../../src/')\n",
    "\n",
    "import os\n",
    "from typing import Dict\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "import csv \n",
    "\n",
    "from aind_vr_foraging_analysis import utils\n",
    "from aind_vr_foraging_analysis.utils import parse, processing, plotting_utils as plotting, AddExtraColumns\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.signal import find_peaks, butter, lfilter\n",
    "\n",
    "\n",
    "colors = sns.color_palette()\n",
    "odor_list_color = [colors[8], colors[0], colors[2], colors[4]]\n",
    "\n",
    "base_path = r'/Volumes/aind/scratch/vr-foraging/data'\n",
    "foraging_figures = r'/Users/nehal.ajmal/Documents/aindproject/analysis_files'\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "mouse_id = '745306'\n",
    "color_dict_label = {}\n",
    "label_dict = {\"InterSite\": '#808080', \"InterPatch\": '#b3b3b3'}\n",
    "\n",
    "# Define paths\n",
    "base_output_dir = '/Users/nehal.ajmal/Documents/aindproject/traces' \n",
    "\n",
    "# Create a subfolder for the mouse if it doesn't exist\n",
    "mouse_output_dir = os.path.join(base_output_dir, mouse_id)\n",
    "os.makedirs(mouse_output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify peaks and troughs\n",
    "#neds to be modified to filter peaks when signal is bad\n",
    "def identify_peaks_and_troughs(data, width_peaks=5, prominence_peaks=0.1, width_troughs=3, prominence_troughs=0.1):\n",
    "    data = data.dropna()\n",
    "    data = data[~data.index.duplicated(keep='first')]\n",
    "    data = data.sort_index()\n",
    "    data_values = data.values.squeeze()\n",
    "    peaks, _ = find_peaks(data_values, width=width_peaks, prominence=prominence_peaks)\n",
    "    troughs, _ = find_peaks(-data_values, width=width_troughs, prominence=prominence_troughs)\n",
    "    troughs = troughs[troughs > peaks[0]]\n",
    "    peak_times = data.index[peaks]\n",
    "    trough_times = data.index[troughs]\n",
    "    return peak_times, trough_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to align sniff peaks with rewards\n",
    "def align_sniff_peaks_with_rewards(stream_data, reward_sites, width_peaks=5, prominence_peaks=0.1, width_troughs=3, prominence_troughs=0.1):\n",
    "    sniff_aligned = reward_sites.copy()\n",
    "    peak_times, trough_times = identify_peaks_and_troughs(stream_data.breathing, width_peaks, prominence_peaks, width_troughs, prominence_troughs)\n",
    "    first_peaks = [np.searchsorted(peak_times, start_time) for start_time in sniff_aligned.index]\n",
    "    first_sniff_peak_start_time = [peak_times[fp] for fp in first_peaks]\n",
    "    sniff_aligned['first_sniff_peak'] = first_sniff_peak_start_time\n",
    "    sniff_aligned = sniff_aligned.set_index('first_sniff_peak')\n",
    "    sniff_aligned.index.name = 'times'\n",
    "    return sniff_aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # function to process each session\n",
    "# def process_session(session_path):\n",
    "#     session_id = session_path.split('/')[-1]\n",
    "#     print(f\"Processing session: {session_id}\")\n",
    "\n",
    "#     try:\n",
    "#         # Load data\n",
    "#         data = parse.load_session_data(session_path)\n",
    "#         reward_sites, active_site, config = parse.parse_dataframe(data)\n",
    "#         reward_sites = AddExtraColumns(reward_sites, active_site, run_on_init=True).reward_sites\n",
    "#         active_site = AddExtraColumns(reward_sites, active_site, run_on_init=False).add_time_previous_intersite_interpatch()\n",
    "#         active_site['next_intersite'] = active_site.index.to_series().shift(-1)\n",
    "#         reward_sites = active_site.loc[active_site['label']=='RewardSite']\n",
    "#         reward_sites['time_in_odor_site'] = reward_sites.next_intersite - reward_sites.index\n",
    "#         list_patches = parse.TaskSchemaProperties(data).patches\n",
    "#         for i, patches in enumerate(list_patches):\n",
    "#             color_dict_label[patches['label']] = odor_list_color[i]\n",
    "\n",
    "#         # Load the encoder data\n",
    "#         stream_data = parse.ContinuousData(data)\n",
    "#         encoder_data = stream_data.encoder_data\n",
    "\n",
    "#         # Align sniff peaks with rewards\n",
    "#         sniff_aligned = align_sniff_peaks_with_rewards(stream_data, reward_sites)\n",
    "\n",
    "#         # Plotting velocity traces\n",
    "#         trial_summary_running = plotting.trial_collection(reward_sites[['visit_number', 'odor_label', 'odor_sites']], encoder_data, mouse_id, session_id, window=(-2, 4))\n",
    "#         max_range = max(trial_summary_running.speed.values)\n",
    "#         y_min = 0 - 2\n",
    "#         y_max = max_range + 8\n",
    "#         plotting.velocity_traces_odor_entry(trial_summary_running, window=(-0.5, 0.5), y_lims=(y_min, y_max), color_dict_label=color_dict_label,\n",
    "    #                                         cmap='magma', mean=True, save=False, n_sites=5, mouse=mouse_id, session=session_id)\n",
    "\n",
    "    #     # Plotting breathing traces\n",
    "    #     trial_summary_breathing = plotting.trial_collection(sniff_aligned[['has_choice', 'visit_number', 'odor_label', 'odor_sites', 'time_in_odor_site']], stream_data.breathing, mouse_id, session_id, window=(-2, 8), taken_col='data')\n",
    "    #     y_max = trial_summary_breathing.data.max()\n",
    "    #     y_min = trial_summary_breathing.data.min()\n",
    "    #     plotting.velocity_traces_odor_entry(trial_summary_breathing, y_lims=(y_min, y_max), window=(-0.5, 0.5),\n",
    "    #                                         color_dict_label=color_dict_label, cmap='magma',\n",
    "    #                                         mean=True, save=False, n_sites=5, y='data', mouse=mouse_id, session=session_id, y_label='Amplitude (a.u.)')\n",
    "\n",
    "    # except Exception as e:\n",
    "        # print(f\"Error processing session {session_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save concatenated dfs to csv to analyze later\n",
    "all_trial_summary_running = pd.DataFrame()\n",
    "all_trial_summary_breathing = pd.DataFrame()\n",
    "\n",
    "# Function to process each session\n",
    "def process_session(session_path):\n",
    "    session_id = session_path.split('/')[-1]\n",
    "    print(f\"Processing session: {session_id}\")\n",
    "\n",
    "    try:\n",
    "        # Load data\n",
    "        data = parse.load_session_data(session_path)\n",
    "        reward_sites, active_site, config = parse.parse_dataframe(data)\n",
    "        reward_sites = AddExtraColumns(reward_sites, active_site, run_on_init=True).reward_sites\n",
    "        active_site = AddExtraColumns(reward_sites, active_site, run_on_init=False).add_time_previous_intersite_interpatch()\n",
    "        active_site['next_intersite'] = active_site.index.to_series().shift(-1)\n",
    "        reward_sites = active_site.loc[active_site['label']=='RewardSite']\n",
    "        reward_sites['time_in_odor_site'] = reward_sites.next_intersite - reward_sites.index\n",
    "        list_patches = parse.TaskSchemaProperties(data).patches\n",
    "        for i, patches in enumerate(list_patches):\n",
    "            color_dict_label[patches['label']] = odor_list_color[i]\n",
    "\n",
    "        # Load the encoder data\n",
    "        stream_data = parse.ContinuousData(data)\n",
    "        encoder_data = stream_data.encoder_data\n",
    "\n",
    "        # Align sniff peaks with rewards\n",
    "        sniff_aligned = align_sniff_peaks_with_rewards(stream_data, reward_sites)\n",
    "\n",
    "        # Plotting velocity traces\n",
    "        trial_summary_running = plotting.trial_collection(\n",
    "            reward_sites[['visit_number', 'odor_label', 'odor_sites']], \n",
    "            encoder_data, mouse_id, session_id, window=(-2, 4)\n",
    "        )\n",
    "        \n",
    "        # Append to global DataFrame\n",
    "        global all_trial_summary_running\n",
    "        all_trial_summary_running = pd.concat([all_trial_summary_running, trial_summary_running])\n",
    "\n",
    "        # Plotting breathing traces\n",
    "        trial_summary_breathing = plotting.trial_collection(\n",
    "            sniff_aligned[['has_choice', 'visit_number', 'odor_label', 'odor_sites', 'time_in_odor_site']], \n",
    "            stream_data.breathing, mouse_id, session_id, window=(-2, 8), taken_col='data'\n",
    "        )\n",
    "        \n",
    "        # Append to global DataFrame\n",
    "        global all_trial_summary_breathing\n",
    "        all_trial_summary_breathing = pd.concat([all_trial_summary_breathing, trial_summary_breathing])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_sessions_path = os.path.join(base_path, mouse_id)\n",
    "for session_folder in os.listdir(mouse_sessions_path):\n",
    "    session_path = os.path.join(mouse_sessions_path, session_folder)\n",
    "    if os.path.isdir(session_path):\n",
    "        process_session(session_path)\n",
    "\n",
    "plt.show() \n",
    "\n",
    "# Save the aggregated DataFrames to files\n",
    "save_dir = os.path.join(base_output_dir, mouse_id)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "all_trial_summary_breathing.to_csv(os.path.join(save_dir, f'trial_summary_breathing_{mouse_id}.csv'), index=False)\n",
    "all_trial_summary_running.to_csv(os.path.join(save_dir, f'trial_summary_running_{mouse_id}.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vr_foraging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
