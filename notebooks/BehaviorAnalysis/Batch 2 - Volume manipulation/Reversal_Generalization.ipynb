{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../src/')\n",
    "\n",
    "import os\n",
    "\n",
    "from aind_vr_foraging_analysis.utils import parse, processing, plotting_utils as plotting, AddExtraColumns\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "pdf_path = r'Z:\\scratch\\vr-foraging\\sessions'\n",
    "base_path = r'Z:\\scratch\\vr-foraging\\data'\n",
    "data_path = r'../../../data/'\n",
    "\n",
    "color1='#d95f02'\n",
    "color2='#1b9e77'\n",
    "color3='#7570b3'\n",
    "color4='#e7298a'\n",
    "odor_list_color = [color1, color2, color3]\n",
    "color_dict = {0: color1, 1: color2, 2: color3}\n",
    "color_dict_label = {'Ethyl Butyrate': color1, 'Alpha-pinene': color2, 'Amyl Acetate': color3, \n",
    "                    '2-Heptanone' : color2, 'Methyl Acetate': color1, 'Fenchone': color3, '2,3-Butanedione': color4,\n",
    "                    'Methyl Butyrate': color1}\n",
    "# color_dict_label = {'Ethyl Butyrate': '#d95f02', 'Alpha-pinene': '#1b9e77', 'Amyl Acetate': '#7570b3', \n",
    "#                     '2-Heptanone' : '#1b9e77', 'Methyl Acetate': '#d95f02', 'Fenchone': '#7570b3', '2,3-Butanedione': '#e7298a'}\n",
    "dict_odor = {}\n",
    "rate = -0.12\n",
    "offset = 0.6\n",
    "dict_odor['Ethyl Butyrate'] = {'rate':rate, 'offset':offset, 'color': '#d95f02'}\n",
    "dict_odor['Methyl Butyrate'] = {'rate':rate, 'offset':0.9, 'color': '#d95f02'}\n",
    "dict_odor['Alpha-pinene'] = {'rate':rate, 'offset':offset, 'color': '#1b9e77'}\n",
    "dict_odor['Amyl Acetate'] = {'rate':rate, 'offset':offset, 'color': '#7570b3'}\n",
    "dict_odor['Methyl Acetate'] = {'rate':rate, 'offset':offset, 'color': color1}\n",
    "dict_odor['2,3-Butanedione'] = {'rate':rate, 'offset':offset, 'color': color4}\n",
    "dict_odor['Fenchone'] = {'rate':rate, 'offset':offset, 'color': '#7570b3'}\n",
    "dict_odor['2-Heptanone'] = {'rate':rate, 'offset':offset, 'color': '#7570b3'}\n",
    "\n",
    "# Define exponential function\n",
    "def exponential_func(x, a, b):\n",
    "    return a * np.exp(b * x)\n",
    "\n",
    "def format_func(value, tick_number):\n",
    "    return f\"{value:.0f}\"\n",
    "\n",
    "results_path = r'C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\experiments\\batch 4 - manipulating cost of travelling and global statistics\\results'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reversal experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.date.today()\n",
    "date_string = \"1/21/2024\"\n",
    "date = datetime.datetime.strptime(date_string, \"%m/%d/%Y\").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame()\n",
    "all_epochs = pd.DataFrame()\n",
    "cum_trial_summary = pd.DataFrame()\n",
    "\n",
    "for mouse in ['699894','694569', '690164']:\n",
    "    session_n = 0\n",
    "    previous_experiment = 0\n",
    "    control_experiment = 0\n",
    "    directory = os.path.join(base_path, mouse)\n",
    "    files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "    sorted_files = sorted(files, key=lambda x: datetime.datetime.strptime(x[-15:-7], \"%Y%m%d\").date(), reverse=False)\n",
    "    \n",
    "    # All this segment is to find the correct session without having the specific path\n",
    "    for file_name in sorted_files:\n",
    "\n",
    "        print(mouse, file_name)\n",
    "        # Find specific session sorted by date\n",
    "        session = file_name[-15:-7]\n",
    "        if datetime.datetime.strptime(session, \"%Y%m%d\").date() < date:\n",
    "            continue\n",
    "            \n",
    "        # Recover data streams\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session_path = Path(session_path)\n",
    "        try:\n",
    "            data = parse.load_session_data(session_path)\n",
    "        except:\n",
    "            print('Error loading data', file_name)\n",
    "\n",
    "        # Parse data\n",
    "        try:\n",
    "            if 'environmentStatistics' in data['config'].streams.TaskLogic.data:\n",
    "                print(data['config'].streams.TaskLogic.data['environmentStatistics']['patches'][0]['patchRewardFunction'])\n",
    "                print(data['config'].streams.TaskLogic.data['environmentStatistics']['patches'][1]['patchRewardFunction'])\n",
    "                print(data['config'].streams.TaskLogic.data['environmentStatistics']['patches'][2]['patchRewardFunction'])\n",
    "            else:\n",
    "                print(data['config'].streams.TaskLogic.data['environment_statistics']['patches'][0]['reward_specification']['reward_function'])\n",
    "                print(data['config'].streams.TaskLogic.data['environment_statistics']['patches'][1]['reward_specification']['reward_function'])\n",
    "                print(data['config'].streams.TaskLogic.data['environment_statistics']['patches'][2]['reward_specification']['reward_function'])\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'Z:/scratch/vr-foraging/data/'\n",
    "batch = 2\n",
    "summary_df = pd.DataFrame()\n",
    "# mouse_list = ['694569','694569','694569', '694569','694569',\n",
    "#               '690164', '690164', '690164','690164', '690164', \n",
    "#               '699894', '699894','699894', '699894', '699894']\n",
    "# file_list = ['20240212T114054','20240215T114212', '20240220T111303' , '20240222T105310', '20240228T112459', '20240301T110416', '20240307T121446',\n",
    "#              '20240212T111123','20240215T113732','20240220T110926','20240222T105243', '20240229T110323', '20240301T105900', '20240307T121323',\n",
    "#              '20240213T081458','20240214T081320', '20240222T082957', '20240223T090118', '20240229T120111', '20240301T122341']\n",
    "\n",
    "mouse_list = ['694569','694569','694569', '694569','694569',\n",
    "              '690164', '690164', '690164','690164', '690164', \n",
    "              '699894', '699894','699894', '699894', '699894']\n",
    "file_list = ['20240301T110416', '20240304T115743', '20240305T092623', '20240306T110105', '20240307T121446',\n",
    "             '20240301T105900', '20240304T112504', '20240305T092707', '20240306T112647', '20240307T121323',\n",
    "             '20240301T122341', '20240304T100025', '20240305T080111', '20240306T083350', '20240307T081725']\n",
    "\n",
    "session_n=0\n",
    "for file_name, mouse in zip(file_list, mouse_list):\n",
    "    if session_n == len(mouse_list)/3:\n",
    "        session_n = 0\n",
    "    session_n += 1\n",
    "    path = os.path.join(base_path, mouse, file_name)\n",
    "    session = file_name[:8]\n",
    "    session_path = Path(path)\n",
    "    print(session, mouse)\n",
    "    try:\n",
    "        data = parse.load_session_data(session_path)\n",
    "    except:\n",
    "        print('Error with loading data')\n",
    "        \n",
    "    # try:\n",
    "    #     if batch == 1:\n",
    "    #         reward_sites, active_site, encoder_data, config =  parse.parse_data_old(data, path)\n",
    "    #         print(batch)\n",
    "    #     else:  \n",
    "    \n",
    "    data['harp_olfactometer'].streams.OdorValveState.load_from_file()\n",
    "    data['harp_olfactometer'].streams.EndValveState.load_from_file()\n",
    "\n",
    "    data['harp_behavior'].streams.OutputSet.load_from_file()\n",
    "    data['harp_behavior'].streams.OutputClear.load_from_file()\n",
    "    data['config'].streams['TaskLogic'].load_from_file()\n",
    "    \n",
    "    all_epochs = parse.parse_dataframe(data)\n",
    "    reward_sites = AddExtraColumns(all_epochs, run_on_init=True).reward_sites\n",
    "    encoder_data = parse.ContinuousData(data).encoder_data\n",
    "\n",
    "    last_engaged_patch = reward_sites['active_patch'][reward_sites['skipped_count'] >= 10].min()\n",
    "    if pd.isna(last_engaged_patch):\n",
    "        last_engaged_patch = reward_sites['active_patch'].max()\n",
    "    reward_sites = reward_sites.loc[reward_sites['active_patch'] <= last_engaged_patch]\n",
    "\n",
    "    # except:\n",
    "    #     print('Error with parsing data')\n",
    "    #     continue\n",
    "    \n",
    "    reward_sites['maximum_reward'] = np.where(reward_sites['odor_label'] == 'Eugenol', 0, 21)\n",
    "    reward_sites['harvested'] = (reward_sites['maximum_reward']-reward_sites['reward_available'])/21\n",
    "    reward_sites['harvested_average'] = processing.compute_window(reward_sites, 5, 'harvested', 'active_patch')\n",
    "    \n",
    "    maximum = reward_sites.active_patch.max()\n",
    "    reward_sites['reversed_patch'] = maximum - reward_sites['active_patch'].values\n",
    "    reward_sites['odor_sites'] = np.arange(len(reward_sites))\n",
    "    reward_sites['mouse'] = mouse\n",
    "    reward_sites['session'] = session_n\n",
    "    summary_df = pd.concat([reward_sites, summary_df], axis=0)\n",
    "\n",
    "summary_df['odor_label'] = summary_df['patch_label']\n",
    "summary_df['harvested'] = np.where(summary_df.reward_amount == 0, 0,summary_df['harvested'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict_label = {'Ethyl Butyrate': color1, 'Alpha-pinene': color1, 'Amyl Acetate': color2, \n",
    "                    '2-Heptanone' : color2, 'Methyl Acetate': color1, 'Fenchone': color3, '2,3-Butanedione': color4,\n",
    "                    'Methyl Butyrate': color1, 'Eugenol': color3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse =  '694569'\n",
    "session = 3\n",
    "choice = 'visit_number'\n",
    "reward_sites = summary_df.loc[(summary_df['mouse'] == mouse)&(summary_df['session'] ==session)]\n",
    "reward_sites = reward_sites.loc[reward_sites['odor_label'] != 'Eugenol']\n",
    "reward_sites['harvested_average'] = processing.compute_window(reward_sites, 5, 'harvested', 'odor_sites')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(22, 4))\n",
    "sns.scatterplot(data=reward_sites, x='odor_sites', y=choice, hue='odor_label', palette=color_dict_label, s=50, ax=ax)\n",
    "plt.plot(reward_sites['odor_sites'], reward_sites[choice], color='black', linewidth=2, alpha=0.5, zorder=0)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(f'{mouse} - session {session}')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in ['694569', '690164', '699894']:\n",
    "    fig, axes = plt.subplots(1,len(summary_df.session.unique()), figsize=(4*len(summary_df.session.unique()), 6), sharey= True)\n",
    "    for session, ax in zip(sorted(summary_df.session.unique()), axes.flatten()):\n",
    "        new_df = summary_df.loc[(summary_df.session == session)&(summary_df.mouse == mouse)].groupby(['active_patch', 'reversed_patch', 'odor_label']).agg({'harvested': 'max', \n",
    "                                                                                                                                                            'visit_number':'count'}).reset_index()\n",
    "        sns.histplot(new_df.loc[new_df.odor_label == 'Amyl Acetate']['visit_number'], bins=np.arange(0,8,0.5), color=color_dict_label['Amyl Acetate'], ax=ax)\n",
    "        sns.histplot(new_df.loc[new_df.odor_label == 'Alpha-pinene']['visit_number'], bins=np.arange(0,8,0.5), color=color_dict_label['Alpha-pinene'], ax=ax)\n",
    "        sns.despine()\n",
    "        ax.set_title(f'Session {session}')\n",
    "        ax.set_xlabel('Visit number')\n",
    "        ax.set_ylabel('Count')\n",
    "    plt.suptitle(f'{mouse}')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {'Alpha-pinene': '#1b9e77', 'Amyl Acetate': '#d95f02', 'Eugenol': '#7570b3'}\n",
    "amount_palette = {3: '#1b9e77', 7: '#d95f02', 0: '#7570b3'}\n",
    "for mouse in ['694569', '690164', '699894']:\n",
    "    if mouse == '694569':\n",
    "        palette = {'Alpha-pinene': '#1b9e77', 'Amyl Acetate': '#d95f02', 'Eugenol': '#7570b3'}\n",
    "    else:\n",
    "        palette = {'Alpha-pinene': '#d95f02', 'Amyl Acetate': '#1b9e77', 'Eugenol': '#7570b3'}\n",
    "        \n",
    "    fig, ax = plt.subplots(1,len(summary_df.session.unique()), figsize=(4*len(summary_df.session.unique()), 5), sharey= True)\n",
    "    for session in sorted(summary_df.session.unique()):\n",
    "        new_df = summary_df.loc[(summary_df.session == session)&(summary_df.mouse == mouse)].groupby(['active_patch', 'reversed_patch', 'odor_label', 'reward_amount']).agg({'harvested': 'max', 'visit_number':'count'}).reset_index()\n",
    "        for odor_label in ['Amyl Acetate', 'Alpha-pinene', 'Eugenol']:\n",
    "            df= new_df.loc[new_df.odor_label == odor_label]\n",
    "            df = df.loc[df.active_patch > 3]\n",
    "            df = df.loc[df.active_patch < df.active_patch.max() - 10]\n",
    "            # if session == 1:\n",
    "            #     patch = 'reversed_patch'\n",
    "            #     ax[session-1].set_xlim(df.active_patch.max(), 0)\n",
    "            # elif session == 4:\n",
    "            #     patch = 'reversed_patch'\n",
    "            #     ax[session-1].set_xlim(df.active_patch.max(), 0)\n",
    "            # else:\n",
    "            #     patch = 'active_patch'\n",
    "            #     if session == 2:\n",
    "            #         session_top = df.active_patch.max()\n",
    "            #     elif session == 3:\n",
    "            #         df['active_patch'] = session_top + df['active_patch']\n",
    "                    \n",
    "            df['harvested_average'] = processing.compute_window(df, 5, 'harvested', patch)\n",
    "            sns.lineplot(data=df, x=patch, y='visit_number', legend=False, color=palette[odor_label], marker='.', linewidth=1, ax=ax[session-1])\n",
    "            ax[session-1].set_xlabel('Patch number')\n",
    "            ax[session-1].set_ylabel('Total stops')\n",
    "            ax[session-1].set_title(f'Session {session}')\n",
    "    \n",
    "    ax[1].yaxis.set_visible(False)\n",
    "    ax[1].spines['left'].set_color('none')\n",
    "    ax[2].yaxis.set_visible(False)\n",
    "    ax[2].spines['left'].set_color('none')\n",
    "    ax[3].yaxis.set_visible(False)\n",
    "    ax[3].spines['left'].set_color('none')\n",
    "    ax[4].yaxis.set_visible(False)\n",
    "    ax[4].spines['left'].set_color('none')\n",
    "    # ax[5].yaxis.set_visible(False)\n",
    "    # ax[5].spines['left'].set_color('none')\n",
    "    plt.suptitle(f'{mouse}')\n",
    "    ax[0].locator_params(axis='y', nbins=4)\n",
    "    sns.despine()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.loc[(summary_df['mouse'] == mouse)&(summary_df['session'] ==session)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse =  '694569'\n",
    "session = 7\n",
    "reward_sites = summary_df.loc[(summary_df['mouse'] == mouse)&(summary_df['session'] ==session)]\n",
    "if isinstance(data['config'], dict):\n",
    "    config = data['config']\n",
    "else:\n",
    "    config = data['config'].streams.TaskLogic.data\n",
    "plotting.segmented_raster_vertical(reward_sites, \n",
    "                                config, \n",
    "                                color_dict_label=color_dict_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization experiments for batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def parse_data_here(data):\n",
    "    try:\n",
    "        ## Load data from encoder efficiently\n",
    "        data['harp_behavior'].streams.AnalogData.load_from_file()\n",
    "        encoder_data = data['harp_behavior'].streams.AnalogData.data\n",
    "    except:\n",
    "        encoder_data = pd.DataFrame()\n",
    "        encoder_data['Encoder']  = parse.read_harp_bin(path + \"\\Behavior\\Register__44\"+\".bin\")[1]\n",
    "\n",
    "    try:\n",
    "        # Open and read the JSON file\n",
    "        with open(str(path)+'\\Config\\TaskLogic.json', 'r') as json_file:\n",
    "            config = json.load(json_file)\n",
    "            \n",
    "    except:\n",
    "        with open(str(path)+'\\config.json', 'r') as json_file:\n",
    "            config = json.load(json_file)\n",
    "        \n",
    "    try:\n",
    "        wheel_size = config.streams.Rig.data['treadmill']['wheelDiameter']\n",
    "        PPR = -config.streams.Rig.data['treadmill']['pulsesPerRevolution']\n",
    "        \n",
    "    except:\n",
    "        wheel_size = 15\n",
    "        PPR = -8192.0\n",
    "\n",
    "    perimeter = wheel_size*np.pi\n",
    "    resolution = perimeter / PPR\n",
    "    encoder_data['velocity'] = (encoder_data['Encoder'] * resolution)*1000\n",
    "\n",
    "    # Reindex the seconds so they are aligned to beginning of the session\n",
    "    start_time = encoder_data.index[0]\n",
    "    # encoder_data.index -= start_time\n",
    "\n",
    "    # Get the first odor onset per reward site\n",
    "    data['software_events'].streams.ActiveSite.load_from_file()\n",
    "    active_site = data['software_events'].streams.ActiveSite.data\n",
    "\n",
    "    # Use json_normalize to create a new DataFrame from the 'data' column\n",
    "    df_normalized = pd.json_normalize(active_site['data'])\n",
    "    df_normalized.index = active_site.index\n",
    "\n",
    "    # Concatenate the normalized DataFrame with the original DataFrame\n",
    "    active_site = pd.concat([active_site, df_normalized], axis=1)\n",
    "\n",
    "    active_site['label'] = np.where(active_site['label'] == 'Reward', 'RewardSite', active_site['label'])\n",
    "    active_site.rename(columns={'startPosition':'start_position'}, inplace= True)\n",
    "    # Rename columns\n",
    "\n",
    "    active_site = active_site[['label', 'start_position','length']]\n",
    "    reward_sites = active_site[active_site['label'] == 'RewardSite']\n",
    "\n",
    "    data['software_events'].streams.GiveReward.load_from_file()\n",
    "    reward = data['software_events'].streams.GiveReward.data\n",
    "    reward.fillna(0, inplace=True)\n",
    "\n",
    "    try:\n",
    "        data['software_events'].streams.ActivePatch.load_from_file()\n",
    "        patches = data['software_events'].streams.ActivePatch.data\n",
    "\n",
    "    except:\n",
    "        patches = active_site.loc[active_site['label'] == 'InterPatch']\n",
    "        patches.rename(columns={'label':'name'}, inplace=True)\n",
    "        patches['name'] = np.where(patches['name'] == 'InterPatch', 'ActivePatch', patches['name'])\n",
    "\n",
    "    try:\n",
    "        # Old way of obtaining the reward amount\n",
    "        reward_available = event[1][\"data\"][\"patchRewardFunction\"][\"initialRewardAmount\"]\n",
    "    except:\n",
    "        reward_available = config['environmentStatistics']['patches'][0]['patchRewardFunction']['initialRewardAmount']\n",
    "                \n",
    "    reward_updates = pd.concat([patches, reward])\n",
    "    reward_updates.sort_index(inplace=True)\n",
    "    reward_updates[\"current_reward\"] = np.nan\n",
    "\n",
    "    for event in reward_updates.iterrows():\n",
    "        if event[1][\"name\"] == 'GiveReward': #update reward\n",
    "            reward_available -= event[1][\"data\"]\n",
    "        elif event[1][\"name\"] == 'ActivePatch': #reset reward\n",
    "            try:\n",
    "                # Old way of obtaining the reward amount\n",
    "                reward_available = event[1][\"data\"][\"patchRewardFunction\"][\"initialRewardAmount\"]\n",
    "            except:\n",
    "                reward_available = config['environmentStatistics']['patches'][0]['patchRewardFunction']['initialRewardAmount']\n",
    "        else:\n",
    "            raise ValueError(\"Unknown event type\")\n",
    "        reward_updates.at[event[0], \"current_reward\"] = reward_available\n",
    "\n",
    "    for site in reward_sites.itertuples():\n",
    "        try:\n",
    "            arg_min, val_min = processing.find_closest(site.Index, reward_updates.index.values, mode=\"below_zero\")\n",
    "            reward_sites.loc[site.Index, \"reward_available\"] = reward_updates[\"current_reward\"].iloc[arg_min]\n",
    "        except:\n",
    "            reward_sites.loc[site.Index, \"reward_available\"] = reward_available\n",
    "\n",
    "    # Find responses to Reward site\n",
    "    data['software_events'].streams.ChoiceFeedback.load_from_file()\n",
    "    choiceFeedback = data['software_events'].streams.ChoiceFeedback.data\n",
    "\n",
    "    reward_sites.loc[:, \"active_patch\"] = -1\n",
    "    reward_sites.loc[:, \"visit_number\"] = -1\n",
    "    reward_sites.loc[:, \"has_choice\"] = False\n",
    "    reward_sites.loc[:, \"reward_delivered\"] = 0\n",
    "    reward_sites.loc[:, \"past_no_reward_count\"] = 0\n",
    "    past_no_reward_counter = 0\n",
    "    current_patch_idx = -1\n",
    "\n",
    "    visit_number = 0\n",
    "    for idx, event in enumerate(reward_sites.iterrows()):\n",
    "        arg_min, val_min = processing.find_closest(event[0], patches.index.values, mode=\"below_zero\")\n",
    "        if not(np.isnan(arg_min)):\n",
    "            reward_sites.loc[event[0], \"active_patch\"] = arg_min\n",
    "        if current_patch_idx != arg_min:\n",
    "            current_patch_idx = arg_min\n",
    "            visit_number = 0\n",
    "        else:\n",
    "            visit_number += 1\n",
    "        reward_sites.loc[event[0], \"visit_number\"] = visit_number\n",
    "\n",
    "        if idx < len(reward_sites) - 1:\n",
    "            choice = choiceFeedback.loc[(choiceFeedback.index >= reward_sites.index[idx]) & (choiceFeedback.index < reward_sites.index[idx+1])]\n",
    "            reward_in_site = reward.loc[(reward.index >= reward_sites.index[idx]) & (reward.index < reward_sites.index[idx+1])]\n",
    "        else:\n",
    "            choice = choiceFeedback.loc[(choiceFeedback.index >= reward_sites.index[idx])]\n",
    "            reward_in_site = reward.loc[(reward.index >= reward_sites.index[idx])]\n",
    "        reward_sites.loc[event[0], \"has_choice\"] = len(choice) > 0\n",
    "        reward_sites.loc[event[0], \"reward_delivered\"] = reward_in_site.iloc[0][\"data\"] if len(reward_in_site) > 0 else 0\n",
    "        reward_sites.loc[event[0], \"past_no_reward_count\"] = past_no_reward_counter\n",
    "        if reward_sites.loc[event[0], \"reward_delivered\"] == 0 and reward_sites.loc[event[0], \"has_choice\"] == 1:\n",
    "            past_no_reward_counter += 1\n",
    "        else:\n",
    "            past_no_reward_counter = 0\n",
    "    try:\n",
    "        df_patch = pd.json_normalize(patches['data'])\n",
    "        df_patch.reset_index(inplace=True)\n",
    "        df_patch.rename(columns={'index':'active_patch', 'label': 'odor_label', 'rewardSpecifications.amount': 'amount'}, inplace=True)\n",
    "        df_patch.rename(columns={'reward_specification.reward_function.amount.value': 'amount'}, inplace=True)\n",
    "    except:\n",
    "        df_patch = pd.DataFrame(columns=['active_patch', 'odor_label', 'amount'])\n",
    "        df_patch['active_patch'] = np.arange(len(patches))\n",
    "        df_patch['odor_label'] = config['environmentStatistics']['patches'][0]['label']\n",
    "        df_patch['amount'] = config['environmentStatistics']['patches'][0]['rewardSpecifications']['amount']\n",
    "        \n",
    "    reward_sites = pd.merge(reward_sites.reset_index(),df_patch[['odor_label', 'active_patch', 'amount']],  on='active_patch')\n",
    "\n",
    "    # Create new column for adjusted seconds to start of session\n",
    "    reward_sites['adj_seconds'] = reward_sites['Seconds'] - start_time\n",
    "    reward_sites.index = reward_sites['Seconds']\n",
    "    reward_sites.drop(columns=['Seconds'], inplace=True)\n",
    "\n",
    "    # ---------------- Add water triggers times ---------------- #\n",
    "    data['harp_behavior'].streams.OutputSet.load_from_file()\n",
    "    water = data['harp_behavior'].streams.OutputSet.data[['SupplyPort0']]\n",
    "    reward_sites['next_index'] = reward_sites.index.to_series().shift(-1)\n",
    "    reward_sites['water_onset'] = None\n",
    "\n",
    "    # Iterate through the actual index of df1\n",
    "    for value in water.index:\n",
    "        # Check if the value is between 'Start' and 'End' in df2\n",
    "        matching_row = reward_sites[(reward_sites.index <= value) & (reward_sites['next_index'].values >= value)]\n",
    "\n",
    "        # If a matching row is found, update the corresponding row in water with the index value\n",
    "        if not matching_row.empty:\n",
    "            matching_index = matching_row.index[0]  # Assuming there's at most one matching row\n",
    "            reward_sites.at[matching_index, 'water_onset'] = value\n",
    "            \n",
    "    # ---------------------------------------------------- #\n",
    "\n",
    "    # ---------------- Add odor triggers times ---------------- #\n",
    "\n",
    "    odor_0 = data['harp_behavior'].streams.OutputSet.data['SupplyPort1']\n",
    "    odor_1 = data['harp_behavior'].streams.OutputSet.data['SupplyPort2']\n",
    "\n",
    "    odor_0 = odor_0.reset_index()\n",
    "    odor_1 = odor_1.reset_index()\n",
    "\n",
    "    odor_0['odor_onset'] = np.where(odor_0['SupplyPort1'] == 1, config['environmentStatistics']['patches'][0]['label'], None)\n",
    "    odor_1['odor_onset'] = np.where(odor_1['SupplyPort2'] == 1, config['environmentStatistics']['patches'][1]['label'], None)\n",
    "\n",
    "    odor_df = pd.concat([odor_0[['Time','odor_onset']], odor_1[['Time','odor_onset']]])\n",
    "    odor_df.sort_index(inplace=True)\n",
    "    odor_df.dropna(inplace=True)\n",
    "\n",
    "    odor_df['time_diff'] = odor_df['Time'].diff()\n",
    "    odor_df = odor_df.drop(index=odor_df.loc[(odor_df['time_diff'] < 1)&(odor_df.index > 0)].index)\n",
    "\n",
    "    try:\n",
    "        reward_sites['odor_onset'] = odor_df['Time'].values\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # ---------------- Add stop triggers times ---------------- #\n",
    "    reward_sites['stop_time'] = None\n",
    "\n",
    "    # Iterate through the actual index of df1\n",
    "    for value in choiceFeedback.index:\n",
    "        # Check if the value is between 'Start' and 'End' in df2\n",
    "        matching_row = reward_sites[(reward_sites.index <= value) & (reward_sites['next_index'].values >= value)]\n",
    "\n",
    "        # If a matching row is found, update the corresponding row in water with the index value\n",
    "        if not matching_row.empty:\n",
    "            matching_index = matching_row.index[0]  # Assuming there's at most one matching row\n",
    "            reward_sites.at[matching_index, 'stop_time'] = value\n",
    "            \n",
    "    reward_sites.drop(columns=['next_index'], inplace=True)\n",
    "    # ---------------------------------------------------- #\n",
    "\n",
    "    # Add colum for site number\n",
    "    reward_sites.loc[:,'total_sites'] = np.arange(len(reward_sites))\n",
    "    reward_sites.loc[:,'collected'] = np.where((reward_sites['reward_delivered'] != 0), 1, 0)\n",
    "\n",
    "    reward_sites['next_visit_number'] = reward_sites['visit_number'].shift(-2)\n",
    "    reward_sites['last_visit'] = np.where(reward_sites['next_visit_number']==0, 1, 0)\n",
    "    reward_sites.drop(columns=['next_visit_number'], inplace=True)\n",
    "\n",
    "    reward_sites['last_site'] = reward_sites['visit_number'].shift(-1)\n",
    "    reward_sites['last_site'] = np.where(reward_sites['last_site'] == 0, 1,0)\n",
    "\n",
    "    reward_sites['next_patch'] = reward_sites['active_patch'].shift(1)\n",
    "    reward_sites['next_odor'] = reward_sites['odor_label'].shift(1)\n",
    "    reward_sites['same_patch'] = np.where((reward_sites['next_patch'] != reward_sites['active_patch'])&(reward_sites['odor_label'] == reward_sites['next_odor'] ), 1, 0)\n",
    "    reward_sites.drop(columns=['next_patch', 'next_odor'], inplace=True)\n",
    "\n",
    "    encoder_data = processing.fir_filter(encoder_data, 'velocity', 5)\n",
    "\n",
    "    return reward_sites, active_site, encoder_data, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dir = 'Z:/scratch/vr-foraging/data/'\n",
    "batch = 1\n",
    "summary_df = pd.DataFrame()\n",
    "colors_list = sns.palettes.color_palette('husl', 5)\n",
    "\n",
    "# mouse_list = ['672102','672103','672107']\n",
    "# file_list = ['20231003T','20231003T','20231003T']\n",
    "mouse_list = ['672102','672102','672102']\n",
    "file_list = ['20231002T094747','20231005T103221','20231006T101656']\n",
    "file_list = ['20231005']\n",
    "\n",
    "mouse_list = ['672103','672103','672103']\n",
    "file_list = ['20231004','20231006','20231009']\n",
    "file_list = ['20231005']\n",
    "\n",
    "session_n = 0\n",
    "\n",
    "for file_name, color, mouse in zip(file_list, colors_list, mouse_list):\n",
    "    print(file_name, mouse)\n",
    "    \n",
    "    if session_n == 3:\n",
    "        session_n = 0\n",
    "    session_n += 1\n",
    "\n",
    "    path = processing.find_file(start_dir + mouse+\"/\", file_name)\n",
    "    session_path = Path(path)\n",
    "    try:\n",
    "        data = parse.load_session_data(session_path)\n",
    "    except:\n",
    "        print('Error with loading data')\n",
    "        \n",
    "    reward_sites, active_site, encoder_data, config = parse_data_here(data)\n",
    "    \n",
    "    # patch_limit = parse.choose_cut(reward_sites, 10)\n",
    "    # reward_sites = reward_sites.loc[reward_sites.active_patch <= patch_limit]\n",
    "\n",
    "    if 'Ethyl Butyrate' in reward_sites.odor_label.unique():\n",
    "        reward_sites['maximum_reward'] = np.where(reward_sites['odor_label'] == 'Ethyl Butyrate', 0, 3)\n",
    "        reward_sites['harvested'] = (reward_sites['maximum_reward']-reward_sites['reward_available'])/3\n",
    "\n",
    "    else:\n",
    "        print(reward_sites.groupby('odor_label')['reward_available'].unique())\n",
    "        reward_sites['maximum_reward'] = np.where(reward_sites['odor_label'] == 'PineBerries', 0, 6)\n",
    "        reward_sites['reward_available'] = np.where(reward_sites['odor_label'] == 'PineBerries', 0, reward_sites['reward_available'])\n",
    "        \n",
    "        reward_sites['harvested'] = (reward_sites['maximum_reward']-reward_sites['reward_available'])/6\n",
    "\n",
    "    maximum = reward_sites.active_patch.max()\n",
    "    reward_sites['reversed_patch'] = maximum - reward_sites['active_patch'].values\n",
    "\n",
    "    reward_sites['mouse'] = mouse\n",
    "    reward_sites['session'] = session_n\n",
    "    summary_df = pd.concat([reward_sites, summary_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict_label = {'Ethyl Butyrate': color1, 'Alpha-pinene': color2, 'Amyl Acetate': color3, 'Bananas': color1, 'PineBerries': color2, 'Pineapple': color3,\n",
    "                    '2-Heptanone' : color2, 'Methyl Acetate': color1, 'Fenchone': color3, '2,3-Butanedione': color4,\n",
    "                    'Methyl Butyrate': color1, 'Eugenol':color3, 'Octanol':color3}\n",
    "if isinstance(data['config'], dict):\n",
    "    config = data['config']\n",
    "else:\n",
    "    config = data['config'].streams.TaskLogic.data\n",
    "plotting.segmented_raster_vertical(reward_sites, \n",
    "                                config, \n",
    "                                color_dict_label=color_dict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_sites['odor_sites'] = np.arange(len(reward_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {'Octanol': 'blue', 'Bananas': 'darkorange', 'Ethyl Butyrate': 'crimson', 'PineBerries': 'indigo'}\n",
    "fig, ax = plt.subplots(1,len(summary_df.session.unique()), figsize=(4*len(summary_df.session.unique()), 4), sharey= True)\n",
    "for session in summary_df.session.unique():\n",
    "    new_df = summary_df.loc[(summary_df.session == session)&(summary_df.mouse == mouse)].groupby(['active_patch', 'reversed_patch', 'odor_label']).agg({'has_choice': 'sum'}).reset_index()\n",
    "    for odor_label in summary_df.odor_label.unique():\n",
    "        df= new_df.loc[new_df.odor_label == odor_label]\n",
    "        if session == 1:\n",
    "            patch = 'reversed_patch'\n",
    "            ax[session-1].set_xlim(75, 0)\n",
    "        elif session == 2:\n",
    "            patch_number = df.active_patch.max()\n",
    "            patch = 'active_patch'\n",
    "        df['harvested_average'] = processing.compute_window(df, 5, 'has_choice', patch)\n",
    "        sns.lineplot(data=df, x=patch, y='has_choice', legend=False, color=palette[odor_label], marker='.', linewidth=1, ax=ax[session-1])\n",
    "        ax[session-1].set_xlabel('Patch number')\n",
    "        ax[session-1].set_ylabel('Total stops')\n",
    "        ax[session-1].set_title(f'Session {session}')\n",
    "        \n",
    "\n",
    "ax[2].yaxis.set_visible(False)\n",
    "ax[2].spines['left'].set_color('none')\n",
    "ax[0].locator_params(axis='y', nbins=3)\n",
    "ax[0].locator_params(axis='x', nbins=4)\n",
    "ax[1].locator_params(axis='x', nbins=4)\n",
    "ax[2].locator_params(axis='x', nbins=4)\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
