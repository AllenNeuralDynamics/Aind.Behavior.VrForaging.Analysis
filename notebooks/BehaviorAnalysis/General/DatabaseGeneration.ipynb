{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../src/')\n",
    "\n",
    "import os\n",
    "from typing import Dict\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "\n",
    "import data_io\n",
    "\n",
    "from harp.reader import create_reader\n",
    "\n",
    "from utils import parse, processing, plotting_utils as plotting, AddExtraColumns\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from tkinter import font\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter, MaxNLocator, FixedLocator\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "def format_func(value, tick_number):\n",
    "    return f\"{value:.0f}\"\n",
    "\n",
    "from numpy.typing import ArrayLike\n",
    "from typing import Literal, Tuple\n",
    "\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_df = pd.DataFrame(columns=['mouse', 'session', 'total_sites', 'rewarded_stops', 'unrewarded_stops', 'water', 'distance', 'session_n'])\n",
    "cumulative_df_trials = pd.DataFrame()\n",
    "# for mouse in [\"690164\",\"690165\",\"690167\",\"699894\",\"699895\",\"699899\", \"694569\"]:\n",
    "for mouse in [\"716455\"]:\n",
    "\n",
    "    base_path = 'Z:/scratch/vr-foraging/data/'\n",
    "\n",
    "    session_n = 0\n",
    "    current_session = ''\n",
    "    for file_name in os.listdir(os.path.join(base_path, mouse)):\n",
    "\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session = file_name[:8]\n",
    "        if current_session != session:\n",
    "            session_n+=1\n",
    "            current_session = session\n",
    "        session_path = Path(session_path)\n",
    "\n",
    "        try:\n",
    "            data = parse.load_session_data(session_path)\n",
    "        except:\n",
    "            print('This session is missing data: ', session)\n",
    "            continue\n",
    "\n",
    "        print(session)\n",
    "        try:\n",
    "            data = parse.load_session_data(session_path)\n",
    "        except:\n",
    "            print('Error in loading')\n",
    "            continue\n",
    "                \n",
    "        try:\n",
    "            data['harp_olfactometer'].streams.OdorValveState.load_from_file()\n",
    "            data['harp_olfactometer'].streams.EndValveState.load_from_file()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            data['harp_behavior'].streams.OutputSet.load_from_file()\n",
    "            data['harp_behavior'].streams.OutputClear.load_from_file()\n",
    "            data['config'].streams['TaskLogic'].load_from_file()\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            reward_sites, active_site, encoder_data, config = analysis.parse_data(data)\n",
    "        except:\n",
    "            print('Error parsing data')\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        collected_df = reward_sites.loc[reward_sites['has_choice']==True].groupby(['collected','odor_label'])['reward_delivered'].count().reset_index()\n",
    "\n",
    "        unrewarded_stops = collected_df.loc[collected_df.collected==0]['reward_delivered'].sum()\n",
    "        rewarded_stops = collected_df.loc[collected_df.collected==1]['reward_delivered'].sum()\n",
    "        water_collected = reward_sites.loc[(reward_sites['collected']==1)]['reward_delivered'].sum()\n",
    "        total_stops = reward_sites.loc[(reward_sites['has_choice']==True)]['reward_available'].count()\n",
    "\n",
    "        stopped_df = reward_sites.loc[(reward_sites['has_choice']==True)].groupby(['collected','odor_label'])[['reward_delivered']].sum().reset_index()\n",
    "        \n",
    "        print('Total sites: ' ,len(reward_sites), ' | ', 'Total rewarded stops: ',rewarded_stops, '(',  np.round((rewarded_stops/total_stops)*100,2),'%) | ', \n",
    "            'Total unrewarded stops: ',unrewarded_stops,'(',  np.round((unrewarded_stops/total_stops)*100,2),'%) | ','Water consumed: ', water_collected, 'ul',)\n",
    "        if 'startPosition' in active_site.columns:\n",
    "            print('Total travelled m: ', np.round(active_site.startPosition.max()/100,2))\n",
    "        else:\n",
    "            print('Total travelled m: ', np.round(active_site.start_position.max(),2))\n",
    "            \n",
    "        for odor_label in stopped_df.loc[(stopped_df.collected==1)].odor_label.unique():\n",
    "            print(odor_label, ':', stopped_df.loc[(stopped_df.odor_label == odor_label)&(stopped_df.collected==1), 'reward_delivered'].iloc[0], 'ul')\n",
    "\n",
    "        if 'startPosition' in active_site.columns:\n",
    "            stop_duration = np.round(active_site.startPosition.max()/100,2)\n",
    "        else:\n",
    "            stop_duration = np.round(active_site.start_position.max(),2)\n",
    "        print('Total travelled m: ', np.round(active_site.start_position.max(),2))\n",
    "        \n",
    "        cumulative_df_trials['mouse'] = mouse\n",
    "        cumulative_df_trials['session'] = session\n",
    "        cumulative_df_trials = pd.concat([cumulative_df_trials, reward_sites], ignore_index=True)\n",
    "\n",
    "        # if session not in cumulative_df.session.unique() and :\n",
    "        new_row = {'mouse':mouse, 'session':session, 'total_sites':len(reward_sites), 'rewarded_stops':rewarded_stops, 'unrewarded_stops':unrewarded_stops, \n",
    "                    'water':water_collected, 'distance':stop_duration, 'session_n':session_n}\n",
    "        cumulative_df.loc[len(cumulative_df)] = new_row\n",
    "        \n",
    "        \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.date.today()\n",
    "date_string = \"4/22/2024\"\n",
    "date = datetime.datetime.strptime(date_string, \"%m/%d/%Y\").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = '715866'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_found = False\n",
    "\n",
    "directory = os.path.join(base_path, mouse)\n",
    "files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=True)\n",
    "\n",
    "for file_name in sorted_files:\n",
    "    \n",
    "    if session_found == True:\n",
    "        break\n",
    "    \n",
    "    print(file_name)\n",
    "    session_path = os.path.join(base_path, mouse, file_name)\n",
    "    session = file_name[:8]\n",
    "    session_path = Path(session_path)\n",
    "    \n",
    "    if datetime.date.fromtimestamp(os.path.getctime(session_path)) != date:\n",
    "        continue\n",
    "    else:\n",
    "        print('correct date found')\n",
    "        session_found = True\n",
    "    \n",
    "\n",
    "    data = analysis.load_session_data(session_path)\n",
    "    \n",
    "\n",
    "    data['harp_olfactometer'].streams.OdorValveState.load_from_file()\n",
    "    data['harp_olfactometer'].streams.EndValveState.load_from_file()\n",
    "    data['software_events'].streams.ActiveSite.load_from_file()\n",
    "    data['software_events'].streams.ChoiceFeedback.load_from_file()\n",
    "    \n",
    "    data['harp_behavior'].streams.OutputSet.load_from_file()\n",
    "    data['harp_behavior'].streams.OutputClear.load_from_file()\n",
    "    \n",
    "    reward_sites, active_site, encoder_data, config = analysis.parse_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs = pd.concat([reward_sites, active_site.loc[active_site.label != 'RewardSite']])\n",
    "all_epochs.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_patch = -1\n",
    "total_sites = -1\n",
    "for i, row in all_epochs.iterrows():\n",
    "    if row['label'] == 'InterPatch':\n",
    "        active_patch += 1\n",
    "    if row['label'] == 'InterSite':\n",
    "        total_sites += 1\n",
    "    all_epochs.at[i, 'active_patch'] = active_patch\n",
    "    all_epochs.at[i, 'total_sites'] = total_sites\n",
    "all_epochs['total_sites'] = np.where(all_epochs['total_sites'] == -1, 0, all_epochs['total_sites'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_df = pd.DataFrame(columns=['odor_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['config'].streams['tasklogic_input'].load_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_df.at[1, 'odor_' + str(i)] = data['config'].streams['tasklogic_input'].data['environment_statistics']['patches'][i]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "data['config'].streams['tasklogic_input'].data['environment_statistics']['patches'][i]\n",
    "cumulative_df['odor_' + str(i)] = data['config'].streams['tasklogic_input'].data['environment_statistics']['patches'][i]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['config'].streams['tasklogic_input'].data['environment_statistics']['patches'][i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
