{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from aind_vr_foraging_analysis.utils.parsing import parse, AddExtraColumns\n",
    "import aind_vr_foraging_analysis.utils.plotting as plotting\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "color1='#d95f02'\n",
    "color2='#1b9e77'\n",
    "color3='#7570b3'\n",
    "color4='yellow'\n",
    "odor_list_color = [color1, color2, color3, color4]\n",
    "\n",
    "pdf_path = r'Z:\\scratch\\vr-foraging\\sessions'\n",
    "base_path = 'Z:/scratch/vr-foraging/data/'\n",
    "foraging_figures = r'C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsVrForaging():\n",
    "    def __init__(self, session_path: PathLike):\n",
    "        self.session_path = Path(session_path)\n",
    "        self.data = parse.load_session_data(self.session_path)\n",
    "        self.session = self.data['config'].streams.session_input.data['date'][:10]\n",
    "        self.mouse = int(self.data['config'].streams.session_input.data['subject'])\n",
    "        self.stage = self.data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        self.rig_name = self.data['config'].streams.rig_input.data['rig_name']\n",
    "        self.experimenter = self.data['config'].streams.session_input.data['experimenter'][0]\n",
    "        \n",
    "        print(self.rig_name)\n",
    "        print(self.stage)\n",
    "        print(self.experimenter)\n",
    "        if self.stage == 'thermistor screening':\n",
    "            return\n",
    "        \n",
    "        self.data = parse.load_session_data(self.session_path)\n",
    "        self.stage = self.data['config'].streams.tasklogic_input.data['stage_name']\n",
    "\n",
    "        self.active_site = parse.parse_dataframe(self.data)\n",
    "        self.reward_sites = self.active_site.loc[self.active_site['label'] == 'OdorSite'].copy()\n",
    "        self.df = self.retrieve_metrics()\n",
    "\n",
    "    def retrieve_metrics(self) -> pd.DataFrame:\n",
    "        reward_sites = self.reward_sites\n",
    "        active_site = self.active_site\n",
    "        data = self.data\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        # Summary of different relevants aspects -------------------------------------------------\n",
    "\n",
    "        unrewarded_stops = reward_sites.loc[reward_sites.is_reward==0]['reward_amount'].count()\n",
    "        rewarded_stops = reward_sites.loc[reward_sites.is_reward==1]['reward_amount'].count()\n",
    "        water_collected = reward_sites.loc[(reward_sites['is_reward']==1)]['reward_amount'].sum()\n",
    "        total_stops = reward_sites.loc[(reward_sites['is_choice']==True)]['reward_amount'].count()\n",
    "\n",
    "        print('Total sites: ' ,len(reward_sites), ' | ', 'Total rewarded stops: ',rewarded_stops, '(',  np.round((rewarded_stops/total_stops)*100,2),'%) | ', \n",
    "            'Total unrewarded stops: ',unrewarded_stops,'(',  np.round((unrewarded_stops/total_stops)*100,2),'%) | ','Water consumed: ', water_collected, 'ul')\n",
    "\n",
    "        print('Total travelled m: ', np.round(active_site.start_position.max()/100,2), ', current position (cm): ', data['operation_control'].streams.CurrentPosition.data.max()[0]\n",
    "        )\n",
    "\n",
    "        for odor_label in reward_sites.odor_label.unique():\n",
    "            values = reward_sites.loc[(reward_sites['odor_label']==odor_label)&(reward_sites['is_reward']==1)]['reward_amount'].sum()\n",
    "            print(f'{odor_label} {values} ul')\n",
    "            \n",
    "        df.at[0,'odor_sites_travelled'] = int(len(reward_sites))\n",
    "        df.at[0,'distance_m'] = data['operation_control'].streams.CurrentPosition.data.max()[0]/100\n",
    "        df.at[0,'water_collected_ul'] = water_collected\n",
    "        df.at[0,'rewarded_stops'] = int(rewarded_stops)\n",
    "        df.at[0,'total_stops'] = int(total_stops)\n",
    "        df.at[0,'session_duration_min'] = (reward_sites.index[-1] - reward_sites.index[0])/60\n",
    "        df.at[0, 'total_patches_visited'] = reward_sites.loc[reward_sites['site_number'] >= 1].patch_number.nunique()\n",
    "        return df\n",
    "\n",
    "    def retrieve_updater_values(self):\n",
    "        # Initialize a pointer for the data values\n",
    "        data_pointer = 0\n",
    "        \n",
    "        reward_sites = self.reward_sites\n",
    "        data = self.data\n",
    "        df = self.df\n",
    "        \n",
    "        # Save the updater values\n",
    "        stop_duration = data['updater_events'].streams.UpdaterStopDurationOffset.data['data']\n",
    "        stop_duration.reset_index(drop=True, inplace=True)\n",
    "        delay = data['updater_events'].streams.UpdaterRewardDelayOffset.data['data']\n",
    "        delay.reset_index(drop=True, inplace=True)\n",
    "        velocity_threshold = data['updater_events'].streams.UpdaterStopVelocityThreshold.data['data']\n",
    "        velocity_threshold.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Create a new column in reward_sites to store the updated values\n",
    "        reward_sites['delay_s'] = None\n",
    "        reward_sites['velocity_threshold_cms'] = None\n",
    "        reward_sites['stop_duration_s'] = None\n",
    "\n",
    "        try:\n",
    "            # Iterate through each row of reward_sites\n",
    "            for index, row in reward_sites.iterrows():\n",
    "                if row['is_reward'] == 1:\n",
    "                    # Copy the next available value from data and move the pointer\n",
    "                    reward_sites.at[index, 'delay_s'] = delay[data_pointer]\n",
    "                    reward_sites.at[index, 'velocity_threshold_cms'] = velocity_threshold[data_pointer]\n",
    "                    reward_sites.at[index, 'stop_duration_s'] = stop_duration[data_pointer]\n",
    "                    data_pointer += 1\n",
    "                else:\n",
    "                    # Copy the same value without moving the pointer\n",
    "                    reward_sites.at[index, 'delay_s'] = delay[data_pointer]\n",
    "                    reward_sites.at[index, 'velocity_threshold_cms'] = velocity_threshold[data_pointer]\n",
    "                    reward_sites.at[index, 'stop_duration_s'] = stop_duration[data_pointer]\n",
    "        except KeyError:\n",
    "                reward_sites.at[index, 'delay_s'] = max(delay)\n",
    "                reward_sites.at[index, 'velocity_threshold_cms'] = max(velocity_threshold)\n",
    "                reward_sites.at[index, 'stop_duration_s'] = max(stop_duration)\n",
    "\n",
    "        # Summary of the training metrics\n",
    "        reward_sites['odor_sites'] = np.arange(1, len(reward_sites)+1)\n",
    "        df.at[0,'start_delay'] = reward_sites['delay_s'].min()\n",
    "        df.at[0,'end_delay'] = reward_sites['delay_s'].max()\n",
    "        df.at[0, 'sites_to_max_delay'] = reward_sites[reward_sites['delay_s'] == reward_sites['delay_s'].max()].iloc[0]['odor_sites']\n",
    "        df.at[0,'start_stop_duration'] = reward_sites['stop_duration_s'].min()\n",
    "        df.at[0,'end_stop_duration'] = reward_sites['stop_duration_s'].max()\n",
    "        df.at[0, 'sites_to_max_stop_duration'] = reward_sites[reward_sites['stop_duration_s'] == reward_sites['stop_duration_s'].max()].iloc[0]['odor_sites']\n",
    "        df.at[0, 'rewarded_sites_in_max_stop'] = int(reward_sites[(reward_sites['stop_duration_s'] == reward_sites['stop_duration_s'].max())&(reward_sites.is_choice == 1)]['odor_sites'].nunique())\n",
    "\n",
    "        df.at[0,'start_velocity_threshold'] = reward_sites['velocity_threshold_cms'].min()\n",
    "        df.at[0,'end_velocity_threshold'] = reward_sites['velocity_threshold_cms'].max()\n",
    "        df.at[0,'target_max_velocity_threshold'] = reward_sites['velocity_threshold_cms'].max()\n",
    "        df.at[0, 'sites_to_min_velocity'] = reward_sites[reward_sites['velocity_threshold_cms'] == reward_sites['velocity_threshold_cms'].min()].iloc[0]['odor_sites']\n",
    "            \n",
    "        self.reward_sites = reward_sites\n",
    "        self.df = df\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return self.df\n",
    "\n",
    "    def get_reward_sites(self):\n",
    "        return self.reward_sites\n",
    "    \n",
    "    def get_mouse_and_session(self):\n",
    "        return self.mouse, self.session\n",
    "    \n",
    "    def run_pdf_summary(self):\n",
    "        color1='#d95f02'\n",
    "        color2='#1b9e77'\n",
    "        color3='#7570b3'\n",
    "        color4='#e7298a'\n",
    "\n",
    "        color_dict_label = {'Ethyl Butyrate': color1, 'Alpha-pinene': color1, 'Amyl Acetate': color3, 'Eugenol' : color3,\n",
    "                            '2-Heptanone' : color2, 'Methyl Acetate': color1, 'Fenchone': color4, '2,3-Butanedione': color4, 'Methyl Butyrate': color2,}\n",
    "        \n",
    "        stream_data = parse.ContinuousData(self.data)\n",
    "        encoder_data = stream_data.encoder_data\n",
    "        odor_sites = AddExtraColumns(self.active_site).get_odor_sites()\n",
    "        active_site = AddExtraColumns(self.active_site).get_all_epochs()\n",
    "        active_site['duration_epoch'] = active_site['stop_time'] - active_site.index\n",
    "        active_site['mouse'] = self.mouse\n",
    "        active_site['session'] = self.session\n",
    "        \n",
    "        # Remove segments where the mouse was disengaged\n",
    "        last_engaged_patch = odor_sites['patch_number'][odor_sites['skipped_count'] >= 10].min()\n",
    "        if pd.isna(last_engaged_patch):\n",
    "            last_engaged_patch = odor_sites['patch_number'].max()\n",
    "            \n",
    "        odor_sites['engaged'] = odor_sites['patch_number'] <= last_engaged_patch  \n",
    "    \n",
    "        trial_summary = plotting.trial_collection(odor_sites[['is_choice', 'site_number', 'odor_label', 'depleted', 'odor_sites', 'is_reward',\n",
    "                                                                'reward_probability','reward_amount','reward_available']], \n",
    "                                                  encoder_data, \n",
    "                                                  window=(-1,3)\n",
    "                                                )\n",
    "    \n",
    "        # Save each figure to a separate page in the PDF\n",
    "        pdf_filename = f'{self.mouse}_{self.session}_summary.pdf'\n",
    "        with PdfPages(pdf_path+\"\\\\\"+pdf_filename) as pdf:\n",
    "            text1 = ('Mouse: ' + str(self.mouse) \n",
    "            + '\\nSession: ' + str(self.session) \n",
    "            + '\\nRig: ' + str(self.rig_name) \n",
    "            + '\\nStage: ' + str(self.stage)\n",
    "            + '\\nTotal sites: '  + str(self.df.total_stops.iloc[0]) \n",
    "            + '\\nTotal rewarded stops: ' + str(self.df.rewarded_stops.iloc[0]) + ' (' +str(np.round((self.df.rewarded_stops.iloc[0]/self.df.total_stops.iloc[0])*100,2)) + '%) \\n' \n",
    "            + 'Water consumed: ' +  str(np.round(self.df.water_collected_ul.iloc[0], 2)) + 'ul\\n' \n",
    "            + 'Session duration: ' + str(np.round(self.df.session_duration_min.iloc[0],2)) + 'min\\n' \n",
    "            + 'Total travelled m: ' + str(np.round(active_site.start_position.max()/100,2))\n",
    "            )\n",
    "            \n",
    "            # '(',  np.round((rewarded_stops/total_stops)*100,2),'%) | ', \n",
    "            text_to_figure = text1\n",
    "            if self.stage[:7] == 'shaping':\n",
    "                text2 = '\\nTotal sites travelled: ' + str(self.df.odor_sites_travelled.iloc[0]) + '\\nRewarded stops in max stop duration: ' + str(self.df.rewarded_sites_in_max_stop.iloc[0]) + '\\nTotal patches visited: ' + str(self.df.total_patches_visited.iloc[0])\n",
    "                text_to_figure = text1 + text2\n",
    "            \n",
    "            # Create a figure\n",
    "            fig, ax = plt.subplots(figsize=(8.5, 11))  # Standard letter size\n",
    "            ax.text(0.1, 0.9, text_to_figure, ha='left', va='center', fontsize=12)\n",
    "            ax.axis('off')  # Hide the axes\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # plotting.raster_with_velocity(active_site, stream_data, color_dict_label=color_dict_label, save=pdf)\n",
    "            plotting.segmented_raster_vertical(odor_sites, \n",
    "                                            self.data['config'].streams['tasklogic_input'].data, \n",
    "                                            save=pdf, \n",
    "                                            color_dict_label=color_dict_label)\n",
    "            plotting.raster_with_velocity(active_site, stream_data, color_dict_label=color_dict_label, save=pdf)\n",
    "            plotting.summary_withinsession_values(odor_sites, \n",
    "                                    color_dict_label = color_dict_label, \n",
    "                                    save=pdf)\n",
    "            plotting.speed_traces_efficient(trial_summary, self.mouse, self.session,  save=pdf)\n",
    "            plotting.preward_estimates(odor_sites, \n",
    "                                    color_dict_label = color_dict_label, \n",
    "                                    save=pdf)\n",
    "            plotting.speed_traces_value(trial_summary, self.mouse, self.session, condition = 'reward_probability', save=pdf) \n",
    "            plotting.velocity_traces_odor_entry(trial_summary, max_range = trial_summary.speed.max(), color_dict_label=color_dict_label, save=pdf)\n",
    "\n",
    "            plotting.length_distributions(self.active_site, self.data, delay=True, save=pdf)\n",
    "            if self.stage[:7] == 'shaping':\n",
    "                plotting.update_values(self.reward_sites, save=pdf)\n",
    "            \n",
    "        return pdf_filename\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do it for several animals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_dict = {'745305': 'Olivia', \n",
    "                '745302': 'Olivia', \n",
    "                '754570': 'Olivia', \n",
    "                '754571': 'Olivia', \n",
    "                '754572' : 'Olivia', \n",
    "                '754582': 'Olivia',\n",
    "                '745300': 'Olivia',\n",
    "                '745301': 'Huy',\n",
    "                '754575': 'Huy',\n",
    "                '754573': 'Huy',\n",
    "                '754567': 'Huy',\n",
    "                '754579': 'Huy',\n",
    "                '745306': 'Huy',\n",
    "                '745307': 'Huy',\n",
    "                '754580': 'Katrina',\n",
    "                '754560': 'Katrina',\n",
    "                '754559': 'Katrina',\n",
    "                '754574': 'Katrina',\n",
    "                '754577': 'Katrina',\n",
    "                '754566': 'Katrina',\n",
    "}               \n",
    "\n",
    "# stage_progression = {'stageA_v1': 'Stage A',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_dict = {\n",
    "                '789923': 'Katrina', \n",
    "                '789917' : 'Katrina', \n",
    "                '789913': 'Katrina',\n",
    "                '789909': 'Huy',\n",
    "                '789910': 'Huy',\n",
    "                '789911': 'Huy',\n",
    "                '789921': 'Huy',\n",
    "                '789918': 'Huy',\n",
    "                '789919': 'Huy',\n",
    "                '789907': 'Olivia',\n",
    "                '789903': 'Olivia',\n",
    "                '789925': 'Olivia',\n",
    "                '789924': 'Olivia',\n",
    "                '789926': 'Olivia',\n",
    "                '789908': 'Olivia',\n",
    "}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mouse_list = trainer_dict.keys()\n",
    "\n",
    "summary_box_trainer  = {}\n",
    "date_string = \"2025-4-15\"\n",
    "date = parse.parse_user_date(date_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "789923_2025-04-15T170313Z\n",
      "4B\n",
      "learning_task_step0\n",
      "Katrina\n",
      "Total sites:  247  |  Total rewarded stops:  105 ( 54.97 %) |  Total unrewarded stops:  142 ( 74.35 %) |  Water consumed:  735.0 ul\n",
      "Total travelled m:  336.93 , current position (cm):  33717.2578\n",
      "Alpha-pinene 518.0 ul\n",
      "Fenchone 217.0 ul\n",
      "Methyl Butyrate 0.0 ul\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     46\u001b[39m     parsed_session.retrieve_updater_values()\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     48\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mTotal sites travelled: \u001b[39m\u001b[33m'\u001b[39m + \u001b[38;5;28mstr\u001b[39m(df.odor_sites_travelled.iloc[\u001b[32m0\u001b[39m]),\n\u001b[32m     49\u001b[39m     \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRewarded stops in max stop duration: \u001b[39m\u001b[33m'\u001b[39m + \u001b[38;5;28mstr\u001b[39m(df.rewarded_sites_in_max_stop.iloc[\u001b[32m0\u001b[39m]),\n\u001b[32m     50\u001b[39m     \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTotal patches visited: \u001b[39m\u001b[33m'\u001b[39m + \u001b[38;5;28mstr\u001b[39m(df.total_patches_visited.iloc[\u001b[32m0\u001b[39m]))\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m pdf_filename = \u001b[43mparsed_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pdf_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m os.startfile(pdf_path+\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m + pdf_filename)\n\u001b[32m     56\u001b[39m reward_sites[\u001b[33m'\u001b[39m\u001b[33mmouse\u001b[39m\u001b[33m'\u001b[39m] = mouse\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 132\u001b[39m, in \u001b[36mMetricsVrForaging.run_pdf_summary\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    127\u001b[39m color4=\u001b[33m'\u001b[39m\u001b[33m#e7298a\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    129\u001b[39m color_dict_label = {\u001b[33m'\u001b[39m\u001b[33mEthyl Butyrate\u001b[39m\u001b[33m'\u001b[39m: color1, \u001b[33m'\u001b[39m\u001b[33mAlpha-pinene\u001b[39m\u001b[33m'\u001b[39m: color1, \u001b[33m'\u001b[39m\u001b[33mAmyl Acetate\u001b[39m\u001b[33m'\u001b[39m: color3, \u001b[33m'\u001b[39m\u001b[33mEugenol\u001b[39m\u001b[33m'\u001b[39m : color3,\n\u001b[32m    130\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m2-Heptanone\u001b[39m\u001b[33m'\u001b[39m : color2, \u001b[33m'\u001b[39m\u001b[33mMethyl Acetate\u001b[39m\u001b[33m'\u001b[39m: color1, \u001b[33m'\u001b[39m\u001b[33mFenchone\u001b[39m\u001b[33m'\u001b[39m: color4, \u001b[33m'\u001b[39m\u001b[33m2,3-Butanedione\u001b[39m\u001b[33m'\u001b[39m: color4, \u001b[33m'\u001b[39m\u001b[33mMethyl Butyrate\u001b[39m\u001b[33m'\u001b[39m: color2,}\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m stream_data = \u001b[43mparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mContinuousData\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m encoder_data = stream_data.encoder_data\n\u001b[32m    134\u001b[39m odor_sites = AddExtraColumns(\u001b[38;5;28mself\u001b[39m.active_site).get_odor_sites()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\git\\Aind.Behavior.VrForaging.Analysis\\src\\aind_vr_foraging_analysis\\utils\\parsing\\parse.py:111\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, data, load_continuous)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\git\\Aind.Behavior.VrForaging.Analysis\\src\\aind_vr_foraging_analysis\\utils\\parsing\\parse.py:246\u001b[39m, in \u001b[36msniff_data_loading\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    241\u001b[39m     self.encoder_data = encoder\n\u001b[32m    243\u001b[39m     return self.encoder_data\n\u001b[32m    245\u001b[39m def torque_loading(self, parser: str = \"filter\"):\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     ## Load data from encoder efficiently\n\u001b[32m    247\u001b[39m     if self.current_version >= Version(\"0.3.0\"):\n\u001b[32m    248\u001b[39m         self.data[\"harp_treadmill\"].streams.SensorData.load_from_file()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\git\\Aind.Behavior.VrForaging.Analysis\\src\\aind_vr_foraging_analysis\\data_io\\__init__.py:377\u001b[39m, in \u001b[36mHarpStream.load_from_file\u001b[39m\u001b[34m(self, path, force_reload)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# load raw file as a binary\u001b[39;00m\n\u001b[32m    376\u001b[39m reg_addr = \u001b[38;5;28mself\u001b[39m._get_address_from_bin(path)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m \u001b[38;5;28mself\u001b[39m._data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregisters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreg_addr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\git\\Aind.Behavior.VrForaging.Analysis\\.venv\\Lib\\site-packages\\harp\\reader.py:178\u001b[39m, in \u001b[36m_create_register_reader.<locals>.reader\u001b[39m\u001b[34m(file, columns, epoch, keep_type)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    176\u001b[39m     file = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams.path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregister.address\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.bin\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m data = \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregister\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregister\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregister\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\git\\Aind.Behavior.VrForaging.Analysis\\.venv\\Lib\\site-packages\\harp\\io.py:75\u001b[39m, in \u001b[36mread\u001b[39m\u001b[34m(file, address, dtype, length, columns, epoch, keep_type)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\n\u001b[32m     39\u001b[39m     file: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, PathLike[Any], BinaryIO],\n\u001b[32m     40\u001b[39m     address: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     keep_type: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     46\u001b[39m ):\n\u001b[32m     47\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read single-register Harp data from the specified file.\u001b[39;00m\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m \u001b[33;03m        A pandas data frame containing message data, sorted by time.\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) == \u001b[32m0\u001b[39m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(columns=columns, index=pd.Index([], dtype=np.float64, name=\u001b[33m\"\u001b[39m\u001b[33mTime\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "odor_sites_sum = pd.DataFrame()\n",
    "for mouse in mouse_list:\n",
    "    session_found = False\n",
    "    directory = os.path.join(base_path, mouse)\n",
    "    files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "    sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "    # All this segment is to find the correct session without having the specific path\n",
    "    for file_name in sorted_files:\n",
    "        if session_found == True:\n",
    "            break\n",
    "        \n",
    "        session = parse.extract_and_convert_time(file_name)\n",
    "        if session != date:\n",
    "            continue\n",
    "        else:\n",
    "            session_found = True\n",
    "            \n",
    "        # Recover data streams\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session_path = Path(session_path)\n",
    "    \n",
    "        print('\\n'+file_name)\n",
    "        parsed_session = MetricsVrForaging(session_path)\n",
    "        if parsed_session.stage == 'thermistor screening':\n",
    "            continue\n",
    "        \n",
    "        df = parsed_session.get_metrics()\n",
    "        df['trainer'] = trainer_dict[mouse]\n",
    "        df['session'] = parsed_session.session\n",
    "        df['stage'] = parsed_session.stage\n",
    "        df['rig'] = parsed_session.rig_name\n",
    "        df['mouse'] = mouse \n",
    "        \n",
    "        try:\n",
    "            simplified_stage = re.search(r'stage([A-Za-z])', parsed_session.stage).group(1)\n",
    "        except:\n",
    "            simplified_stage = parsed_session.stage\n",
    "            \n",
    "        df['simplified_stage'] = simplified_stage\n",
    "        \n",
    "        reward_sites = parsed_session.get_reward_sites()\n",
    "\n",
    "        if parsed_session.stage[:7] == 'shaping':\n",
    "            parsed_session.retrieve_updater_values()\n",
    "            print(\n",
    "            'Total sites travelled: ' + str(df.odor_sites_travelled.iloc[0]),\n",
    "            '\\nRewarded stops in max stop duration: ' + str(df.rewarded_sites_in_max_stop.iloc[0]),\n",
    "            '\\nTotal patches visited: ' + str(df.total_patches_visited.iloc[0]))\n",
    "\n",
    "        \n",
    "        pdf_filename = parsed_session.run_pdf_summary()\n",
    "        os.startfile(pdf_path+\"/\" + pdf_filename)\n",
    "        \n",
    "        reward_sites['mouse'] = mouse\n",
    "        reward_sites['session'] = parsed_session.session\n",
    "        reward_sites['stage'] = parsed_session.stage\n",
    "        reward_sites['simplified_stage'] = simplified_stage\n",
    "        odor_sites_sum = pd.concat([odor_sites_sum, reward_sites], axis=0)\n",
    "                \n",
    "    if session_found != True:\n",
    "        print('-----------------------------------')\n",
    "        print('Was not able to find the session for mouse: ', mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "def extract_middle_frame(video_path):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    mid_frame_idx = frame_count // 2\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, mid_frame_idx)\n",
    "    success, frame = cap.read()\n",
    "    cap.release()\n",
    "    if success:\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        return Image.fromarray(frame_rgb)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def collect_frames_from_folders(parent_folder):\n",
    "    parent_folder = Path(parent_folder)\n",
    "    frames = []\n",
    "\n",
    "    for subfolder in sorted(parent_folder.iterdir()):\n",
    "        if subfolder.is_dir():\n",
    "            videos = list(subfolder.glob(\"*.mp4\")) + list(subfolder.glob(\"*.avi\")) + list(subfolder.glob(\"*.mov\"))\n",
    "            if videos:\n",
    "                frame = extract_middle_frame(videos[0])\n",
    "                if frame:\n",
    "                    frames.append(frame)\n",
    "\n",
    "    return frames\n",
    "\n",
    "def save_combined_image(frames, output_path='combined3.png'):\n",
    "    widths, heights = zip(*(f.size for f in frames))\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    combined_image = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for frame in frames:\n",
    "        combined_image.paste(frame, (x_offset, 0))\n",
    "        x_offset += frame.width\n",
    "\n",
    "    combined_image.save(output_path)\n",
    "    print(f\"Saved combined image to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_list = trainer_dict.keys()\n",
    "\n",
    "summary_box_trainer  = {}\n",
    "date_string = \"2025-4-10\"\n",
    "date = parse.parse_user_date(date_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 123] The filename, directory name, or volume label syntax is incorrect: 'Z:\\\\scratch\\x0br-foraging\\\\data\\x0789909\\x0789909_2025-04-10T201248Z\\x08ehavior-videos'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\7\u001b[39;00m\u001b[33m89909\u001b[39m\u001b[38;5;130;01m\\7\u001b[39;00m\u001b[33m89909_2025-04-10T201248Z\u001b[39m\u001b[38;5;130;01m\\b\u001b[39;00m\u001b[33mehavior-videos\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     25\u001b[39m                  \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\7\u001b[39;00m\u001b[33m89926\u001b[39m\u001b[38;5;130;01m\\7\u001b[39;00m\u001b[33m89926_2025-04-12T190646Z\u001b[39m\u001b[38;5;130;01m\\b\u001b[39;00m\u001b[33mehavior-videos\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     26\u001b[39m                  \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\7\u001b[39;00m\u001b[33m89903\u001b[39m\u001b[38;5;130;01m\\7\u001b[39;00m\u001b[33m89903_2025-04-11T182605Z\u001b[39m\u001b[38;5;130;01m\\b\u001b[39;00m\u001b[33mehavior-videos\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     27\u001b[39m                  \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\7\u001b[39;00m\u001b[33m89924\u001b[39m\u001b[38;5;130;01m\\7\u001b[39;00m\u001b[33m89924_2025-04-11T182839Z\u001b[39m\u001b[38;5;130;01m\\b\u001b[39;00m\u001b[33mehavior-videos\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     28\u001b[39m     parent_folder = \u001b[33m\"\u001b[39m\u001b[33mZ:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mscratch\u001b[39m\u001b[38;5;130;01m\\v\u001b[39;00m\u001b[33mr-foraging\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m  + filename\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     frames = \u001b[43mcollect_frames_from_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     save_combined_image(frames, output_path=\u001b[33m'\u001b[39m\u001b[33mcombined4.png\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mcollect_frames_from_folders\u001b[39m\u001b[34m(parent_folder)\u001b[39m\n\u001b[32m     21\u001b[39m parent_folder = Path(parent_folder)\n\u001b[32m     22\u001b[39m frames = []\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m subfolder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(parent_folder.iterdir()):\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m subfolder.is_dir():\n\u001b[32m     26\u001b[39m         videos = \u001b[38;5;28mlist\u001b[39m(subfolder.glob(\u001b[33m\"\u001b[39m\u001b[33m*.mp4\u001b[39m\u001b[33m\"\u001b[39m)) + \u001b[38;5;28mlist\u001b[39m(subfolder.glob(\u001b[33m\"\u001b[39m\u001b[33m*.avi\u001b[39m\u001b[33m\"\u001b[39m)) + \u001b[38;5;28mlist\u001b[39m(subfolder.glob(\u001b[33m\"\u001b[39m\u001b[33m*.mov\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\pathlib.py:931\u001b[39m, in \u001b[36mPath.iterdir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    928\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Iterate over the files in this directory.  Does not yield any\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[33;03m    result for the special paths '.' and '..'.\u001b[39;00m\n\u001b[32m    930\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m os.listdir(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    932\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_child_relpath(name)\n",
      "\u001b[31mOSError\u001b[39m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'Z:\\\\scratch\\x0br-foraging\\\\data\\x0789909\\x0789909_2025-04-10T201248Z\\x08ehavior-videos'"
     ]
    }
   ],
   "source": [
    "for mouse in mouse_list:\n",
    "    session_found = False\n",
    "    directory = os.path.join(base_path, mouse)\n",
    "    files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "    sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "    # All this segment is to find the correct session without having the specific path\n",
    "    for file_name in sorted_files:\n",
    "        if session_found == True:\n",
    "            break\n",
    "        \n",
    "        session = parse.extract_and_convert_time(file_name)\n",
    "        if session != date:\n",
    "            continue\n",
    "        else:\n",
    "            session_found = True\n",
    "            \n",
    "        # Recover data streams\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session_path = Path(session_path)\n",
    "        \n",
    "# Example usage:\n",
    "for filename in ['\\789909\\789909_2025-04-10T201248Z\\behavior-videos', \n",
    "                 '\\789926\\789926_2025-04-12T190646Z\\behavior-videos',\n",
    "                 '\\789903\\789903_2025-04-11T182605Z\\behavior-videos',\n",
    "                 '\\789924\\789924_2025-04-11T182839Z\\behavior-videos']:\n",
    "    parent_folder = \"Z:\\scratch\\vr-foraging\\data\"  + filename\n",
    "    frames = collect_frames_from_folders(parent_folder)\n",
    "    save_combined_image(frames, output_path='combined4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined image to combined_5A.png\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m parent_folder = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mZ:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mscratch\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mvr-foraging\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m754574\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m754574_2025-04-14T162924Z\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbehavior-videos\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m frames = collect_frames_from_folders(parent_folder)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43msave_combined_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcombined_4C.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m parent_folder = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mZ:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mscratch\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mvr-foraging\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m789915\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m789915_2025-04-14T161154Z\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbehavior-videos\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m frames = collect_frames_from_folders(parent_folder)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36msave_combined_image\u001b[39m\u001b[34m(frames, output_path)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_combined_image\u001b[39m(frames, output_path=\u001b[33m'\u001b[39m\u001b[33mcombined3.png\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     widths, heights = \u001b[38;5;28mzip\u001b[39m(*(f.size \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m frames))\n\u001b[32m     36\u001b[39m     total_width = \u001b[38;5;28msum\u001b[39m(widths)\n\u001b[32m     37\u001b[39m     max_height = \u001b[38;5;28mmax\u001b[39m(heights)\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "parent_folder = r\"Z:\\scratch\\vr-foraging\\data\\789914\\789914_2025-04-12T175116Z\\behavior-videos\"\n",
    "frames = collect_frames_from_folders(parent_folder)\n",
    "save_combined_image(frames, output_path=f'combined_5A.png')\n",
    "\n",
    "parent_folder = r\"Z:\\scratch\\vr-foraging\\data\\754574\\754574_2025-04-14T162924Z\\behavior-videos\"\n",
    "frames = collect_frames_from_folders(parent_folder)\n",
    "save_combined_image(frames, output_path=f'combined_4C.png')\n",
    "\n",
    "parent_folder = r\"Z:\\scratch\\vr-foraging\\data\\789915\\789915_2025-04-14T161154Z\\behavior-videos\"\n",
    "frames = collect_frames_from_folders(parent_folder)\n",
    "save_combined_image(frames, output_path=f'combined_5B.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
