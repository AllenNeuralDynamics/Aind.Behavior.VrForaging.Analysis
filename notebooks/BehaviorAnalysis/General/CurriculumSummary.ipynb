{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from aind_vr_foraging_analysis.utils import parse, plotting_utils as plotting, AddExtraColumns\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "color1='#d95f02'\n",
    "color2='#1b9e77'\n",
    "color3='#7570b3'\n",
    "color4='yellow'\n",
    "odor_list_color = [color1, color2, color3, color4]\n",
    "\n",
    "pdf_path = r'Z:\\scratch\\vr-foraging\\sessions'\n",
    "base_path = 'Z:/scratch/vr-foraging/data/'\n",
    "foraging_figures = r'C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsVrForaging():\n",
    "    def __init__(self, session_path: PathLike):\n",
    "        self.session_path = Path(session_path)\n",
    "        self.data = parse.load_session_data(self.session_path)\n",
    "        self.session = self.data['config'].streams.session_input.data['date'][:10]\n",
    "        self.mouse = int(self.data['config'].streams.session_input.data['subject'])\n",
    "        self.stage = self.data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        self.rig_name = self.data['config'].streams.rig_input.data['rig_name']\n",
    "        self.experimenter = self.data['config'].streams.session_input.data['experimenter'][0]\n",
    "        \n",
    "        print(self.rig_name)\n",
    "        print(self.stage)\n",
    "        print(self.experimenter)\n",
    "        if self.stage == 'thermistor screening':\n",
    "            return\n",
    "        \n",
    "        self.data = parse.load_session_data(self.session_path)\n",
    "        self.stage = self.data['config'].streams.tasklogic_input.data['stage_name']\n",
    "\n",
    "        self.active_site = parse.parse_dataframe(self.data)\n",
    "        self.reward_sites = self.active_site.loc[self.active_site['label'] == 'OdorSite'].copy()\n",
    "        self.df = self.retrieve_metrics()\n",
    "\n",
    "    def retrieve_metrics(self) -> pd.DataFrame:\n",
    "        reward_sites = self.reward_sites\n",
    "        active_site = self.active_site\n",
    "        data = self.data\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        # Summary of different relevants aspects -------------------------------------------------\n",
    "\n",
    "        unrewarded_stops = reward_sites.loc[reward_sites.is_reward==0]['reward_amount'].count()\n",
    "        rewarded_stops = reward_sites.loc[reward_sites.is_reward==1]['reward_amount'].count()\n",
    "        water_collected = reward_sites.loc[(reward_sites['is_reward']==1)]['reward_amount'].sum()\n",
    "        total_stops = reward_sites.loc[(reward_sites['is_choice']==True)]['reward_amount'].count()\n",
    "\n",
    "        print('Total sites: ' ,len(reward_sites), ' | ', 'Total rewarded stops: ',rewarded_stops, '(',  np.round((rewarded_stops/total_stops)*100,2),'%) | ', \n",
    "            'Total unrewarded stops: ',unrewarded_stops,'(',  np.round((unrewarded_stops/total_stops)*100,2),'%) | ','Water consumed: ', water_collected, 'ul')\n",
    "\n",
    "        print('Total travelled m: ', np.round(active_site.start_position.max()/100,2), ', current position (cm): ', data['operation_control'].streams.CurrentPosition.data.max()[0]\n",
    "        )\n",
    "\n",
    "        for odor_label in reward_sites.odor_label.unique():\n",
    "            values = reward_sites.loc[(reward_sites['odor_label']==odor_label)&(reward_sites['is_reward']==1)]['reward_amount'].sum()\n",
    "            print(f'{odor_label} {values} ul')\n",
    "            \n",
    "        df.at[0,'odor_sites_travelled'] = int(len(reward_sites))\n",
    "        df.at[0,'distance_m'] = data['operation_control'].streams.CurrentPosition.data.max()[0]/100\n",
    "        df.at[0,'water_collected_ul'] = water_collected\n",
    "        df.at[0,'rewarded_stops'] = int(rewarded_stops)\n",
    "        df.at[0,'total_stops'] = int(total_stops)\n",
    "        df.at[0,'session_duration_min'] = (reward_sites.index[-1] - reward_sites.index[0])/60\n",
    "        df.at[0, 'total_patches_visited'] = reward_sites.loc[reward_sites['site_number'] >= 1].patch_number.nunique()\n",
    "        return df\n",
    "\n",
    "    def retrieve_updater_values(self):\n",
    "        # Initialize a pointer for the data values\n",
    "        data_pointer = 0\n",
    "        \n",
    "        reward_sites = self.reward_sites\n",
    "        data = self.data\n",
    "        df = self.df\n",
    "        \n",
    "        # Save the updater values\n",
    "        stop_duration = data['updater_events'].streams.UpdaterStopDurationOffset.data['data']\n",
    "        stop_duration.reset_index(drop=True, inplace=True)\n",
    "        delay = data['updater_events'].streams.UpdaterRewardDelayOffset.data['data']\n",
    "        delay.reset_index(drop=True, inplace=True)\n",
    "        velocity_threshold = data['updater_events'].streams.UpdaterStopVelocityThreshold.data['data']\n",
    "        velocity_threshold.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Create a new column in reward_sites to store the updated values\n",
    "        reward_sites['delay_s'] = None\n",
    "        reward_sites['velocity_threshold_cms'] = None\n",
    "        reward_sites['stop_duration_s'] = None\n",
    "\n",
    "        try:\n",
    "            # Iterate through each row of reward_sites\n",
    "            for index, row in reward_sites.iterrows():\n",
    "                if row['is_reward'] == 1:\n",
    "                    # Copy the next available value from data and move the pointer\n",
    "                    reward_sites.at[index, 'delay_s'] = delay[data_pointer]\n",
    "                    reward_sites.at[index, 'velocity_threshold_cms'] = velocity_threshold[data_pointer]\n",
    "                    reward_sites.at[index, 'stop_duration_s'] = stop_duration[data_pointer]\n",
    "                    data_pointer += 1\n",
    "                else:\n",
    "                    # Copy the same value without moving the pointer\n",
    "                    reward_sites.at[index, 'delay_s'] = delay[data_pointer]\n",
    "                    reward_sites.at[index, 'velocity_threshold_cms'] = velocity_threshold[data_pointer]\n",
    "                    reward_sites.at[index, 'stop_duration_s'] = stop_duration[data_pointer]\n",
    "        except KeyError:\n",
    "                reward_sites.at[index, 'delay_s'] = max(delay)\n",
    "                reward_sites.at[index, 'velocity_threshold_cms'] = max(velocity_threshold)\n",
    "                reward_sites.at[index, 'stop_duration_s'] = max(stop_duration)\n",
    "\n",
    "        # Summary of the training metrics\n",
    "        reward_sites['odor_sites'] = np.arange(1, len(reward_sites)+1)\n",
    "        df.at[0,'start_delay'] = reward_sites['delay_s'].min()\n",
    "        df.at[0,'end_delay'] = reward_sites['delay_s'].max()\n",
    "        df.at[0, 'sites_to_max_delay'] = reward_sites[reward_sites['delay_s'] == reward_sites['delay_s'].max()].iloc[0]['odor_sites']\n",
    "        df.at[0,'start_stop_duration'] = reward_sites['stop_duration_s'].min()\n",
    "        df.at[0,'end_stop_duration'] = reward_sites['stop_duration_s'].max()\n",
    "        df.at[0, 'sites_to_max_stop_duration'] = reward_sites[reward_sites['stop_duration_s'] == reward_sites['stop_duration_s'].max()].iloc[0]['odor_sites']\n",
    "        df.at[0, 'rewarded_sites_in_max_stop'] = int(reward_sites[(reward_sites['stop_duration_s'] == reward_sites['stop_duration_s'].max())&(reward_sites.is_choice == 1)]['odor_sites'].nunique())\n",
    "\n",
    "        df.at[0,'start_velocity_threshold'] = reward_sites['velocity_threshold_cms'].min()\n",
    "        df.at[0,'end_velocity_threshold'] = reward_sites['velocity_threshold_cms'].max()\n",
    "        df.at[0,'target_max_velocity_threshold'] = reward_sites['velocity_threshold_cms'].max()\n",
    "        df.at[0, 'sites_to_min_velocity'] = reward_sites[reward_sites['velocity_threshold_cms'] == reward_sites['velocity_threshold_cms'].min()].iloc[0]['odor_sites']\n",
    "            \n",
    "        self.reward_sites = reward_sites\n",
    "        self.df = df\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return self.df\n",
    "\n",
    "    def get_reward_sites(self):\n",
    "        return self.reward_sites\n",
    "    \n",
    "    def get_mouse_and_session(self):\n",
    "        return self.mouse, self.session\n",
    "    \n",
    "    def run_pdf_summary(self):\n",
    "        color1='#d95f02'\n",
    "        color2='#1b9e77'\n",
    "        color3='#7570b3'\n",
    "        color4='#e7298a'\n",
    "\n",
    "        color_dict_label = {'Ethyl Butyrate': color1, 'Alpha-pinene': color1, 'Amyl Acetate': color3, 'Eugenol' : color3,\n",
    "                            '2-Heptanone' : color2, 'Methyl Acetate': color1, 'Fenchone': color3, '2,3-Butanedione': color4, 'Methyl Butyrate': color2,}\n",
    "        \n",
    "        stream_data = parse.ContinuousData(self.data)\n",
    "        encoder_data = stream_data.encoder_data\n",
    "        odor_sites = AddExtraColumns(self.active_site).reward_sites\n",
    "        active_site = AddExtraColumns(self.active_site).all_epochs\n",
    "        active_site['duration_epoch'] = active_site.index.to_series().diff().shift(-1)\n",
    "        active_site['mouse'] = self.mouse\n",
    "        active_site['session'] = self.session\n",
    "        \n",
    "        # Remove segments where the mouse was disengaged\n",
    "        last_engaged_patch = odor_sites['patch_number'][odor_sites['skipped_count'] >= 10].min()\n",
    "        if pd.isna(last_engaged_patch):\n",
    "            last_engaged_patch = odor_sites['patch_number'].max()\n",
    "            \n",
    "        odor_sites['engaged'] = odor_sites['patch_number'] <= last_engaged_patch  \n",
    "    \n",
    "        \n",
    "        trial_summary = plotting.trial_collection(odor_sites[['is_choice', 'site_number', 'odor_label', 'odor_sites', 'is_reward','depleted',\n",
    "                                                                'reward_probability','reward_amount','reward_available']], \n",
    "                                                  encoder_data, \n",
    "                                                  self.mouse, \n",
    "                                                  self.session, \n",
    "                                                  window=(-1,3)\n",
    "                                                )\n",
    "    \n",
    "        # Save each figure to a separate page in the PDF\n",
    "        pdf_filename = f'{self.mouse}_{self.session}_summary.pdf'\n",
    "        with PdfPages(pdf_path+\"\\\\\"+pdf_filename) as pdf:\n",
    "            text1 = ('Mouse: ' + str(self.mouse) \n",
    "            + '\\nSession: ' + str(self.session) \n",
    "            + '\\nRig: ' + str(self.rig_name) \n",
    "            + '\\nStage: ' + str(self.stage)\n",
    "            + '\\nTotal sites: '  + str(self.df.total_stops.iloc[0]) \n",
    "            + '\\nTotal rewarded stops: ' + str(self.df.rewarded_stops.iloc[0]) + ' (' +str(np.round((self.df.rewarded_stops.iloc[0]/self.df.total_stops.iloc[0])*100,2)) + '%) \\n' \n",
    "            + 'Water consumed: ' +  str(np.round(self.df.water_collected_ul.iloc[0], 2)) + 'ul\\n' \n",
    "            + 'Session duration: ' + str(np.round(self.df.session_duration_min.iloc[0],2)) + 'min\\n' \n",
    "            + 'Total travelled m: ' + str(np.round(active_site.start_position.max()/100,2))\n",
    "            )\n",
    "            \n",
    "            # '(',  np.round((rewarded_stops/total_stops)*100,2),'%) | ', \n",
    "            text_to_figure = text1\n",
    "            if self.stage[:7] == 'shaping':\n",
    "                text2 = '\\nTotal sites travelled: ' + str(self.df.odor_sites_travelled.iloc[0]) + '\\nRewarded stops in max stop duration: ' + str(self.df.rewarded_sites_in_max_stop.iloc[0]) + '\\nTotal patches visited: ' + str(self.df.total_patches_visited.iloc[0])\n",
    "                text_to_figure = text1 + text2\n",
    "            \n",
    "            # Create a figure\n",
    "            fig, ax = plt.subplots(figsize=(8.5, 11))  # Standard letter size\n",
    "            ax.text(0.1, 0.9, text_to_figure, ha='left', va='center', fontsize=12)\n",
    "            ax.axis('off')  # Hide the axes\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # plotting.raster_with_velocity(active_site, stream_data, color_dict_label=color_dict_label, save=pdf)\n",
    "            plotting.segmented_raster_vertical(odor_sites, \n",
    "                                            self.data['config'].streams['tasklogic_input'].data, \n",
    "                                            save=pdf, \n",
    "                                            color_dict_label=color_dict_label)\n",
    "            plotting.summary_withinsession_values(odor_sites, \n",
    "                                    color_dict_label = color_dict_label, \n",
    "                                    save=pdf)\n",
    "            plotting.speed_traces_efficient(trial_summary, self.mouse, self.session,  save=pdf)\n",
    "            plotting.preward_estimates(odor_sites, \n",
    "                                    color_dict_label = color_dict_label, \n",
    "                                    save=pdf)\n",
    "            plotting.speed_traces_value(trial_summary, self.mouse, self.session, condition = 'reward_probability', save=pdf) \n",
    "            plotting.velocity_traces_odor_entry(trial_summary, max_range = trial_summary.speed.max(), color_dict_label=color_dict_label, save=pdf)\n",
    "\n",
    "            plotting.length_distributions(self.active_site, self.data, delay=True, save=pdf)\n",
    "            if self.stage[:7] == 'shaping':\n",
    "                plotting.update_values(self.reward_sites, save=pdf)\n",
    "            \n",
    "        return pdf_filename\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do it for several animals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_dict = {'745305': 'Olivia', \n",
    "                '745302': 'Olivia', \n",
    "                '754570': 'Olivia', \n",
    "                '754571': 'Olivia', \n",
    "                '754572' : 'Olivia', \n",
    "                '754582': 'Olivia',\n",
    "                '745300': 'Olivia',\n",
    "                '745301': 'Huy',\n",
    "                '754575': 'Huy',\n",
    "                '754573': 'Huy',\n",
    "                '754567': 'Huy',\n",
    "                '754579': 'Huy',\n",
    "                '745306': 'Huy',\n",
    "                '745307': 'Huy',\n",
    "                '754580': 'Katrina',\n",
    "                '754560': 'Katrina',\n",
    "                '754559': 'Katrina',\n",
    "                '754574': 'Katrina',\n",
    "                '754577': 'Katrina',\n",
    "                '754566': 'Katrina',\n",
    "}               \n",
    "\n",
    "# stage_progression = {'stageA_v1': 'Stage A',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_dict = {'789914': 'Katrina', \n",
    "                '789915': 'Katrina', \n",
    "                '789923': 'Katrina', \n",
    "                '789917' : 'Katrina', \n",
    "                '789909': 'Huy',\n",
    "                '789910': 'Huy',\n",
    "                '789911': 'Huy',\n",
    "                '789921': 'Huy',\n",
    "                '789918': 'Huy',\n",
    "                '789907': 'Olivia',\n",
    "                '789903': 'Olivia',\n",
    "                '789925': 'Olivia',\n",
    "                '789924': 'Olivia',\n",
    "                '789926': 'Olivia',\n",
    "}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_list = trainer_dict.keys()\n",
    "\n",
    "date_string = \"2025-4-2\"\n",
    "date = parse.parse_user_date(date_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "789914_2025-04-02T161519Z\n",
      "5A\n",
      "shaping_stageA_distanceA_stopA_v1\n",
      "Katrina\n",
      "Total sites:  159  |  Total rewarded stops:  145 ( 91.19 %) |  Total unrewarded stops:  14 ( 8.81 %) |  Water consumed:  725.0 ul\n",
      "Total travelled m:  61.29 , current position (cm):  6135.99414\n",
      "Amyl Acetate 725.0 ul\n",
      "Total sites travelled: 159.0 \n",
      "Rewarded stops in max stop duration: 1.0 \n",
      "Total patches visited: 1.0\n",
      "\n",
      "789915_2025-04-02T161252Z\n",
      "5B\n",
      "shaping_stageA_distanceA_stopA_v1\n",
      "Katrina\n",
      "Total sites:  365  |  Total rewarded stops:  193 ( 88.13 %) |  Total unrewarded stops:  172 ( 78.54 %) |  Water consumed:  965.0 ul\n",
      "Total travelled m:  248.65 , current position (cm):  24877.7031\n",
      "Amyl Acetate 965.0 ul\n",
      "Total sites travelled: 365.0 \n",
      "Rewarded stops in max stop duration: 31.0 \n",
      "Total patches visited: 30.0\n",
      "\n",
      "789923_2025-04-02T161404Z\n",
      "4B\n",
      "shaping_stageA_distanceA_stopA_v1\n",
      "Katrina\n",
      "Total sites:  177  |  Total rewarded stops:  161 ( 92.0 %) |  Total unrewarded stops:  16 ( 9.14 %) |  Water consumed:  805.0 ul\n",
      "Total travelled m:  69.34 , current position (cm):  6970.37207\n",
      "Amyl Acetate 805.0 ul\n",
      "Total sites travelled: 177.0 \n",
      "Rewarded stops in max stop duration: 1.0 \n",
      "Total patches visited: 1.0\n",
      "\n",
      "789917_2025-04-02T161418Z\n",
      "4C\n",
      "shaping_stageA_distanceA_stopA_v1\n",
      "Katrina\n",
      "Total sites:  107  |  Total rewarded stops:  93 ( 86.92 %) |  Total unrewarded stops:  14 ( 13.08 %) |  Water consumed:  465.0 ul\n",
      "Total travelled m:  41.6 , current position (cm):  4163.60156\n",
      "Amyl Acetate 465.0 ul\n",
      "Total sites travelled: 107.0 \n",
      "Rewarded stops in max stop duration: 1.0 \n",
      "Total patches visited: 1.0\n",
      "\n",
      "789909_2025-04-02T202432Z\n",
      "4A\n",
      "shaping_stageA_distanceA_stopA_v1\n",
      "Huy\n",
      "Total sites:  215  |  Total rewarded stops:  150 ( 89.29 %) |  Total unrewarded stops:  65 ( 38.69 %) |  Water consumed:  750.0 ul\n",
      "Total travelled m:  120.41 , current position (cm):  12058.7227\n",
      "Amyl Acetate 750.0 ul\n",
      "Total sites travelled: 215.0 \n",
      "Rewarded stops in max stop duration: 0.0 \n",
      "Total patches visited: 18.0\n",
      "\n",
      "789910_2025-04-02T202448Z\n",
      "4B\n",
      "shaping_stageA_distanceA_stopA_v1\n",
      "Huy\n",
      "Total sites:  404  |  Total rewarded stops:  169 ( 84.5 %) |  Total unrewarded stops:  235 ( 117.5 %) |  Water consumed:  845.0 ul\n",
      "Total travelled m:  309.41 , current position (cm):  30985.1367\n",
      "Amyl Acetate 845.0 ul\n",
      "Total sites travelled: 404.0 \n",
      "Rewarded stops in max stop duration: 23.0 \n",
      "Total patches visited: 36.0\n",
      "\n",
      "789921_2025-04-02T202523Z\n",
      "5A\n",
      "shaping_stageA_distanceA_stopA_v1\n",
      "Huy\n",
      "Total sites:  424  |  Total rewarded stops:  167 ( 90.76 %) |  Total unrewarded stops:  257 ( 139.67 %) |  Water consumed:  835.0 ul\n",
      "Total travelled m:  337.88 , current position (cm):  33835.1719\n",
      "Amyl Acetate 835.0 ul\n",
      "Total sites travelled: 424.0 \n",
      "Rewarded stops in max stop duration: 12.0 \n",
      "Total patches visited: 31.0\n",
      "\n",
      "789918_2025-04-02T203144Z\n",
      "5B\n",
      "shaping_stageA_distanceA_stopA_v1\n",
      "Huy\n",
      "Total sites:  345  |  Total rewarded stops:  154 ( 89.02 %) |  Total unrewarded stops:  191 ( 110.4 %) |  Water consumed:  770.0 ul\n",
      "Total travelled m:  258.05 , current position (cm):  25819.8184\n",
      "Amyl Acetate 770.0 ul\n",
      "Total sites travelled: 345.0 \n",
      "Rewarded stops in max stop duration: 0.0 \n",
      "Total patches visited: 41.0\n",
      "\n",
      "789907_2025-04-02T181535Z\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m session_path = Path(session_path)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m+file_name)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m parsed_session = \u001b[43mMetricsVrForaging\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m parsed_session.stage == \u001b[33m'\u001b[39m\u001b[33mthermistor screening\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mMetricsVrForaging.__init__\u001b[39m\u001b[34m(self, session_path)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, session_path: PathLike):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mself\u001b[39m.session_path = Path(session_path)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[43mparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_session_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mself\u001b[39m.session = \u001b[38;5;28mself\u001b[39m.data[\u001b[33m'\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m'\u001b[39m].streams.session_input.data[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m10\u001b[39m]\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mself\u001b[39m.mouse = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m.data[\u001b[33m'\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m'\u001b[39m].streams.session_input.data[\u001b[33m'\u001b[39m\u001b[33msubject\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\git\\Aind.Behavior.VrForaging.Analysis\\src\\aind_vr_foraging_analysis\\utils\\parse.py:613\u001b[39m, in \u001b[36mload_session_data\u001b[39m\u001b[34m(session_path)\u001b[39m\n\u001b[32m    607\u001b[39m HarpSniffsensor = data_io.reader_from_url(\n\u001b[32m    608\u001b[39m     \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/AllenNeuralDynamics/harp.device.sniff-detector/main/device.yml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m )\n\u001b[32m    610\u001b[39m HarpLickometer = data_io.reader_from_url(\n\u001b[32m    611\u001b[39m     \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/AllenNeuralDynamics/harp.device.lickety-split/main/device.yml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    612\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m HarpStepperDriver = \u001b[43mdata_io\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreader_from_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://raw.githubusercontent.com/harp-tech/device.stepperdriver/main/device.yml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    615\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    616\u001b[39m HarpEnvironmentSensor = data_io.reader_from_url(\n\u001b[32m    617\u001b[39m     \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/AllenNeuralDynamics/harp.device.environment-sensor/refs/heads/main/device.yml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    618\u001b[39m )\n\u001b[32m    620\u001b[39m session_path_behavior = session_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\git\\Aind.Behavior.VrForaging.Analysis\\src\\aind_vr_foraging_analysis\\data_io\\__init__.py:108\u001b[39m, in \u001b[36mreader_from_url\u001b[39m\u001b[34m(device_yml_url, base_path)\u001b[39m\n\u001b[32m    106\u001b[39m response = requests.get(device_yml_url)\n\u001b[32m    107\u001b[39m response.raise_for_status()\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m device = \u001b[43mread_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextIOWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m reg_readers = {\n\u001b[32m    110\u001b[39m     name: _create_register_parser(\n\u001b[32m    111\u001b[39m         device, name, _ReaderParams(base_path, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m device.registers.keys()\n\u001b[32m    114\u001b[39m }\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DeviceReader(device, reg_readers)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\git\\Aind.Behavior.VrForaging.Analysis\\.venv\\Lib\\site-packages\\harp\\schema.py:39\u001b[39m, in \u001b[36mread_schema\u001b[39m\u001b[34m(file, include_common_registers)\u001b[39m\n\u001b[32m     37\u001b[39m schema = parse_yaml_raw_as(Model, file.read())\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mWhoAmI\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m schema.registers \u001b[38;5;129;01mand\u001b[39;00m include_common_registers:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     common = \u001b[43m_read_common_registers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     schema.registers = \u001b[38;5;28mdict\u001b[39m(common.registers, **schema.registers)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m common.bitMasks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\git\\Aind.Behavior.VrForaging.Analysis\\.venv\\Lib\\site-packages\\harp\\schema.py:12\u001b[39m, in \u001b[36m_read_common_registers\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_common_registers\u001b[39m() -> Registers:\n\u001b[32m     11\u001b[39m     file = resources.files(__package__) / \u001b[33m\"\u001b[39m\u001b[33mcommon.yml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfileIO\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparse_yaml_raw_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRegisters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileIO\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "odor_sites_sum = pd.DataFrame()\n",
    "for mouse in mouse_list:\n",
    "    session_found = False\n",
    "\n",
    "    directory = os.path.join(base_path, mouse)\n",
    "    files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "    sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "    # All this segment is to find the correct session without having the specific path\n",
    "    for file_name in sorted_files:\n",
    "        if session_found == True:\n",
    "            break\n",
    "        \n",
    "        session = parse.extract_and_convert_time(file_name)\n",
    "        if session != date:\n",
    "            continue\n",
    "        else:\n",
    "            session_found = True\n",
    "            \n",
    "        # Recover data streams\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session_path = Path(session_path)\n",
    "    \n",
    "        print('\\n'+file_name)\n",
    "        parsed_session = MetricsVrForaging(session_path)\n",
    "        if parsed_session.stage == 'thermistor screening':\n",
    "            continue\n",
    "        \n",
    "        df = parsed_session.get_metrics()\n",
    "        df['trainer'] = trainer_dict[mouse]\n",
    "        df['session'] = parsed_session.session\n",
    "        df['stage'] = parsed_session.stage\n",
    "        df['rig'] = parsed_session.rig_name\n",
    "        df['mouse'] = mouse \n",
    "        \n",
    "        try:\n",
    "            simplified_stage = re.search(r'stage([A-Za-z])', parsed_session.stage).group(1)\n",
    "        except:\n",
    "            simplified_stage = parsed_session.stage\n",
    "            \n",
    "        df['simplified_stage'] = simplified_stage\n",
    "        \n",
    "        reward_sites = parsed_session.get_reward_sites()\n",
    "\n",
    "        if parsed_session.stage[:7] == 'shaping':\n",
    "            parsed_session.retrieve_updater_values()\n",
    "            print(\n",
    "            'Total sites travelled: ' + str(df.odor_sites_travelled.iloc[0]),\n",
    "            '\\nRewarded stops in max stop duration: ' + str(df.rewarded_sites_in_max_stop.iloc[0]),\n",
    "            '\\nTotal patches visited: ' + str(df.total_patches_visited.iloc[0]))\n",
    "\n",
    "        \n",
    "        pdf_filename = parsed_session.run_pdf_summary()\n",
    "        os.startfile(pdf_path+\"/\" + pdf_filename)\n",
    "        \n",
    "        reward_sites['mouse'] = mouse\n",
    "        reward_sites['session'] = parsed_session.session\n",
    "        reward_sites['stage'] = parsed_session.stage\n",
    "        reward_sites['simplified_stage'] = simplified_stage\n",
    "        odor_sites_sum = pd.concat([odor_sites_sum, reward_sites], axis=0)\n",
    "        if session_found != True:\n",
    "            print('-----------------------------------')\n",
    "            print('Was not able to find the session for mouse: ', mouse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
