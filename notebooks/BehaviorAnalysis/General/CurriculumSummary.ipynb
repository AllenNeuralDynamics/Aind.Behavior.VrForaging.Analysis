{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from os import PathLike\n",
    "import os\n",
    "\n",
    "from aind_vr_foraging_analysis.utils.parsing import parse, data_access\n",
    "import aind_vr_foraging_analysis.utils.plotting as plotting\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "color1='#d95f02'\n",
    "color2='#1b9e77'\n",
    "color3='#7570b3'\n",
    "color4='yellow'\n",
    "odor_list_color = [color1, color2, color3, color4]\n",
    "\n",
    "pdf_path = r'Z:\\scratch\\vr-foraging\\sessions'\n",
    "base_path = 'Z:/scratch/vr-foraging/data/'\n",
    "foraging_figures = r'C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign codes\n",
    "def get_condition_code(text):\n",
    "    if 'delayed' in text:\n",
    "        return 'D'\n",
    "    elif 'single' in text:\n",
    "        return 'S'\n",
    "    elif 'no_reward' in text or 'noreward' in text:\n",
    "        return 'N'\n",
    "    elif 'double' in text:\n",
    "        return 'Do'\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsVrForaging():\n",
    "    def __init__(self, session_path: PathLike):\n",
    "        self.session_path = session_path\n",
    "        self.active_site, self.stream_data, self.data = data_access.load_session(\n",
    "        session_path, extra=True\n",
    "        )\n",
    "        \n",
    "        self.reward_sites = self.active_site.loc[self.active_site['label'] == 'OdorSite']\n",
    "\n",
    "        utc = pytz.UTC\n",
    "        local_tz = pytz.timezone(\"America/Los_Angeles\")\n",
    "\n",
    "        utc_str = self.data['config'].streams.session_input.data['date']\n",
    "        utc_dt = datetime.fromisoformat(utc_str)        # full timestamp\n",
    "        local_dt = utc_dt.replace(tzinfo=utc).astimezone(local_tz)\n",
    "\n",
    "        self.session = str(local_dt.strftime(\"%Y-%m-%d_%H\"))  \n",
    "        self.mouse = int(self.data['config'].streams.session_input.data['subject'])\n",
    "        self.stage = self.data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        self.rig_name = self.data['config'].streams.rig_input.data['rig_name']\n",
    "        self.experimenter = self.data['config'].streams.session_input.data['experimenter'][0]\n",
    "        self.updaters = self.data['config'].streams.tasklogic_input.data['task_parameters']['updaters']\n",
    "\n",
    "        print(self.rig_name)\n",
    "        print(self.stage)\n",
    "        print(self.experimenter)\n",
    "        \n",
    "        if self.stage == 'thermistor screening':\n",
    "            return\n",
    "        \n",
    "        self.df = self.retrieve_metrics()\n",
    "\n",
    "    def retrieve_metrics(self) -> pd.DataFrame:\n",
    "        reward_sites = self.reward_sites\n",
    "        active_site = self.active_site\n",
    "        data = self.data\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        # Summary of different relevants aspects -------------------------------------------------\n",
    "\n",
    "        unrewarded_stops = reward_sites.loc[(reward_sites['is_choice']==1) & (reward_sites['is_reward']==0)]['reward_amount'].count()\n",
    "        rewarded_stops = reward_sites.loc[reward_sites.is_reward==1]['reward_amount'].count()\n",
    "        water_collected = reward_sites.loc[(reward_sites['is_reward']==1)]['reward_amount'].sum()\n",
    "        total_stops = reward_sites.loc[(reward_sites['is_choice']==True)]['reward_amount'].count()\n",
    "\n",
    "        print('Total sites: ' ,len(reward_sites), ' | ', 'Total rewarded stops: ',rewarded_stops, '(',  np.round((rewarded_stops/total_stops)*100,2),'%) | ', \n",
    "            'Total unrewarded stops: ',unrewarded_stops,'(',  np.round((unrewarded_stops/total_stops)*100,2),'%) | ','Water consumed: ', water_collected, 'ul')\n",
    "\n",
    "        print('Total travelled m: ', np.round(active_site.start_position.max()/100,2), ', current position (cm): ', data['operation_control'].streams.CurrentPosition.data.max()[0]\n",
    "        )\n",
    "\n",
    "        for odor_label in reward_sites.odor_label.unique():\n",
    "            values = reward_sites.loc[(reward_sites['odor_label']==odor_label)&(reward_sites['is_reward']==1)]['reward_amount'].sum()\n",
    "            print(f'{odor_label} {values} ul')\n",
    "            \n",
    "        df.at[0,'odor_sites_travelled'] = int(len(reward_sites))\n",
    "        df.at[0,'distance_m'] = data['operation_control'].streams.CurrentPosition.data.max()[0]/100\n",
    "        df.at[0,'water_collected_ul'] = water_collected\n",
    "        df.at[0,'rewarded_stops'] = int(rewarded_stops)\n",
    "        df.at[0,'total_stops'] = int(total_stops)\n",
    "        df.at[0,'session_duration_min'] = (reward_sites.index[-1] - reward_sites.index[0])/60\n",
    "        df.at[0, 'total_patches_visited'] = reward_sites.loc[reward_sites['site_number'] >= 1].patch_number.nunique()\n",
    "        return df\n",
    "\n",
    "    def retrieve_updater_values(self):\n",
    "        # Initialize a pointer for the data values\n",
    "        data_pointer = 0\n",
    "        \n",
    "        reward_sites = self.reward_sites\n",
    "        data = self.data\n",
    "        df = self.df\n",
    "        \n",
    "        # Helper function to safely extract stream data\n",
    "        def get_stream_data(data, key):\n",
    "            try:\n",
    "                stream = data['updater_events'].streams[key].data['data']\n",
    "                stream.reset_index(drop=True, inplace=True)\n",
    "                return stream\n",
    "            except (KeyError, AttributeError):\n",
    "                return None\n",
    "\n",
    "        # Load updater data safely\n",
    "        stop_duration = get_stream_data(data, 'UpdaterStopDurationOffset')\n",
    "        delay = get_stream_data(data, 'UpdaterRewardDelayOffset')\n",
    "        velocity_threshold = get_stream_data(data, 'UpdaterStopVelocityThreshold')\n",
    "\n",
    "        # Create new columns in reward_sites with default values\n",
    "        reward_sites['delay_s'] = np.nan\n",
    "        reward_sites['velocity_threshold_cms'] = np.nan\n",
    "        reward_sites['stop_duration_s'] = np.nan\n",
    "\n",
    "        data_pointer = 0\n",
    "        try:\n",
    "            for index, row in reward_sites.iterrows():\n",
    "                if row['is_reward'] == 1:\n",
    "                    if delay is not None and len(delay) > data_pointer:\n",
    "                        reward_sites.at[index, 'delay_s'] = delay[data_pointer]\n",
    "                    if velocity_threshold is not None and len(velocity_threshold) > data_pointer:\n",
    "                        reward_sites.at[index, 'velocity_threshold_cms'] = velocity_threshold[data_pointer]\n",
    "                    if stop_duration is not None and len(stop_duration) > data_pointer:\n",
    "                        reward_sites.at[index, 'stop_duration_s'] = stop_duration[data_pointer]\n",
    "                    data_pointer += 1\n",
    "                else:\n",
    "                    if delay is not None and len(delay) > data_pointer:\n",
    "                        reward_sites.at[index, 'delay_s'] = delay[data_pointer]\n",
    "                    if velocity_threshold is not None and len(velocity_threshold) > data_pointer:\n",
    "                        reward_sites.at[index, 'velocity_threshold_cms'] = velocity_threshold[data_pointer]\n",
    "                    if stop_duration is not None and len(stop_duration) > data_pointer:\n",
    "                        reward_sites.at[index, 'stop_duration_s'] = stop_duration[data_pointer]\n",
    "        except IndexError:\n",
    "            if delay is not None:\n",
    "                reward_sites.at[index, 'delay_s'] = delay.max()\n",
    "            if velocity_threshold is not None:\n",
    "                reward_sites.at[index, 'velocity_threshold_cms'] = velocity_threshold.max()\n",
    "            if stop_duration is not None:\n",
    "                reward_sites.at[index, 'stop_duration_s'] = stop_duration.max()\n",
    "\n",
    "        # Summary of the training metrics\n",
    "        reward_sites['odor_sites'] = np.arange(1, len(reward_sites) + 1)\n",
    "\n",
    "        # Safely update df only if values exist\n",
    "        if delay is not None:\n",
    "            df.at[0, 'start_delay'] = reward_sites['delay_s'].min()\n",
    "            df.at[0, 'end_delay'] = reward_sites['delay_s'].max()\n",
    "            df.at[0, 'sites_to_max_delay'] = reward_sites[reward_sites['delay_s'] == reward_sites['delay_s'].max()].iloc[0]['odor_sites']\n",
    "\n",
    "        if stop_duration is not None:\n",
    "            df.at[0, 'start_stop_duration'] = reward_sites['stop_duration_s'].min()\n",
    "            df.at[0, 'end_stop_duration'] = reward_sites['stop_duration_s'].max()\n",
    "            df.at[0, 'sites_to_max_stop_duration'] = reward_sites[reward_sites['stop_duration_s'] == reward_sites['stop_duration_s'].max()].iloc[0]['odor_sites']\n",
    "            df.at[0, 'rewarded_sites_in_max_stop'] = int(reward_sites[(reward_sites['stop_duration_s'] == reward_sites['stop_duration_s'].max()) & (reward_sites.is_choice == 1)]['odor_sites'].nunique())\n",
    "\n",
    "        if velocity_threshold is not None:\n",
    "            df.at[0, 'start_velocity_threshold'] = reward_sites['velocity_threshold_cms'].min()\n",
    "            df.at[0, 'end_velocity_threshold'] = reward_sites['velocity_threshold_cms'].max()\n",
    "            df.at[0, 'target_max_velocity_threshold'] = reward_sites['velocity_threshold_cms'].max()\n",
    "            df.at[0, 'sites_to_min_velocity'] = reward_sites[reward_sites['velocity_threshold_cms'] == reward_sites['velocity_threshold_cms'].min()].iloc[0]['odor_sites']\n",
    "            df.at[0, 'sites_to_max_velocity'] = reward_sites[reward_sites['velocity_threshold_cms'] == reward_sites['velocity_threshold_cms'].max()].iloc[0]['odor_sites']        \n",
    "        \n",
    "        self.reward_sites = reward_sites\n",
    "        self.df = df\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return self.df\n",
    "\n",
    "    def get_reward_sites(self):\n",
    "        return self.reward_sites\n",
    "    \n",
    "    def get_mouse_and_session(self):\n",
    "        return self.mouse, self.session\n",
    "    \n",
    "    def run_pdf_summary(self):\n",
    "        color1='#d95f02'\n",
    "        color2='#1b9e77'\n",
    "        color3='#7570b3'\n",
    "        color4='#e7298a'\n",
    "        color5 = 'yellow'\n",
    "        color6 = '#66a61e'\n",
    "        color7 = \"#1e8ba6\"\n",
    "        color8 = \"#a61e1e\"\n",
    "        color9 = \"#271ea6\"\n",
    "        color10 = \"#225c64\"\n",
    "\n",
    "        odor_sites = self.reward_sites.copy()\n",
    "        encoder_data = self.stream_data.encoder_data\n",
    "        active_site = self.active_site.copy()\n",
    "        \n",
    "        common_segments = {\n",
    "            'InterSite': '#808080',\n",
    "            'InterPatch': '#b3b3b3'\n",
    "            }\n",
    "        \n",
    "        colors = [color1, color2, color3, color4, color5, color6, color7, color8, color9, color10]\n",
    "        patches = odor_sites['patch_label'].unique()\n",
    "\n",
    "        color_dict_label = {\n",
    "            odor: colors[i]\n",
    "            for i, odor in enumerate(sorted(set(patches)))\n",
    "        }\n",
    "        \n",
    "        color_dict_label.update(common_segments)\n",
    "        \n",
    "        active_site['mouse'] = self.mouse\n",
    "        active_site['session'] = self.session\n",
    "        \n",
    "        # Apply function\n",
    "        active_site['long_patch_label'] = active_site['patch_label']\n",
    "        active_site['patch_label'] = active_site['patch_label'].apply(get_condition_code)\n",
    "        \n",
    "        # odor_sites['odor_label'] = odor_sites['odor_label'].str.replace(' ', '_')\n",
    "        \n",
    "        # Remove segments where the mouse was disengaged\n",
    "        last_engaged_patch = odor_sites['patch_number'][odor_sites['skipped_count'] >= 10].min()\n",
    "        if pd.isna(last_engaged_patch):\n",
    "            last_engaged_patch = odor_sites['patch_number'].max()\n",
    "            \n",
    "        odor_sites['engaged'] = odor_sites['patch_number'] <= last_engaged_patch  \n",
    "    \n",
    "        try:\n",
    "            odor_sites['block'] = odor_sites['patch_label'].str.extract(r'set(\\d+)').astype(int)\n",
    "        except ValueError: \n",
    "            odor_sites['block'] = 0\n",
    "\n",
    "        # Apply function\n",
    "        odor_sites['long_patch_label'] = odor_sites['patch_label']\n",
    "        odor_sites['patch_label'] = odor_sites['patch_label'].apply(get_condition_code)\n",
    "        \n",
    "        trial_summary = plotting.trial_collection(odor_sites, \n",
    "                                                  encoder_data, \n",
    "                                                  window=(-1,3)\n",
    "                                                )\n",
    "    \n",
    "        # Save each figure to a separate page in the PDF\n",
    "        pdf_filename = f'{self.mouse}_{self.session}_summary.pdf'\n",
    "        with PdfPages(pdf_path+\"\\\\\"+pdf_filename) as pdf:\n",
    "            text1 = ('Mouse: ' + str(self.mouse) \n",
    "            + '\\nSession: ' + str(self.session) \n",
    "            + '\\nRig: ' + str(self.rig_name) \n",
    "            + '\\nStage: ' + str(self.stage)\n",
    "            + '\\nTotal sites travelled: '  + str(self.df.odor_sites_travelled.iloc[0]) \n",
    "            + '\\nTotal choices: '  + str(self.df.total_stops.iloc[0]) \n",
    "            + '\\nTotal rewarded stops: ' + str(self.df.rewarded_stops.iloc[0]) + ' (' +str(np.round((self.df.rewarded_stops.iloc[0]/self.df.total_stops.iloc[0])*100,2)) + '%) \\n' \n",
    "            + 'Water consumed: ' +  str(np.round(self.df.water_collected_ul.iloc[0], 2)) + 'ul\\n' \n",
    "            + 'Session duration: ' + str(np.round(self.df.session_duration_min.iloc[0],2)) + 'min\\n' \n",
    "            + 'Total travelled m: ' + str(np.round(active_site.start_position.max()/100,2))\n",
    "            )\n",
    "            \n",
    "            # '(',  np.round((rewarded_stops/total_stops)*100,2),'%) | ', \n",
    "            text_to_figure = text1\n",
    "            # if self.stage[:7] == 'shaping':\n",
    "            #     text2 = '\\nTotal sites travelled: ' + str(self.df.odor_sites_travelled.iloc[0]) + '\\nRewarded stops in max stop duration: ' + str(self.df.rewarded_sites_in_max_stop.iloc[0]) + '\\nTotal patches visited: ' + str(self.df.total_patches_visited.iloc[0])\n",
    "            #     text_to_figure = text1 + text2\n",
    "            \n",
    "            # Create a figure\n",
    "            fig, ax = plt.subplots(figsize=(8.5, 11))  # Standard letter size\n",
    "            ax.text(0.1, 0.9, text_to_figure, ha='left', va='center', fontsize=12)\n",
    "            ax.axis('off')  # Hide the axes\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # plotting.raster_with_velocity(active_site, stream_data, color_dict_label=color_dict_label, save=pdf)\n",
    "            plotting.segmented_raster_vertical(odor_sites, \n",
    "                                            save=pdf, \n",
    "                                            color_dict_label=color_dict_label)\n",
    "            plotting.raster_with_velocity(active_site, self.stream_data, color_dict_label=color_dict_label, save=pdf)\n",
    "        \n",
    "            plotting.summary_withinsession_values(odor_sites, \n",
    "                                    color_dict_label = color_dict_label, \n",
    "                                    save=pdf)\n",
    "            plotting.speed_traces_efficient(trial_summary, self.mouse, self.session,  save=pdf)\n",
    "            plotting.preward_estimates(odor_sites, \n",
    "                                    color_dict_label = color_dict_label, \n",
    "                                    minimum_size=0,\n",
    "                                    save=pdf)\n",
    "            \n",
    "            plotting.speed_traces_value(trial_summary, self.mouse, self.session, condition = 'reward_probability', save=pdf) \n",
    "            plotting.velocity_traces_odor_entry(trial_summary, max_range = trial_summary.speed.max(), color_dict_label=color_dict_label, save=pdf)\n",
    "\n",
    "            plotting.length_distributions(self.active_site, self.data, delay=True, save=pdf)\n",
    "            if len(self.updaters):\n",
    "                plotting.update_values(self.reward_sites, save=pdf)\n",
    "            \n",
    "        return pdf_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do it for several animals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_dict = {\n",
    "                '808728': 'Olivia',\n",
    "                '808619': 'Olivia',\n",
    "                '794591': 'HUY',\n",
    "                '789909': 'Huy',\n",
    "                '789910': 'Huy',\n",
    "                '789911': 'Huy',\n",
    "                '788641': 'Huy',\n",
    "                '789918': 'Huy',\n",
    "                '789919': 'Huy',\n",
    "                '789907': 'Olivia',\n",
    "                '789903': 'Olivia',\n",
    "                '789925': 'Olivia',\n",
    "                '789924': 'Olivia',\n",
    "                '789926': 'Olivia',\n",
    "                '789908': 'Olivia',\n",
    "                '789914': 'Katrina', \n",
    "                '789915': 'Katrina', \n",
    "                '789923': 'Katrina', \n",
    "                '789917' : 'Katrina', \n",
    "                '789913' : 'Katrina', \n",
    "}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_dict = {\n",
    "                '828424': 'Pascha',\n",
    "                # '828426': 'Pascha',\n",
    "                # '828415': 'Pascha',\n",
    "                # '841306': 'Pascha',\n",
    "                # '818151': 'Huy',\n",
    "                # '818152' : 'Huy',\n",
    "                # '807093': 'Huy', \n",
    "                # '807086': 'Huy',\n",
    "                # '815102': 'Huy',\n",
    "                # '828420': 'Huy',\n",
    "                # '806527': 'Huy',\n",
    "                # '828417': 'Huy',\n",
    "                # '828418': 'Huy',\n",
    "                # '808729': 'Alex',\n",
    "                # '815104': 'Alex',\n",
    "                # '815103': 'Alex',\n",
    "                # '795133': 'Alex',\n",
    "                # '822683': 'Huy',\n",
    "                # '828423': 'Tiffany',\n",
    "                # '828425': \"Tiffany\",\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_list = trainer_dict.keys()\n",
    "# mouse_list = [\"715866\", \"713578\", \"707349\", \"716455\", \n",
    "#               \"716458\",\"715865\",\"715869\",\"713545\",\"715867\",\n",
    "#               \"715870\",\"694569\"]\n",
    "date_string = \"2026-02-12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odor_sites_sum = pd.DataFrame()\n",
    "for mouse in mouse_list:\n",
    "    print(\"# ---------------------------------------------------------------------\")\n",
    "    print(mouse)\n",
    "    session_paths = data_access.find_sessions_relative_to_date(\n",
    "        mouse=mouse,\n",
    "        date_string=date_string,\n",
    "        when='on_or_after',\n",
    "    )\n",
    "    \n",
    "    for session_path in session_paths:\n",
    "        print(session_path)\n",
    "        parsed_session = MetricsVrForaging(session_path)\n",
    "        if parsed_session.stage == 'thermistor screening':\n",
    "            continue\n",
    "        \n",
    "        df = parsed_session.get_metrics()\n",
    "        df['trainer'] = trainer_dict[mouse]\n",
    "        df['session'] = parsed_session.session\n",
    "        df['stage'] = parsed_session.stage\n",
    "        df['rig'] = parsed_session.rig_name\n",
    "        df['mouse'] = mouse \n",
    "        \n",
    "        try:\n",
    "            simplified_stage = re.search(r'stage([A-Za-z])', parsed_session.stage).group(1)\n",
    "        except:\n",
    "            simplified_stage = parsed_session.stage\n",
    "            \n",
    "        df['simplified_stage'] = simplified_stage\n",
    "        \n",
    "        reward_sites = parsed_session.get_reward_sites()\n",
    "\n",
    "        if len(parsed_session.updaters) != 0:\n",
    "            parsed_session.retrieve_updater_values()\n",
    "            print(\n",
    "            'Total sites travelled: ' + str(df.odor_sites_travelled.iloc[0]),\n",
    "            '\\nRewarded stops in max stop duration: ' + str(df.rewarded_sites_in_max_stop.iloc[0]),\n",
    "            '\\nTotal patches visited: ' + str(df.total_patches_visited.iloc[0]))\n",
    "\n",
    "        pdf_filename = parsed_session.run_pdf_summary()\n",
    "\n",
    "        os.startfile(pdf_path+\"/\" + pdf_filename)\n",
    "        \n",
    "        reward_sites['mouse'] = mouse\n",
    "        reward_sites['session'] = parsed_session.session\n",
    "        reward_sites['stage'] = parsed_session.stage\n",
    "        reward_sites['simplified_stage'] = simplified_stage\n",
    "        odor_sites_sum = pd.concat([odor_sites_sum, reward_sites], axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aind.Behavior.VrForaging.Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
