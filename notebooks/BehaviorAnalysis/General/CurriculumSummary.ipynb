{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from os import PathLike\n",
    "import os\n",
    "\n",
    "from aind_vr_foraging_analysis.utils.parsing import parse, data_access\n",
    "import aind_vr_foraging_analysis.utils.plotting as plotting\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "color1='#d95f02'\n",
    "color2='#1b9e77'\n",
    "color3='#7570b3'\n",
    "color4='yellow'\n",
    "odor_list_color = [color1, color2, color3, color4]\n",
    "\n",
    "pdf_path = r'Z:\\scratch\\vr-foraging\\sessions'\n",
    "base_path = 'Z:/scratch/vr-foraging/data/'\n",
    "foraging_figures = r'C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign codes\n",
    "def get_condition_code(text):\n",
    "    if 'delayed' in text:\n",
    "        return 'D'\n",
    "    elif 'single' in text:\n",
    "        return 'S'\n",
    "    elif 'no_reward' in text or 'noreward' in text:\n",
    "        return 'N'\n",
    "    elif 'double' in text:\n",
    "        return 'Do'\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsVrForaging():\n",
    "    def __init__(self, session_path: PathLike):\n",
    "        self.session_path = session_path\n",
    "        self.active_site, self.stream_data, self.data = data_access.load_session(\n",
    "        session_path\n",
    "        )\n",
    "        \n",
    "        self.reward_sites = self.active_site.loc[self.active_site['label'] == 'OdorSite']\n",
    "        self.session = self.data['config'].streams.session_input.data['date'][:10]\n",
    "        self.mouse = int(self.data['config'].streams.session_input.data['subject'])\n",
    "        self.stage = self.data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        self.rig_name = self.data['config'].streams.rig_input.data['rig_name']\n",
    "        self.experimenter = self.data['config'].streams.session_input.data['experimenter'][0]\n",
    "        self.updaters = self.data['config'].streams.tasklogic_input.data['task_parameters']['updaters']\n",
    "\n",
    "        print(self.rig_name)\n",
    "        print(self.stage)\n",
    "        print(self.experimenter)\n",
    "        \n",
    "        if self.stage == 'thermistor screening':\n",
    "            return\n",
    "        \n",
    "        self.df = self.retrieve_metrics()\n",
    "\n",
    "    def retrieve_metrics(self) -> pd.DataFrame:\n",
    "        reward_sites = self.reward_sites\n",
    "        active_site = self.active_site\n",
    "        data = self.data\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        # Summary of different relevants aspects -------------------------------------------------\n",
    "\n",
    "        unrewarded_stops = reward_sites.loc[reward_sites.is_reward==0]['reward_amount'].count()\n",
    "        rewarded_stops = reward_sites.loc[reward_sites.is_reward==1]['reward_amount'].count()\n",
    "        water_collected = reward_sites.loc[(reward_sites['is_reward']==1)]['reward_amount'].sum()\n",
    "        total_stops = reward_sites.loc[(reward_sites['is_choice']==True)]['reward_amount'].count()\n",
    "\n",
    "        print('Total sites: ' ,len(reward_sites), ' | ', 'Total rewarded stops: ',rewarded_stops, '(',  np.round((rewarded_stops/total_stops)*100,2),'%) | ', \n",
    "            'Total unrewarded stops: ',unrewarded_stops,'(',  np.round((unrewarded_stops/total_stops)*100,2),'%) | ','Water consumed: ', water_collected, 'ul')\n",
    "\n",
    "        print('Total travelled m: ', np.round(active_site.start_position.max()/100,2), ', current position (cm): ', data['operation_control'].streams.CurrentPosition.data.max()[0]\n",
    "        )\n",
    "\n",
    "        for odor_label in reward_sites.odor_label.unique():\n",
    "            values = reward_sites.loc[(reward_sites['odor_label']==odor_label)&(reward_sites['is_reward']==1)]['reward_amount'].sum()\n",
    "            print(f'{odor_label} {values} ul')\n",
    "            \n",
    "        df.at[0,'odor_sites_travelled'] = int(len(reward_sites))\n",
    "        df.at[0,'distance_m'] = data['operation_control'].streams.CurrentPosition.data.max()[0]/100\n",
    "        df.at[0,'water_collected_ul'] = water_collected\n",
    "        df.at[0,'rewarded_stops'] = int(rewarded_stops)\n",
    "        df.at[0,'total_stops'] = int(total_stops)\n",
    "        df.at[0,'session_duration_min'] = (reward_sites.index[-1] - reward_sites.index[0])/60\n",
    "        df.at[0, 'total_patches_visited'] = reward_sites.loc[reward_sites['site_number'] >= 1].patch_number.nunique()\n",
    "        return df\n",
    "\n",
    "    def retrieve_updater_values(self):\n",
    "        # Initialize a pointer for the data values\n",
    "        data_pointer = 0\n",
    "        \n",
    "        reward_sites = self.reward_sites\n",
    "        data = self.data\n",
    "        df = self.df\n",
    "        \n",
    "        # Helper function to safely extract stream data\n",
    "        def get_stream_data(data, key):\n",
    "            try:\n",
    "                stream = data['updater_events'].streams[key].data['data']\n",
    "                stream.reset_index(drop=True, inplace=True)\n",
    "                return stream\n",
    "            except (KeyError, AttributeError):\n",
    "                return None\n",
    "\n",
    "        # Load updater data safely\n",
    "        stop_duration = get_stream_data(data, 'UpdaterStopDurationOffset')\n",
    "        delay = get_stream_data(data, 'UpdaterRewardDelayOffset')\n",
    "        velocity_threshold = get_stream_data(data, 'UpdaterStopVelocityThreshold')\n",
    "\n",
    "        print(stop_duration)\n",
    "        # Create new columns in reward_sites with default values\n",
    "        reward_sites['delay_s'] = np.nan\n",
    "        reward_sites['velocity_threshold_cms'] = np.nan\n",
    "        reward_sites['stop_duration_s'] = np.nan\n",
    "\n",
    "        data_pointer = 0\n",
    "        try:\n",
    "            for index, row in reward_sites.iterrows():\n",
    "                if row['is_reward'] == 1:\n",
    "                    if delay is not None and len(delay) > data_pointer:\n",
    "                        reward_sites.at[index, 'delay_s'] = delay[data_pointer]\n",
    "                    if velocity_threshold is not None and len(velocity_threshold) > data_pointer:\n",
    "                        reward_sites.at[index, 'velocity_threshold_cms'] = velocity_threshold[data_pointer]\n",
    "                    if stop_duration is not None and len(stop_duration) > data_pointer:\n",
    "                        reward_sites.at[index, 'stop_duration_s'] = stop_duration[data_pointer]\n",
    "                    data_pointer += 1\n",
    "                else:\n",
    "                    if delay is not None and len(delay) > data_pointer:\n",
    "                        reward_sites.at[index, 'delay_s'] = delay[data_pointer]\n",
    "                    if velocity_threshold is not None and len(velocity_threshold) > data_pointer:\n",
    "                        reward_sites.at[index, 'velocity_threshold_cms'] = velocity_threshold[data_pointer]\n",
    "                    if stop_duration is not None and len(stop_duration) > data_pointer:\n",
    "                        reward_sites.at[index, 'stop_duration_s'] = stop_duration[data_pointer]\n",
    "        except IndexError:\n",
    "            if delay is not None:\n",
    "                reward_sites.at[index, 'delay_s'] = delay.max()\n",
    "            if velocity_threshold is not None:\n",
    "                reward_sites.at[index, 'velocity_threshold_cms'] = velocity_threshold.max()\n",
    "            if stop_duration is not None:\n",
    "                reward_sites.at[index, 'stop_duration_s'] = stop_duration.max()\n",
    "\n",
    "        # Summary of the training metrics\n",
    "        reward_sites['odor_sites'] = np.arange(1, len(reward_sites) + 1)\n",
    "\n",
    "        # Safely update df only if values exist\n",
    "        if delay is not None:\n",
    "            df.at[0, 'start_delay'] = reward_sites['delay_s'].min()\n",
    "            df.at[0, 'end_delay'] = reward_sites['delay_s'].max()\n",
    "            df.at[0, 'sites_to_max_delay'] = reward_sites[reward_sites['delay_s'] == reward_sites['delay_s'].max()].iloc[0]['odor_sites']\n",
    "\n",
    "        if stop_duration is not None:\n",
    "            df.at[0, 'start_stop_duration'] = reward_sites['stop_duration_s'].min()\n",
    "            df.at[0, 'end_stop_duration'] = reward_sites['stop_duration_s'].max()\n",
    "            df.at[0, 'sites_to_max_stop_duration'] = reward_sites[reward_sites['stop_duration_s'] == reward_sites['stop_duration_s'].max()].iloc[0]['odor_sites']\n",
    "            df.at[0, 'rewarded_sites_in_max_stop'] = int(reward_sites[(reward_sites['stop_duration_s'] == reward_sites['stop_duration_s'].max()) & (reward_sites.is_choice == 1)]['odor_sites'].nunique())\n",
    "\n",
    "        if velocity_threshold is not None:\n",
    "            df.at[0, 'start_velocity_threshold'] = reward_sites['velocity_threshold_cms'].min()\n",
    "            df.at[0, 'end_velocity_threshold'] = reward_sites['velocity_threshold_cms'].max()\n",
    "            df.at[0, 'target_max_velocity_threshold'] = reward_sites['velocity_threshold_cms'].max()\n",
    "            df.at[0, 'sites_to_min_velocity'] = reward_sites[reward_sites['velocity_threshold_cms'] == reward_sites['velocity_threshold_cms'].min()].iloc[0]['odor_sites']\n",
    "            df.at[0, 'sites_to_max_velocity'] = reward_sites[reward_sites['velocity_threshold_cms'] == reward_sites['velocity_threshold_cms'].max()].iloc[0]['odor_sites']        \n",
    "        \n",
    "        self.reward_sites = reward_sites\n",
    "        self.df = df\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return self.df\n",
    "\n",
    "    def get_reward_sites(self):\n",
    "        return self.reward_sites\n",
    "    \n",
    "    def get_mouse_and_session(self):\n",
    "        return self.mouse, self.session\n",
    "    \n",
    "    def run_pdf_summary(self):\n",
    "        color1='#d95f02'\n",
    "        color2='#1b9e77'\n",
    "        color3='#7570b3'\n",
    "        color4='#e7298a'\n",
    "\n",
    "        color_dict_label = {'InterSite': '#808080',\n",
    "            'InterPatch': '#b3b3b3', \n",
    "            'PatchZA': '#d95f02', 'PatchZB': '#d95f02', \n",
    "            'PatchB': '#d95f02','PatchA': '#7570b3', \n",
    "            'PatchC': '#1b9e77',\n",
    "            'Alpha-pinene': '#1b9e77', \n",
    "            'Methyl Butyrate': '#7570b3', \n",
    "            'Amyl Acetate': '#d95f02', \n",
    "            'Fenchone': '#7570b3', \n",
    "            'S': color1,\n",
    "            'D': color2,\n",
    "            'N': color3,   \n",
    "            'Do': color1,\n",
    "            'None': color4\n",
    "            }\n",
    "        \n",
    "        odor_sites = self.reward_sites.copy()\n",
    "        encoder_data = self.stream_data.encoder_data\n",
    "        active_site = self.active_site.copy()\n",
    "        \n",
    "        active_site['mouse'] = self.mouse\n",
    "        active_site['session'] = self.session\n",
    "        \n",
    "        # Apply function\n",
    "        active_site['long_patch_label'] = active_site['patch_label']\n",
    "        active_site['patch_label'] = active_site['patch_label'].apply(get_condition_code)\n",
    "        \n",
    "        # odor_sites['odor_label'] = odor_sites['odor_label'].str.replace(' ', '_')\n",
    "        \n",
    "        # Remove segments where the mouse was disengaged\n",
    "        last_engaged_patch = odor_sites['patch_number'][odor_sites['skipped_count'] >= 10].min()\n",
    "        if pd.isna(last_engaged_patch):\n",
    "            last_engaged_patch = odor_sites['patch_number'].max()\n",
    "            \n",
    "        odor_sites['engaged'] = odor_sites['patch_number'] <= last_engaged_patch  \n",
    "    \n",
    "        try:\n",
    "            odor_sites['block'] = odor_sites['patch_label'].str.extract(r'set(\\d+)').astype(int)\n",
    "        except ValueError: \n",
    "            odor_sites['block'] = 0\n",
    "\n",
    "        # Apply function\n",
    "        odor_sites['long_patch_label'] = odor_sites['patch_label']\n",
    "        odor_sites['patch_label'] = odor_sites['patch_label'].apply(get_condition_code)\n",
    "        \n",
    "        trial_summary = plotting.trial_collection(odor_sites[['is_choice', 'site_number', 'odor_label', 'depleted', 'odor_sites', 'is_reward','reward_probability','reward_amount','reward_available']], \n",
    "                                                  encoder_data, \n",
    "                                                  window=(-1,3)\n",
    "                                                )\n",
    "    \n",
    "        # Save each figure to a separate page in the PDF\n",
    "        pdf_filename = f'{self.mouse}_{self.session}_summary.pdf'\n",
    "        with PdfPages(pdf_path+\"\\\\\"+pdf_filename) as pdf:\n",
    "            text1 = ('Mouse: ' + str(self.mouse) \n",
    "            + '\\nSession: ' + str(self.session) \n",
    "            + '\\nRig: ' + str(self.rig_name) \n",
    "            + '\\nStage: ' + str(self.stage)\n",
    "            + '\\nTotal sites: '  + str(self.df.total_stops.iloc[0]) \n",
    "            + '\\nTotal rewarded stops: ' + str(self.df.rewarded_stops.iloc[0]) + ' (' +str(np.round((self.df.rewarded_stops.iloc[0]/self.df.total_stops.iloc[0])*100,2)) + '%) \\n' \n",
    "            + 'Water consumed: ' +  str(np.round(self.df.water_collected_ul.iloc[0], 2)) + 'ul\\n' \n",
    "            + 'Session duration: ' + str(np.round(self.df.session_duration_min.iloc[0],2)) + 'min\\n' \n",
    "            + 'Total travelled m: ' + str(np.round(active_site.start_position.max()/100,2))\n",
    "            )\n",
    "            \n",
    "            # '(',  np.round((rewarded_stops/total_stops)*100,2),'%) | ', \n",
    "            text_to_figure = text1\n",
    "            if self.stage[:7] == 'shaping':\n",
    "                text2 = '\\nTotal sites travelled: ' + str(self.df.odor_sites_travelled.iloc[0]) + '\\nRewarded stops in max stop duration: ' + str(self.df.rewarded_sites_in_max_stop.iloc[0]) + '\\nTotal patches visited: ' + str(self.df.total_patches_visited.iloc[0])\n",
    "                text_to_figure = text1 + text2\n",
    "            \n",
    "            # Create a figure\n",
    "            fig, ax = plt.subplots(figsize=(8.5, 11))  # Standard letter size\n",
    "            ax.text(0.1, 0.9, text_to_figure, ha='left', va='center', fontsize=12)\n",
    "            ax.axis('off')  # Hide the axes\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # plotting.raster_with_velocity(active_site, stream_data, color_dict_label=color_dict_label, save=pdf)\n",
    "            plotting.segmented_raster_vertical(odor_sites, \n",
    "                                            save=pdf, \n",
    "                                            color_dict_label=color_dict_label)\n",
    "            plotting.raster_with_velocity(active_site, self.stream_data, color_dict_label=color_dict_label, save=pdf)\n",
    "        \n",
    "            plotting.summary_withinsession_values(odor_sites, \n",
    "                                    color_dict_label = color_dict_label, \n",
    "                                    save=pdf)\n",
    "            plotting.speed_traces_efficient(trial_summary, self.mouse, self.session,  save=pdf)\n",
    "            plotting.preward_estimates(odor_sites, \n",
    "                                    color_dict_label = color_dict_label, \n",
    "                                    save=pdf)\n",
    "            plotting.speed_traces_value(trial_summary, self.mouse, self.session, condition = 'reward_probability', save=pdf) \n",
    "            plotting.velocity_traces_odor_entry(trial_summary, max_range = trial_summary.speed.max(), color_dict_label=color_dict_label, save=pdf)\n",
    "\n",
    "            plotting.length_distributions(self.active_site, self.data, delay=True, save=pdf)\n",
    "            if len(self.updaters):\n",
    "                plotting.update_values(self.reward_sites, save=pdf)\n",
    "            \n",
    "        return pdf_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do it for several animals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_dict = {'745305': 'Olivia', \n",
    "                '745302': 'Olivia', \n",
    "                '754570': 'Olivia', \n",
    "                '754571': 'Olivia', \n",
    "                '754572' : 'Olivia', \n",
    "                '754582': 'Olivia',\n",
    "                '745300': 'Olivia',\n",
    "                '745301': 'Huy',\n",
    "                '754575': 'Huy',\n",
    "                '754573': 'Huy',\n",
    "                '754567': 'Huy',\n",
    "                '754579': 'Huy',\n",
    "                '745306': 'Huy',\n",
    "                '745307': 'Huy',\n",
    "                '754580': 'Katrina',\n",
    "                '754560': 'Katrina',\n",
    "                '754559': 'Katrina',\n",
    "                '754574': 'Katrina',\n",
    "                '754577': 'Katrina',\n",
    "                '754566': 'Katrina',\n",
    "}               \n",
    "\n",
    "# stage_progression = {'stageA_v1': 'Stage A',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_dict = {\n",
    "                '789909': 'Huy',\n",
    "                '789910': 'Huy',\n",
    "                '789911': 'Huy',\n",
    "                '788641': 'Huy',\n",
    "                '789918': 'Huy',\n",
    "                '789919': 'Huy',\n",
    "                '789907': 'Olivia',\n",
    "                '789903': 'Olivia',\n",
    "                '789925': 'Olivia',\n",
    "                '789924': 'Olivia',\n",
    "                '789926': 'Olivia',\n",
    "                '789908': 'Olivia',\n",
    "                '754574': 'Katrina',\n",
    "                '789914': 'Katrina', \n",
    "                '789915': 'Katrina', \n",
    "                '789923': 'Katrina', \n",
    "                '789917' : 'Katrina', \n",
    "                '789913' : 'Katrina', \n",
    "                '781896': 'Jason',\n",
    "                '781898': 'Jason',\n",
    "}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_list = trainer_dict.keys()\n",
    "# mouse_list = [\"715866\", \"713578\", \"707349\", \"716455\", \n",
    "#               \"716458\",\"715865\",\"715869\",\"713545\",\"715867\",\n",
    "#               \"715870\",\"694569\"]\n",
    "date_string = \"2025-6-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ---------------------------------------------------------------------\n",
      "789909\n",
      "4A\n",
      "learning_task_set3\n",
      "Tiffany\n",
      "Total sites:  363  |  Total rewarded stops:  135 ( 81.33 %) |  Total unrewarded stops:  228 ( 137.35 %) |  Water consumed:  810.0 ul\n",
      "Total travelled m:  781.38 , current position (cm):  78345.6328\n",
      "Fenchone 426.0 ul\n",
      "Alpha-pinene 384.0 ul\n",
      "Methyl Butyrate 0.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789910\n",
      "5A\n",
      "learning_task_set3\n",
      "Tiffany\n",
      "Total sites:  264  |  Total rewarded stops:  121 ( 69.94 %) |  Total unrewarded stops:  143 ( 82.66 %) |  Water consumed:  726.0 ul\n",
      "Total travelled m:  429.21 , current position (cm):  42952.0\n",
      "Fenchone 534.0 ul\n",
      "Alpha-pinene 192.0 ul\n",
      "Methyl Butyrate 0.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789911\n",
      "4C\n",
      "distance_long\n",
      "Tiffany\n",
      "Total sites:  423  |  Total rewarded stops:  191 ( 50.53 %) |  Total unrewarded stops:  232 ( 61.38 %) |  Water consumed:  955.0 ul\n",
      "Total travelled m:  622.72 , current position (cm):  62384.9883\n",
      "Fenchone 790.0 ul\n",
      "Alpha-pinene 165.0 ul\n",
      "Methyl Butyrate 0.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "788641\n",
      "4B\n",
      "shaping_stageB_distanceD_stopE_probB\n",
      "Tiffany\n",
      "Total sites:  263  |  Total rewarded stops:  153 ( 74.63 %) |  Total unrewarded stops:  110 ( 53.66 %) |  Water consumed:  765.0 ul\n",
      "Total travelled m:  416.06 , current position (cm):  41622.6992\n",
      "Methyl Butyrate 765.0 ul\n",
      "0      0.406\n",
      "1      0.409\n",
      "2      0.412\n",
      "3      0.415\n",
      "4      0.418\n",
      "       ...  \n",
      "221    0.500\n",
      "222    0.500\n",
      "223    0.500\n",
      "224    0.500\n",
      "225    0.500\n",
      "Name: data, Length: 226, dtype: float64\n",
      "Total sites travelled: 263.0 \n",
      "Rewarded stops in max stop duration: 169.0 \n",
      "Total patches visited: 30.0\n",
      "# ---------------------------------------------------------------------\n",
      "789918\n",
      "5B\n",
      "distance_long\n",
      "Tiffany\n",
      "Total sites:  397  |  Total rewarded stops:  175 ( 50.29 %) |  Total unrewarded stops:  222 ( 63.79 %) |  Water consumed:  875.0 ul\n",
      "Total travelled m:  618.37 , current position (cm):  62112.5469\n",
      "Fenchone 590.0 ul\n",
      "Amyl Acetate 0.0 ul\n",
      "Alpha-pinene 285.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789919\n",
      "4D\n",
      "distance_short\n",
      "Tiffany\n",
      "Total sites:  473  |  Total rewarded stops:  196 ( 52.69 %) |  Total unrewarded stops:  277 ( 74.46 %) |  Water consumed:  980.0 ul\n",
      "Total travelled m:  663.13 , current position (cm):  66338.3203\n",
      "Fenchone 585.0 ul\n",
      "Alpha-pinene 395.0 ul\n",
      "Amyl Acetate 0.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789907\n",
      "4C\n",
      "learning_task_set3\n",
      "Tiffany\n",
      "Total sites:  412  |  Total rewarded stops:  190 ( 82.61 %) |  Total unrewarded stops:  222 ( 96.52 %) |  Water consumed:  1140.0 ul\n",
      "Total travelled m:  769.32 , current position (cm):  77004.7734\n",
      "Fenchone 780.0 ul\n",
      "Alpha-pinene 360.0 ul\n",
      "Methyl Butyrate 0.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789903\n",
      "4B\n",
      "learning_task_set3\n",
      "Tiffany\n",
      "Total sites:  378  |  Total rewarded stops:  154 ( 70.32 %) |  Total unrewarded stops:  224 ( 102.28 %) |  Water consumed:  924.0 ul\n",
      "Total travelled m:  677.74 , current position (cm):  67810.125\n",
      "Alpha-pinene 96.0 ul\n",
      "Fenchone 828.0 ul\n",
      "Methyl Butyrate 0.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789925\n",
      "4A\n",
      "learning_task_set3\n",
      "Tiffany\n",
      "Total sites:  369  |  Total rewarded stops:  135 ( 74.18 %) |  Total unrewarded stops:  234 ( 128.57 %) |  Water consumed:  810.0 ul\n",
      "Total travelled m:  747.2 , current position (cm):  74967.5781\n",
      "Methyl Butyrate 0.0 ul\n",
      "Fenchone 624.0 ul\n",
      "Alpha-pinene 186.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789924\n",
      "5B\n",
      "learning_task_set3\n",
      "Tiffany\n",
      "Total sites:  308  |  Total rewarded stops:  133 ( 73.89 %) |  Total unrewarded stops:  175 ( 97.22 %) |  Water consumed:  798.0 ul\n",
      "Total travelled m:  552.64 , current position (cm):  55420.2617\n",
      "Alpha-pinene 234.0 ul\n",
      "Methyl Butyrate 0.0 ul\n",
      "Fenchone 564.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789926\n",
      "5A\n",
      "learning_task_set3\n",
      "Tiffany\n",
      "Total sites:  286  |  Total rewarded stops:  136 ( 71.2 %) |  Total unrewarded stops:  150 ( 78.53 %) |  Water consumed:  816.0 ul\n",
      "Total travelled m:  476.52 , current position (cm):  47686.8672\n",
      "Fenchone 576.0 ul\n",
      "Alpha-pinene 240.0 ul\n",
      "Methyl Butyrate 0.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789908\n",
      "4D\n",
      "distance_short\n",
      "Tiffany\n",
      "Total sites:  394  |  Total rewarded stops:  166 ( 59.5 %) |  Total unrewarded stops:  228 ( 81.72 %) |  Water consumed:  830.0 ul\n",
      "Total travelled m:  618.73 , current position (cm):  61943.8516\n",
      "Fenchone 720.0 ul\n",
      "Alpha-pinene 110.0 ul\n",
      "Amyl Acetate 0.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "754574\n",
      "4B\n",
      "learning_task_set3_double\n",
      "Katrina\n",
      "Total sites:  321  |  Total rewarded stops:  139 ( 77.65 %) |  Total unrewarded stops:  182 ( 101.68 %) |  Water consumed:  834.0 ul\n",
      "Total travelled m:  590.16 , current position (cm):  59112.3242\n",
      "Fenchone 552.0 ul\n",
      "Alpha-pinene 282.0 ul\n",
      "Methyl Butyrate 0.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789914\n",
      "5A\n",
      "learning_task_set3\n",
      "Katrina\n",
      "Total sites:  328  |  Total rewarded stops:  134 ( 62.33 %) |  Total unrewarded stops:  194 ( 90.23 %) |  Water consumed:  804.0 ul\n",
      "Total travelled m:  536.74 , current position (cm):  53741.0117\n",
      "Methyl Butyrate 0.0 ul\n",
      "Fenchone 612.0 ul\n",
      "Alpha-pinene 192.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789915\n",
      "5B\n",
      "learning_task_set3\n",
      "Katrina\n",
      "Total sites:  277  |  Total rewarded stops:  126 ( 64.29 %) |  Total unrewarded stops:  151 ( 77.04 %) |  Water consumed:  756.0 ul\n",
      "Total travelled m:  429.82 , current position (cm):  42988.6016\n",
      "Alpha-pinene 126.0 ul\n",
      "Fenchone 630.0 ul\n",
      "Methyl Butyrate 0.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789923\n",
      "4C\n",
      "learning_task_set3\n",
      "Katrina\n",
      "Total sites:  278  |  Total rewarded stops:  103 ( 59.54 %) |  Total unrewarded stops:  175 ( 101.16 %) |  Water consumed:  618.0 ul\n",
      "Total travelled m:  481.3 , current position (cm):  48177.3203\n",
      "Fenchone 600.0 ul\n",
      "Alpha-pinene 18.0 ul\n",
      "Methyl Butyrate 0.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789917\n",
      "4A\n",
      "learning_task_set3\n",
      "Katrina\n",
      "Total sites:  386  |  Total rewarded stops:  124 ( 67.03 %) |  Total unrewarded stops:  262 ( 141.62 %) |  Water consumed:  744.0 ul\n",
      "Total travelled m:  797.2 , current position (cm):  79749.5234\n",
      "Methyl Butyrate 0.0 ul\n",
      "Alpha-pinene 246.0 ul\n",
      "Fenchone 498.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "789913\n",
      "4D\n",
      "distance_short\n",
      "Katrina\n",
      "Total sites:  597  |  Total rewarded stops:  191 ( 55.69 %) |  Total unrewarded stops:  406 ( 118.37 %) |  Water consumed:  955.0 ul\n",
      "Total travelled m:  1126.72 , current position (cm):  112746.352\n",
      "Fenchone 735.0 ul\n",
      "Amyl Acetate 0.0 ul\n",
      "Alpha-pinene 220.0 ul\n",
      "# ---------------------------------------------------------------------\n",
      "781896\n",
      "5A\n",
      "shaping_stageB_distanceD_stopE_probB\n",
      "Jason\n",
      "Total sites:  207  |  Total rewarded stops:  68 ( 57.14 %) |  Total unrewarded stops:  139 ( 116.81 %) |  Water consumed:  340.0 ul\n",
      "Total travelled m:  479.61 , current position (cm):  48152.0273\n",
      "Methyl Butyrate 340.0 ul\n",
      "0      0.406\n",
      "1      0.409\n",
      "2      0.412\n",
      "3      0.415\n",
      "4      0.418\n",
      "       ...  \n",
      "114    0.500\n",
      "115    0.500\n",
      "116    0.500\n",
      "117    0.500\n",
      "118    0.500\n",
      "Name: data, Length: 119, dtype: float64\n",
      "Total sites travelled: 207.0 \n",
      "Rewarded stops in max stop duration: 46.0 \n",
      "Total patches visited: 25.0\n",
      "# ---------------------------------------------------------------------\n",
      "781898\n",
      "4B\n",
      "shaping_stageB_distanceD_stopE_probB\n",
      "Jason\n",
      "Total sites:  422  |  Total rewarded stops:  167 ( 76.26 %) |  Total unrewarded stops:  255 ( 116.44 %) |  Water consumed:  835.0 ul\n",
      "Total travelled m:  1036.35 , current position (cm):  103896.344\n",
      "Methyl Butyrate 835.0 ul\n",
      "0      0.406\n",
      "1      0.409\n",
      "2      0.412\n",
      "3      0.415\n",
      "4      0.418\n",
      "       ...  \n",
      "215    0.500\n",
      "216    0.500\n",
      "217    0.500\n",
      "218    0.500\n",
      "219    0.500\n",
      "Name: data, Length: 220, dtype: float64\n",
      "Total sites travelled: 422.0 \n",
      "Rewarded stops in max stop duration: 179.0 \n",
      "Total patches visited: 37.0\n"
     ]
    }
   ],
   "source": [
    "odor_sites_sum = pd.DataFrame()\n",
    "for mouse in mouse_list:\n",
    "    print(\"# ---------------------------------------------------------------------\")\n",
    "    print(mouse)\n",
    "    session_paths = data_access.find_sessions_relative_to_date(\n",
    "        mouse=mouse,\n",
    "        date_string=date_string,\n",
    "        when='on'\n",
    "    )\n",
    "    for session_path in session_paths:\n",
    "        parsed_session = MetricsVrForaging(session_path)\n",
    "        if parsed_session.stage == 'thermistor screening':\n",
    "            continue\n",
    "        \n",
    "        df = parsed_session.get_metrics()\n",
    "        df['trainer'] = trainer_dict[mouse]\n",
    "        df['session'] = parsed_session.session\n",
    "        df['stage'] = parsed_session.stage\n",
    "        df['rig'] = parsed_session.rig_name\n",
    "        df['mouse'] = mouse \n",
    "        \n",
    "        try:\n",
    "            simplified_stage = re.search(r'stage([A-Za-z])', parsed_session.stage).group(1)\n",
    "        except:\n",
    "            simplified_stage = parsed_session.stage\n",
    "            \n",
    "        df['simplified_stage'] = simplified_stage\n",
    "        \n",
    "        reward_sites = parsed_session.get_reward_sites()\n",
    "\n",
    "        if len(parsed_session.updaters) != 0:\n",
    "            parsed_session.retrieve_updater_values()\n",
    "            print(\n",
    "            'Total sites travelled: ' + str(df.odor_sites_travelled.iloc[0]),\n",
    "            '\\nRewarded stops in max stop duration: ' + str(df.rewarded_sites_in_max_stop.iloc[0]),\n",
    "            '\\nTotal patches visited: ' + str(df.total_patches_visited.iloc[0]))\n",
    "\n",
    "        pdf_filename = parsed_session.run_pdf_summary()\n",
    "        os.startfile(pdf_path+\"/\" + pdf_filename)\n",
    "        \n",
    "        reward_sites['mouse'] = mouse\n",
    "        reward_sites['session'] = parsed_session.session\n",
    "        reward_sites['stage'] = parsed_session.stage\n",
    "        reward_sites['simplified_stage'] = simplified_stage\n",
    "        odor_sites_sum = pd.concat([odor_sites_sum, reward_sites], axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
