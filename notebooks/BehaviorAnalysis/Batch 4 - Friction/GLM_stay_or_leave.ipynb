{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magic tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../src/')\n",
    "\n",
    "import os\n",
    "\n",
    "from aind_vr_foraging_analysis.utils import parse, processing, plotting_utils as plotting, AddExtraColumns\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "pdf_path = r'Z:\\scratch\\vr-foraging\\sessions'\n",
    "base_path = r'Z:\\scratch\\vr-foraging\\data'\n",
    "data_path = r'../../../data/'\n",
    "\n",
    "# Define exponential function\n",
    "def exponential_func(x, a, b):\n",
    "    return a * np.exp(b * x)\n",
    "\n",
    "def format_func(value, tick_number):\n",
    "    return f\"{value:.0f}\"\n",
    "\n",
    "results_path = r'C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\experiments\\batch 4 - manipulating cost of travelling and global statistics\\results'\n",
    "\n",
    "import plotting_friction_experiment as friction\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from scipy.stats import ttest_1samp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_mouse_scaled, y_mouse):\n",
    "                    # Define the parameter grid\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "    # Initialize the logistic regression model\n",
    "    log_reg = LogisticRegression()\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit GridSearchCV\n",
    "    grid_search.fit(X_mouse_scaled, y_mouse)\n",
    "\n",
    "    # Get the best parameter\n",
    "    best_C = grid_search.best_params_['C']\n",
    "    print(f\"The best value for C is: {best_C}\")\n",
    "\n",
    "    # Get the best score\n",
    "    best_score = grid_search.best_score_\n",
    "    print(f\"The best cross-validation score is: {best_score:.2f}\")\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    log_reg = LogisticRegression(C=best_C)\n",
    "    \n",
    "    return best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading')\n",
    "summary_df = pd.read_csv(os.path.join(data_path, 'batch_4.csv'), index_col=0)\n",
    "summary_df['perceived_reward_probability'] = summary_df['cumulative_rewards'] / (summary_df['visit_number'] +1)\n",
    "summary_df = summary_df[(summary_df['experiment'] == 'data_collection')|(summary_df['experiment'] == 'friction')|(summary_df['experiment'] == 'control')|(summary_df['experiment'] == 'distance_long')|(summary_df['experiment'] == 'distance_short')|(summary_df['experiment'] == 'friction_15')|(summary_df['experiment'] == 'friction_optimized')|(summary_df['experiment'] == 'distance_extra_long')|(summary_df['experiment'] == 'distance_extra_short')]\n",
    "summary_df = summary_df[(summary_df['mouse'] != 754573)&(summary_df['mouse'] != 754572)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summary_df.loc[(summary_df.experiment == \"data_collection\")&(summary_df.label == 'RewardSite')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Run first version of the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run model without any interaction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['reward_probability', 'consecutive_failures', 'visit_number', 'cumulative_rewards', 'active_patch']\n",
    "\n",
    "# Initialize dataframes to store weights and cross-validation results\n",
    "weights_df = pd.DataFrame(columns=['regressors', 'weights', 'mouse', 'session'])\n",
    "cv_results_df = pd.DataFrame(columns=['mouse', 'cv_score'])\n",
    "\n",
    "for (mouse, session), mouse_df in summary_df.groupby(['mouse', 'session']):\n",
    "    print(f\"Mouse: {mouse}, Session: {session}\")\n",
    "    \n",
    "    # Filter data for the current mouse\n",
    "    \n",
    "    # Select features and target variable\n",
    "    X_mouse = mouse_df[features]\n",
    "    y_mouse = mouse_df['has_choice'].astype(int)\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_mouse_scaled = scaler.fit_transform(X_mouse)\n",
    "    \n",
    "    # Perform grid search to find the best value for C\n",
    "    # best_C = grid_search(X_mouse_scaled, y_mouse)\n",
    "    best_C=1\n",
    "    \n",
    "    # Perform 5-fold cross-validation\n",
    "    log_reg = LogisticRegression(C=best_C)\n",
    "    cv_scores = cross_val_score(log_reg, X_mouse_scaled, y_mouse, cv=5)\n",
    "    \n",
    "    # Fit the logistic regression model using formula\n",
    "    log_reg.fit(X_mouse_scaled, y_mouse)\n",
    "    \n",
    "    # Get the weights for each feature\n",
    "    feature_weights = pd.Series(log_reg.coef_[0], index=features)\n",
    "    feature_weights = feature_weights.reset_index()\n",
    "    feature_weights.rename(columns={'index': 'regressors', 0: 'weights'}, inplace=True)\n",
    "    feature_weights['mouse'] = mouse\n",
    "    feature_weights['session'] = session\n",
    "\n",
    "    # Append the weights and cv scores to the respective dataframes\n",
    "    weights_df = pd.concat([weights_df, feature_weights], ignore_index=True)\n",
    "    cv_results_df = pd.concat([cv_results_df, pd.DataFrame({'session': [session], 'mouse': [mouse], 'cv_score': [cv_scores.mean()]})], ignore_index=True)\n",
    "\n",
    "    # Print the cross-validation scores and their mean\n",
    "    print(f\"Mean cross-validation score: {cv_scores.mean():.2f}\")\n",
    "    print('\\n')\n",
    "    # Get the weights for each feature\n",
    "\n",
    "weights_df['mouse'] = weights_df['mouse'].round(0).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot using the collapsed data\n",
    "fig, axes = plt.subplots(4, 4, figsize=(20, 14), sharex=True)\n",
    "\n",
    "# Perform t-tests and plot significance\n",
    "for (mouse, group), ax in zip(weights_df.groupby('mouse'), axes.flatten()):\n",
    "    # Perform t-test for each regressor in the group\n",
    "    significant_regressors = []\n",
    "    for regressor in group['regressors'].unique():\n",
    "        regressor_data = group[group['regressors'] == regressor]['weights']\n",
    "        t_stat, p_value = ttest_1samp(regressor_data, 0)\n",
    "        \n",
    "        # Determine the significance level\n",
    "        if p_value < 0.001:\n",
    "            significance = '***'\n",
    "        elif p_value < 0.01:\n",
    "            significance = '**'\n",
    "        elif p_value < 0.05:\n",
    "            significance = '*'\n",
    "        else:\n",
    "            significance = None\n",
    "\n",
    "        if significance:\n",
    "            significant_regressors.append((regressor, regressor_data.max(), significance))\n",
    "\n",
    "    # Plot the swarmplot\n",
    "    sns.swarmplot(\n",
    "        data=group, \n",
    "        x='regressors', \n",
    "        y='weights', \n",
    "        palette='tab10', \n",
    "        ax=ax, \n",
    "        hue='regressors', \n",
    "        legend=False\n",
    "    )\n",
    "    ax.set_title(f'Mouse {mouse}')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.hlines(0, -0.5, len(group['regressors'].unique()) - 0.5, color='black', linestyle='--')\n",
    "\n",
    "    # Annotate significant results\n",
    "    for regressor, max_value, significance in significant_regressors:\n",
    "        x = list(group['regressors'].unique()).index(regressor)\n",
    "        y = max_value + 0.05  # Position above max value\n",
    "        ax.text(x, y, significance, ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "# Manually create the legend\n",
    "handles = []\n",
    "for regressor, color in zip(weights_df['regressors'].unique(), sns.color_palette('tab10', len(weights_df['regressors'].unique()))):\n",
    "    handles.append(mpatches.Patch(color=color, label=regressor))\n",
    "\n",
    "# Add legend at the bottom with 3 columns\n",
    "fig.legend(\n",
    "    handles=handles,\n",
    "    bbox_to_anchor=(0.5, -0.05),  # Centered below the figure\n",
    "    loc='upper center',\n",
    "    ncol=3,  # Number of columns\n",
    "    title='Features',\n",
    "    prop={'size': 12}\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.15)  # Add space at the bottom for the legend\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Aggregate the weights by mouse and regressor\n",
    "aggregated_df = weights_df.groupby(['mouse', 'regressors'], as_index=False).mean()\n",
    "\n",
    "# Perform t-tests on the aggregated data\n",
    "t_test_results = []\n",
    "for regressor in aggregated_df['regressors'].unique():\n",
    "    regressor_data = aggregated_df[aggregated_df['regressors'] == regressor]['weights']\n",
    "    t_stat, p_value = ttest_1samp(regressor_data, 0)\n",
    "    \n",
    "    # Determine the significance level\n",
    "    if p_value < 0.001:\n",
    "        significance = '***'\n",
    "    elif p_value < 0.01:\n",
    "        significance = '**'\n",
    "    elif p_value < 0.05:\n",
    "        significance = '*'\n",
    "    else:\n",
    "        significance = None\n",
    "\n",
    "    t_test_results.append({'regressor': regressor, 'p_value': p_value, 'significance': significance})\n",
    "\n",
    "t_test_results_df = pd.DataFrame(t_test_results)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 6))\n",
    "\n",
    "# One point per mouse\n",
    "sns.swarmplot(\n",
    "    data=aggregated_df, \n",
    "    x='regressors', \n",
    "    y='weights', \n",
    "    hue='regressors', \n",
    "    palette='tab10', \n",
    "    dodge=True\n",
    ")\n",
    "\n",
    "# Annotate significance levels\n",
    "for i, row in t_test_results_df.iterrows():\n",
    "    regressor = row['regressor']\n",
    "    significance = row['significance']\n",
    "    if significance:\n",
    "        x = list(aggregated_df['regressors'].unique()).index(regressor)\n",
    "        y = aggregated_df[aggregated_df['regressors'] == regressor]['weights'].max() + 0.1\n",
    "        plt.text(x, y, significance, ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "# Add horizontal line at 0\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "\n",
    "# Customize labels and legend\n",
    "plt.xlabel('')\n",
    "plt.xlim(-1, len(aggregated_df['regressors'].unique()))\n",
    "plt.ylabel('Weight')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Weights Per Regressor \\n (Aggregated by Mouse)')\n",
    "\n",
    "# Manually create legend\n",
    "handles = []\n",
    "for regressor, color in zip(aggregated_df['regressors'].unique(), sns.color_palette('tab10', len(aggregated_df['regressors'].unique()))):\n",
    "    handles.append(mpatches.Patch(color=color, label=regressor))\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run model without any interaction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['reward_probability', 'consecutive_failures', 'visit_number', 'cumulative_rewards', 'active_patch']\n",
    "\n",
    "# Initialize dataframes to store weights and cross-validation results\n",
    "weights_df = pd.DataFrame(columns=['regressors', 'weights', 'mouse', 'session'])\n",
    "cv_results_df = pd.DataFrame(columns=['mouse', 'cv_score'])\n",
    "\n",
    "for (mouse, session), mouse_df in summary_df.groupby(['mouse', 'session']):\n",
    "    print(f\"Mouse: {mouse}, Session: {session}\")\n",
    "    \n",
    "    # Select features and target variable\n",
    "    X_mouse = mouse_df[features]\n",
    "    y_mouse = mouse_df['has_choice'].astype(int)\n",
    "    \n",
    "    # Define the pipeline\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    scaler = StandardScaler()\n",
    "    log_reg = LogisticRegression(C=1, max_iter=1000)\n",
    "    \n",
    "    pipeline = make_pipeline(poly, scaler, log_reg)\n",
    "    \n",
    "    # Perform 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, X_mouse, y_mouse, cv=5)\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_mouse, y_mouse)\n",
    "    \n",
    "    # Extract the feature names after applying PolynomialFeatures\n",
    "    poly_features = poly.fit(X_mouse).get_feature_names_out(features)\n",
    "    \n",
    "    # Get the weights for each feature\n",
    "    log_reg_model = pipeline.named_steps['logisticregression']\n",
    "    feature_weights = pd.Series(log_reg_model.coef_[0], index=poly_features)\n",
    "    feature_weights = feature_weights.reset_index()\n",
    "    feature_weights.rename(columns={'index': 'regressors', 0: 'weights'}, inplace=True)\n",
    "    feature_weights['mouse'] = mouse\n",
    "    feature_weights['session'] = session\n",
    "\n",
    "    # Append the weights and cv scores to the respective dataframes\n",
    "    weights_df = pd.concat([weights_df, feature_weights], ignore_index=True)\n",
    "    cv_results_df = pd.concat([cv_results_df, pd.DataFrame({'session': [session], 'mouse': [mouse], 'cv_score': [cv_scores.mean()]})], ignore_index=True)\n",
    "\n",
    "    # Print the cross-validation scores and their mean\n",
    "    print(f\"Mean cross-validation score: {cv_scores.mean():.2f}\")\n",
    "    print('\\n')\n",
    "\n",
    "weights_df['mouse'] = weights_df['mouse'].round(0).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot using the collapsed data\n",
    "fig, axes = plt.subplots(2, 5, figsize=(26, 8), sharex=True)\n",
    "\n",
    "# Perform t-tests and plot significance\n",
    "for (mouse, group), ax in zip(weights_df.groupby('mouse'), axes.flatten()):\n",
    "    # Perform t-test for each regressor in the group\n",
    "    significant_regressors = []\n",
    "    for regressor in group['regressors'].unique():\n",
    "        regressor_data = group[group['regressors'] == regressor]['weights']\n",
    "        t_stat, p_value = ttest_1samp(regressor_data, 0)\n",
    "        \n",
    "        # Determine the significance level\n",
    "        if p_value < 0.001:\n",
    "            significance = '***'\n",
    "        elif p_value < 0.01:\n",
    "            significance = '**'\n",
    "        elif p_value < 0.05:\n",
    "            significance = '*'\n",
    "        else:\n",
    "            significance = None\n",
    "\n",
    "        if significance:\n",
    "            significant_regressors.append((regressor, regressor_data.max(), significance))\n",
    "\n",
    "    # Plot the swarmplot\n",
    "    sns.swarmplot(\n",
    "        data=group, \n",
    "        x='regressors', \n",
    "        y='weights', \n",
    "        palette='tab20', \n",
    "        ax=ax, \n",
    "        hue='regressors', \n",
    "        legend=False\n",
    "    )\n",
    "    ax.set_title(f'Mouse {mouse}')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.hlines(0, -0.5, len(group['regressors'].unique()) - 0.5, color='black', linestyle='--')\n",
    "\n",
    "    # Annotate significant results\n",
    "    for regressor, max_value, significance in significant_regressors:\n",
    "        x = list(group['regressors'].unique()).index(regressor)\n",
    "        y = max_value + 0.05  # Position above max value\n",
    "        ax.text(x, y, significance, ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "# Manually create the legend\n",
    "handles = []\n",
    "for regressor, color in zip(weights_df['regressors'].unique(), sns.color_palette('tab20', len(weights_df['regressors'].unique()))):\n",
    "    handles.append(mpatches.Patch(color=color, label=regressor))\n",
    "\n",
    "# Add legend at the bottom with 3 columns\n",
    "fig.legend(\n",
    "    handles=handles,\n",
    "    bbox_to_anchor=(0.5, 0.05),  # Centered below the figure\n",
    "    loc='upper center',\n",
    "    ncol=3,  # Number of columns\n",
    "    title='Features',\n",
    "    prop={'size': 12}\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.10)  # Add space at the bottom for the legend\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate the weights by mouse and regressor\n",
    "aggregated_df = weights_df.groupby(['mouse', 'regressors'], as_index=False).mean()\n",
    "\n",
    "# Perform t-tests on the aggregated data\n",
    "t_test_results = []\n",
    "for regressor in aggregated_df['regressors'].unique():\n",
    "    regressor_data = aggregated_df[aggregated_df['regressors'] == regressor]['weights']\n",
    "    t_stat, p_value = ttest_1samp(regressor_data, 0)\n",
    "    \n",
    "    # Determine the significance level\n",
    "    if p_value < 0.001:\n",
    "        significance = '***'\n",
    "    elif p_value < 0.01:\n",
    "        significance = '**'\n",
    "    elif p_value < 0.05:\n",
    "        significance = '*'\n",
    "    else:\n",
    "        significance = None\n",
    "\n",
    "    t_test_results.append({'regressor': regressor, 'p_value': p_value, 'significance': significance})\n",
    "\n",
    "t_test_results_df = pd.DataFrame(t_test_results)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# One point per mouse\n",
    "sns.swarmplot(\n",
    "    data=aggregated_df, \n",
    "    x='regressors', \n",
    "    y='weights', \n",
    "    hue='regressors', \n",
    "    palette='tab20', \n",
    "    dodge=True\n",
    ")\n",
    "\n",
    "# Annotate significance levels\n",
    "for i, row in t_test_results_df.iterrows():\n",
    "    regressor = row['regressor']\n",
    "    significance = row['significance']\n",
    "    if significance:\n",
    "        x = list(aggregated_df['regressors'].unique()).index(regressor)\n",
    "        y = aggregated_df[aggregated_df['regressors'] == regressor]['weights'].max() + 0.1\n",
    "        plt.text(x-0.2, y, significance, ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "# Add horizontal line at 0\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "\n",
    "# Customize labels and legend\n",
    "plt.xlabel('')\n",
    "plt.xlim(-1.5, len(aggregated_df['regressors'].unique()) - 0.5)\n",
    "plt.ylabel('Weight')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Weights Per Regressor (Aggregated by Mouse)')\n",
    "\n",
    "# Manually create legend\n",
    "handles = []\n",
    "for regressor, color in zip(aggregated_df['regressors'].unique(), sns.color_palette('tab20', len(aggregated_df['regressors'].unique()))):\n",
    "    handles.append(mpatches.Patch(color=color, label=regressor))\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.3)  # Adjust space for the legend\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: collapse sessions by mouse and regressor\n",
    "collapsed_df = (\n",
    "    weights_df\n",
    "    .groupby(['mouse', 'regressors'], as_index=False)\n",
    "    .agg({'weights': 'mean'})  # Replace 'mean' with the desired aggregation function\n",
    ")\n",
    "\n",
    "# Plot using the collapsed data\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "sns.swarmplot(data=collapsed_df, x='regressors', y='weights', hue='mouse', palette='tab10')\n",
    "sns.boxplot(data=collapsed_df, x='regressors', y='weights', color='grey')\n",
    "plt.hlines(0, -0.5, 4.5, color='black', linestyle='--')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., ncol=2)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Remove variables one at a time to find which ones are needed for the movel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['reward_probability', 'consecutive_failures', 'visit_number', 'cumulative_rewards', 'active_patch']\n",
    "# Initialize dataframes to store weights and cross-validation results\n",
    "weights_df = pd.DataFrame(columns=features)\n",
    "cv_results_df = pd.DataFrame(columns=['mouse', 'cv_score'])\n",
    "\n",
    "# Perform logistic regression excluding one feature at a time\n",
    "for feature in features:\n",
    "    new_features = features.copy()  \n",
    "    new_features.remove(feature)\n",
    "    \n",
    "    # Iterate over each unique mouse\n",
    "    for mouse in summary_df['mouse'].unique():\n",
    "        for session in summary_df.loc[(summary_df['mouse'] == mouse)].session.unique():\n",
    "            print(f\"Mouse: {mouse}, Session: {session}\")\n",
    "            \n",
    "            # Filter data for the current mouse\n",
    "            mouse_df = summary_df[(summary_df['mouse'] == mouse)&(summary_df['session'] == session)]\n",
    "            \n",
    "            # Select features and target variable\n",
    "            X_mouse = mouse_df[new_features]\n",
    "            y_mouse = mouse_df['has_choice'].astype(int)\n",
    "            \n",
    "            # Standardize the features\n",
    "            scaler = StandardScaler()\n",
    "            X_mouse_scaled = scaler.fit_transform(X_mouse)\n",
    "            \n",
    "\n",
    "            cv_scores = cross_val_score(log_reg, X_mouse_scaled, y_mouse, cv=5)\n",
    "            \n",
    "            # Fit the logistic regression model\n",
    "            log_reg.fit(X_mouse_scaled, y_mouse)\n",
    "            \n",
    "            # Get the weights for each feature\n",
    "            feature_weights = pd.Series(log_reg.coef_[0], index=new_features)\n",
    "            \n",
    "            # Append the weights and cv scores to the respective dataframes\n",
    "            weights_df = pd.concat([weights_df, feature_weights.to_frame().T], ignore_index=True)\n",
    "            cv_results_df = pd.concat([cv_results_df, pd.DataFrame({'feature_removed': [feature],'session': [session], 'mouse': [mouse], 'cv_score': [cv_scores.mean()]})], ignore_index=True)\n",
    "    \n",
    "\n",
    "            # Print the cross-validation scores and their mean\n",
    "            print(f\"Cross-validation scores: {cv_scores}\")\n",
    "            print(f\"Mean cross-validation score: {cv_scores.mean():.2f}\")\n",
    "\n",
    "            # Get the weights for each feature\n",
    "            feature_weights = pd.Series(log_reg.coef_[0], index=new_features)\n",
    "            print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "sns.boxplot(data=cv_results_df, x='mouse', y='cv_score', hue='feature_removed', palette='tab10')\n",
    "plt.xticks(rotation=45)\n",
    "sns.despine()\n",
    "plt.legend(title='Feature removed', loc='upper left', bbox_to_anchor=(1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
