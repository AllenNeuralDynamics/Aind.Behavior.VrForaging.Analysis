{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from aind_vr_foraging_analysis.utils import parse, plotting_utils as plotting, AddExtraColumns\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "color1='#d95f02'\n",
    "color2='#1b9e77'\n",
    "color3='#7570b3'\n",
    "color4='yellow'\n",
    "odor_list_color = [color1, color2, color3, color4]\n",
    "\n",
    "pdf_path = r'Z:\\scratch\\vr-foraging\\sessions'\n",
    "base_path = r'Z:/scratch/vr-foraging/data/'\n",
    "results_path = r'C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\experiments\\batch 4 - manipulating cost of travelling and global statistics\\results'\n",
    "data_path = r'../../../data/'\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import plotting_friction_experiment as f\n",
    "\n",
    "from statsmodels.formula.api import glm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Modelling libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "palette = {\n",
    "    'control': 'darkgrey',  # Red\n",
    "    'friction_high': '#6a51a3',  # Purple\n",
    "    'friction_med': '#807dba',  # Lighter Purple\n",
    "    'friction_low': '#9e9ac8',  # Lightest Purple\n",
    "    'distance_extra_short': 'crimson',  # Blue\n",
    "    'distance_short': 'pink',  # Lighter Blue\n",
    "    'distance_extra_long': '#fd8d3c',  # Yellow\n",
    "    'distance_long': '#fdae6b'  # Lighter Yellow\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_roc_curve(y_probs, y_mouse, plot=False):\n",
    "    # Assuming log_reg is your trained logistic regression model\n",
    "    # and X_mouse_scaled is your test data (or any data to predict on)\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_mouse, y_probs)\n",
    "\n",
    "    # Calculate AUC\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Find the best threshold (maximizing Youden's J statistic)\n",
    "    # J = TPR - FPR\n",
    "    j_scores = tpr - fpr\n",
    "    best_threshold_index = np.argmax(j_scores)\n",
    "    best_threshold = thresholds[best_threshold_index]\n",
    "\n",
    "    if plot:\n",
    "        # Plot ROC curve\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Random classifier (diagonal line)\n",
    "        plt.scatter(fpr[best_threshold_index], tpr[best_threshold_index], color='red', label=f'Best threshold = {best_threshold:.2f}')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        sns.despine()\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Best threshold: {best_threshold}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(metrics_list, y_mouse, y_pred):    # Calculate confusion matrix (TP, TN, FP, FN)\n",
    "    \"\"\"\n",
    "    Calculate various classification metrics and append them to the provided metrics list.\n",
    "    Parameters:\n",
    "    metrics_list (list): A list to which the calculated metrics dictionary will be appended.\n",
    "    y_mouse (array-like): True labels.\n",
    "    y_pred (array-like): Predicted labels.\n",
    "    Returns:\n",
    "    list: The updated metrics list with the metrics dictionary for the current fold.\n",
    "    \n",
    "    The metrics dictionary contains the following keys:\n",
    "    - \"Accuracy 0\": Accuracy for class 0 (negative class).\n",
    "    - \"Precision 0\": Precision for class 0 (negative class).\n",
    "    - \"Recall 0\": Recall for class 0 (negative class).\n",
    "    - \"F1 Score 0\": F1 score for class 0 (negative class).\n",
    "    - \"Accuracy 1\": Accuracy for class 1 (positive class).\n",
    "    - \"Precision 1\": Precision for class 1 (positive class).\n",
    "    - \"Recall 1\": Recall for class 1 (positive class).\n",
    "    - \"F1 Score 1\": F1 score for class 1 (positive class).\n",
    "    - \"TN\": True negatives.\n",
    "    - \"FP\": False positives.\n",
    "    - \"FN\": False negatives.\n",
    "    - \"TP\": True positives.\n",
    "    \"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(y_mouse, y_pred)\n",
    "    TP = cm[1, 1]\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "    \n",
    "    # Calculate metrics for class 0 (negative class)\n",
    "    precision_0 = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    recall_0 = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
    "    f1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0) if (precision_0 + recall_0) > 0 else 0\n",
    "    accuracy_0 = (TN) / (TN + FP)  # Proportion of predictions that were `0`\n",
    "    \n",
    "    # Calculate metrics for class 1 (positive class)\n",
    "    precision_1 = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    recall_1 = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0\n",
    "    accuracy_1 = (TP) / (TP + FN)  # Proportion of predictions that were `1`\n",
    "    \n",
    "    # Collect the metrics for this fold as a dictionary\n",
    "    fold_metrics = {\n",
    "        \"Accuracy 0\": accuracy_0,\n",
    "        \"Precision 0\": precision_0,\n",
    "        \"Recall 0\": recall_0,\n",
    "        \"F1 Score 0\": f1_0,\n",
    "        \"Accuracy 1\": accuracy_1,\n",
    "        \"Precision 1\": precision_1,\n",
    "        \"Recall 1\": recall_1,\n",
    "        \"F1 Score 1\": f1_1,\n",
    "        \"TN\": TN,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN,\n",
    "        \"TP\": TP\n",
    "    }\n",
    "    \n",
    "    # Append the metrics dictionary to the list\n",
    "    metrics_list.append(fold_metrics)\n",
    "    return metrics_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **One shot evaluation of time and speed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torque_data = {}\n",
    "date = datetime.date.today()\n",
    "date_string = \"11/25/2024\"\n",
    "date = datetime.datetime.strptime(date_string, \"%m/%d/%Y\").date()\n",
    "mouse = '745301'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df = pd.read_csv(data_path + 'torque_calibration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_n = 0\n",
    "cum_active_site = pd.DataFrame()\n",
    "cum_velocity = pd.DataFrame()\n",
    "cum_torque = pd.DataFrame()\n",
    "within_session_number = 0\n",
    "control_experiment = 0\n",
    "previous_experiment = None\n",
    "\n",
    "directory = os.path.join(base_path, mouse)\n",
    "files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "# All this segment is to find the correct session without having the specific path\n",
    "for file_name in sorted_files:\n",
    "    # Find specific session sorted by date\n",
    "    session = file_name[-15:-7]\n",
    "    if datetime.datetime.strptime(session, \"%Y%m%d\").date() != date:\n",
    "        continue\n",
    "\n",
    "    # Recover data streams\n",
    "    session_path = os.path.join(base_path, mouse, file_name)\n",
    "    session_path = Path(session_path)\n",
    "    data = parse.load_session_data(session_path)\n",
    "    \n",
    "    # Parse data into a dataframe with the main features\n",
    "    try:\n",
    "        reward_sites, active_site, config = parse.parse_dataframe(data)\n",
    "    except:\n",
    "        continue\n",
    "    # -- At this step you can save the data into a csv file\n",
    "    \n",
    "    rig_name = data['config'].streams.rig_input.data['rig_name']\n",
    "    # Expand with extra columns\n",
    "    reward_sites = AddExtraColumns(reward_sites, active_site, run_on_init=True).reward_sites\n",
    "    active_site = AddExtraColumns(reward_sites, active_site, run_on_init=False).add_time_previous_intersite_interpatch()\n",
    "\n",
    "    # Load the encoder data separately\n",
    "    stream_data = parse.ContinuousData(data)\n",
    "    encoder_data = stream_data.encoder_data\n",
    "    odor_triggers = stream_data.odor_triggers\n",
    "    software_tone = data['software_events'].streams['ChoiceFeedback'].data.index\n",
    "    choice_tone = stream_data.choice_feedback.index\n",
    "\n",
    "    experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "    \n",
    "    # Recover color palette\n",
    "    color_dict_label = {}\n",
    "    dict_odor = {}\n",
    "    list_patches = parse.TaskSchemaProperties(data).patches\n",
    "    for i, patches in enumerate(list_patches):\n",
    "        color_dict_label[patches['label']] = odor_list_color[i]\n",
    "        dict_odor[i] = patches['label']\n",
    "    \n",
    "    if active_site.loc[active_site.label == 'InterPatch'].length.min() == 50:\n",
    "        section = 'PostPatch'\n",
    "    else:\n",
    "        print(experiment)\n",
    "        section = 'InterPatch'\n",
    "\n",
    "    if section == 'PostPatch':\n",
    "        active_site['active_patch'] = active_site['active_patch'].shift(-1)\n",
    "        \n",
    "    active_site['end_epoch'] = active_site.index.to_series().shift(-1)\n",
    "    active_site['epoch_duration'] = active_site['end_epoch'] - active_site.index\n",
    "    friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "    new_active_site = active_site[active_site['label'] == section]\n",
    "    \n",
    "    # What was the friction applied if we have the friction of the schema? (We have the friction in the schema, we want the reality)\n",
    "    wheel = rig_name\n",
    "    resolved_torque = f.quadratic_model(65535 * friction, params_df.loc[params_df.wheel == wheel].a.values[0], params_df.loc[params_df.wheel == wheel].b.values[0], params_df.loc[params_df.wheel == wheel].c.values[0])    \n",
    "    actual_friction = (params_df.loc[params_df.wheel == wheel].c.values[0] - resolved_torque)/params_df.loc[params_df.wheel == wheel].c.values[0]    \n",
    "    actual_friction *=100    \n",
    "    \n",
    "    session_n += 1\n",
    "    new_active_site['session_n'] = session_n\n",
    "    new_active_site['experiment'] = experiment\n",
    "    \n",
    "    experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "    if previous_experiment != experiment:\n",
    "        within_session_number = 0\n",
    "        previous_experiment = experiment\n",
    "    else:\n",
    "        within_session_number += 1\n",
    "\n",
    "    if experiment == 'control':\n",
    "        control_experiment += 1\n",
    "        within_session_number = control_experiment\n",
    "            \n",
    "    new_active_site['within_session_number'] = within_session_number   \n",
    "    new_active_site = new_active_site.loc[new_active_site.active_patch <= 40]\n",
    "    cum_active_site = pd.concat([cum_active_site, new_active_site])\n",
    "    \n",
    "    velocity = plotting.trial_collection(new_active_site, \n",
    "                                                    encoder_data, \n",
    "                                                    mouse, \n",
    "                                                    session, \n",
    "                                                    window=[-1,10],  \n",
    "                                                    cropped_to_length='epoch',\n",
    "                                                    taken_col='filtered_velocity')\n",
    "\n",
    "    velocity['cropped'] = velocity.times < min(velocity.groupby('active_patch').times.max())\n",
    "    velocity['align'] = 'onset'\n",
    "    cum_velocity = pd.concat([cum_velocity, velocity])\n",
    "    \n",
    "    velocity = plotting.trial_collection(new_active_site, \n",
    "                                                encoder_data, \n",
    "                                                mouse, \n",
    "                                                session, \n",
    "                                                window=[-5,2],  \n",
    "                                                aligned='end_epoch',\n",
    "                                                taken_col='filtered_velocity')\n",
    "\n",
    "    velocity['cropped'] = velocity.times < min(velocity.groupby('active_patch').times.max())\n",
    "    velocity['align'] = 'offset'\n",
    "    cum_velocity = pd.concat([cum_velocity, velocity])\n",
    "\n",
    "    torque_data = stream_data.torque_data\n",
    "    brake_data = stream_data.brake_data\n",
    "    \n",
    "    velocity = plotting.trial_collection(new_active_site, \n",
    "                                                    torque_data, \n",
    "                                                    mouse, \n",
    "                                                    session, \n",
    "                                                    window=[-1,10],  \n",
    "                                                    cropped_to_length='epoch',\n",
    "                                                    taken_col=['Torque'])\n",
    "\n",
    "\n",
    "    velocity_end = plotting.trial_collection(new_active_site, \n",
    "                                                    torque_data, \n",
    "                                                    mouse, \n",
    "                                                    session, \n",
    "                                                    aligned='end_epoch',\n",
    "                                                    window=[-5,2],  \n",
    "                                                    taken_col=['Torque'])\n",
    "    \n",
    "    velocity['align'] = 'onset'\n",
    "    velocity_end['align'] = 'offset'\n",
    "    cum_torque = pd.concat([cum_torque, velocity])\n",
    "    cum_torque = pd.concat([cum_torque, velocity_end])\n",
    "    \n",
    "    data[cum_torque.mouse.unique()[0]] = (cum_torque.loc[(cum_torque['align'] =='onset')&(cum_torque.times>0)&(cum_torque.times<1)&(cum_torque.experiment == 'control')].Torque.mean() - \n",
    "    cum_torque.loc[(cum_torque['align'] =='onset')&(cum_torque.times>0)&(cum_torque.times<1)&(cum_torque.experiment == 'friction')].Torque.mean())\n",
    "    # plt.ylim(0, 40)\n",
    "    \n",
    "    fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "    ax = axes[0]\n",
    "    sns.lineplot(data=new_active_site, x='active_patch', y='epoch_duration', hue='active_patch',  marker='o', ax=ax, legend=False)\n",
    "    ax.set_ylabel('Duration (s)')\n",
    "    ax.set_xlabel('Patch #')\n",
    "    \n",
    "    ax = axes[1]\n",
    "    sns.lineplot(data=cum_velocity.loc[(cum_velocity.cropped==True)&(cum_velocity.experiment==experiment)&(cum_velocity['align']=='onset')], x='times', y='speed', \n",
    "                errorbar=(\"ci\", 95), alpha=0.8, ax=ax)\n",
    "    plt.xlim(-1, max(cum_velocity.loc[cum_velocity.cropped==True].times))\n",
    "    plt.ylim(-15, 60)\n",
    "    plt.fill_betweenx([-15, 60], -1, 0, color=color1, alpha=0.2)\n",
    "    plt.fill_betweenx([-15, 60],0, 15, color='grey', alpha=0.2)\n",
    "    plt.xlabel('Time from inter-patch start (s)')\n",
    "    plt.ylabel('Velocity (cm/s)')\n",
    "    plt.title(f'{experiment} { friction} {np.around(actual_friction,2)}')\n",
    "    plt.legend(bbox_to_anchor=(1,0.9), title='Patch #')\n",
    "    plt.suptitle(mouse)\n",
    "    sns.despine()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.torque_plots(cum_torque, limits=[min(cum_torque.Torque), max(cum_torque.Torque)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.epoch_duration_plot(cum_active_site, mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.plot_velocity_across_sessions(cum_velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in ['754570','754579','754567','754580','754559','754560','754577','754566','754570','754571','754574','754575', '754582','745302','745305','745301']:\n",
    "    session_n = 0\n",
    "    cum_active_site = pd.DataFrame()\n",
    "    cum_velocity = pd.DataFrame()\n",
    "    cum_torque = pd.DataFrame()\n",
    "    within_session_number = 0\n",
    "    control_experiment = 0\n",
    "    previous_experiment = None\n",
    "\n",
    "    directory = os.path.join(base_path, mouse)\n",
    "    files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "    sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "    # All this segment is to find the correct session without having the specific path\n",
    "    for file_name in sorted_files:\n",
    "        # Find specific session sorted by date\n",
    "        session = file_name[-15:-7]\n",
    "        if datetime.datetime.strptime(session, \"%Y%m%d\").date() != date:\n",
    "            continue\n",
    "\n",
    "            \n",
    "        # Recover data streams\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session_path = Path(session_path)\n",
    "        data = parse.load_session_data(session_path)\n",
    "        \n",
    "        # Parse data into a dataframe with the main features\n",
    "        try:\n",
    "            reward_sites, active_site, config = parse.parse_dataframe(data)\n",
    "        except:\n",
    "            continue\n",
    "        # -- At this step you can save the data into a csv file\n",
    "        \n",
    "        rig_name = data['config'].streams.rig_input.data['rig_name']\n",
    "\n",
    "        # Expand with extra columns\n",
    "        reward_sites = AddExtraColumns(reward_sites, active_site, run_on_init=True).reward_sites\n",
    "        active_site = AddExtraColumns(reward_sites, active_site, run_on_init=False).add_time_previous_intersite_interpatch()\n",
    "\n",
    "        # Load the encoder data separately\n",
    "        stream_data = parse.ContinuousData(data)\n",
    "        encoder_data = stream_data.encoder_data\n",
    "        odor_triggers = stream_data.odor_triggers\n",
    "        software_tone = data['software_events'].streams['ChoiceFeedback'].data.index\n",
    "        choice_tone = stream_data.choice_feedback.index\n",
    "\n",
    "        friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        new_active_site = active_site[active_site['label'] == section]\n",
    "        \n",
    "        # What was the friction applied if we have the friction of the schema? (We have the friction in the schema, we want the reality)\n",
    "        wheel = rig_name\n",
    "        resolved_torque = f.quadratic_model(65535 * friction, params_df.loc[params_df.wheel == wheel].a.values[0], params_df.loc[params_df.wheel == wheel].b.values[0], params_df.loc[params_df.wheel == wheel].c.values[0])    \n",
    "        actual_friction = (params_df.loc[params_df.wheel == wheel].c.values[0] - resolved_torque)/params_df.loc[params_df.wheel == wheel].c.values[0]    \n",
    "        actual_friction *=100    \n",
    "        \n",
    "        experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        \n",
    "        if experiment == 'friction' or experiment == 'friction_15' or experiment == 'friction_optimized':\n",
    "            if actual_friction < 8:\n",
    "                experiment = 'friction_low'\n",
    "            elif actual_friction > 8 and actual_friction < 16:\n",
    "                experiment = 'friction_med'\n",
    "            else:\n",
    "                experiment = 'friction_high'\n",
    "            \n",
    "        # Recover color palette\n",
    "        color_dict_label = {}\n",
    "        dict_odor = {}\n",
    "        list_patches = parse.TaskSchemaProperties(data).patches\n",
    "        for i, patches in enumerate(list_patches):\n",
    "            color_dict_label[patches['label']] = odor_list_color[i]\n",
    "            dict_odor[i] = patches['label']\n",
    "        \n",
    "        if active_site.loc[active_site.label == 'InterPatch'].length.min() == 50:\n",
    "            section = 'PostPatch'\n",
    "        else:\n",
    "            print(experiment)\n",
    "            section = 'InterPatch'\n",
    "\n",
    "        if section == 'PostPatch':\n",
    "            active_site['active_patch'] = active_site['active_patch'].shift(-1)\n",
    "            \n",
    "        active_site['end_epoch'] = active_site.index.to_series().shift(-1)\n",
    "        active_site['epoch_duration'] = active_site['end_epoch'] - active_site.index\n",
    "        friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        new_active_site = active_site[active_site['label'] == section]\n",
    "        \n",
    "        session_n += 1\n",
    "        new_active_site['session_n'] = session_n\n",
    "        new_active_site['experiment'] = experiment\n",
    "        \n",
    "        experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        if previous_experiment != experiment:\n",
    "            within_session_number = 0\n",
    "            previous_experiment = experiment\n",
    "        else:\n",
    "            within_session_number += 1\n",
    "\n",
    "        if experiment == 'control':\n",
    "            control_experiment += 1\n",
    "            within_session_number = control_experiment\n",
    "                \n",
    "        new_active_site['within_session_number'] = within_session_number   \n",
    "        new_active_site['actual_friction'] = actual_friction\n",
    "        new_active_site['friction'] = friction\n",
    "        \n",
    "        cum_active_site = pd.concat([cum_active_site, new_active_site])\n",
    "        \n",
    "        velocity = plotting.trial_collection(new_active_site, \n",
    "                                                        encoder_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,10],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col='filtered_velocity')\n",
    "\n",
    "        velocity['cropped'] = velocity.times < min(velocity.groupby('active_patch').times.max())\n",
    "        cum_velocity = pd.concat([cum_velocity, velocity])\n",
    "\n",
    "        torque_data = stream_data.torque_data\n",
    "        brake_data = stream_data.brake_data\n",
    "        \n",
    "        velocity = plotting.trial_collection(new_active_site, \n",
    "                                                        torque_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,10],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col=['Torque'])\n",
    "\n",
    "\n",
    "        velocity_end = plotting.trial_collection(new_active_site, \n",
    "                                                        torque_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        aligned='end_epoch',\n",
    "                                                        window=[-5,2],  \n",
    "                                                        taken_col=['Torque'])\n",
    "        \n",
    "        velocity['align'] = 'onset'\n",
    "        velocity_end['align'] = 'offset'\n",
    "        cum_torque = pd.concat([cum_torque, velocity])\n",
    "        cum_torque = pd.concat([cum_torque, velocity_end])\n",
    "        \n",
    "        data[cum_torque.mouse.unique()[0]] = (cum_torque.loc[(cum_torque['align'] =='onset')&(cum_torque.times>0)&(cum_torque.times<1)&(cum_torque.experiment == 'control')].Torque.mean() - \n",
    "        cum_torque.loc[(cum_torque['align'] =='onset')&(cum_torque.times>0)&(cum_torque.times<1)&(cum_torque.experiment == 'friction')].Torque.mean())\n",
    "        # plt.ylim(0, 40)\n",
    "        \n",
    "        fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "        ax = axes[0]\n",
    "        sns.lineplot(data=new_active_site, x='active_patch', y='epoch_duration', hue='active_patch',  marker='o', ax=ax, legend=False)\n",
    "\n",
    "        ax = axes[1]\n",
    "        sns.lineplot(data=cum_velocity.loc[(cum_velocity.cropped==True)&(cum_velocity.experiment==experiment)], x='times', y='speed', \n",
    "                    hue='active_patch',  errorbar=None, alpha=0.8, ax=ax)\n",
    "        plt.xlim(-1, max(cum_velocity.loc[cum_velocity.cropped==True].times))\n",
    "        plt.ylim(-15, 60)\n",
    "        plt.fill_betweenx([-15, 60], -1, 0, color=color1, alpha=0.2)\n",
    "        plt.fill_betweenx([-15, 60],0, 15, color='grey', alpha=0.2)\n",
    "        plt.xlabel('Time from inter-patch start (s)')\n",
    "        plt.ylabel('Velocity (cm/s)')\n",
    "        plt.title(f'{experiment} { friction} {np.around(actual_friction,2)}')\n",
    "        plt.legend(bbox_to_anchor=(1,0.9), title='Patch #')\n",
    "        plt.suptitle(mouse)\n",
    "        sns.despine()\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parse velocity, time and speed for different sessions and animals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.date.today()\n",
    "date_string = \"08/28/2024\"\n",
    "date = datetime.datetime.strptime(date_string, \"%m/%d/%Y\").date()\n",
    "params_df = pd.read_csv(data_path + 'torque_calibration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plot the data but don't save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.DataFrame()\n",
    "list_experiments = ['control', 'friction', 'friction_15', 'friction_optimized', 'distance_short', 'distance_long', 'distance_extra_short', 'distance_extra_long']\n",
    "for mouse in ['754570','754579','754567','754580','754559','754560','754577','754566','754570','754571','754574','754575', '754582','745302','745305','745301']:\n",
    "    print(mouse)\n",
    "    session_n = 0\n",
    "    active_site_list = []\n",
    "    velocity_list = []\n",
    "    velocity_list_end = []\n",
    "    torque_list = []\n",
    "    within_session_number = 0\n",
    "    control_experiment = 0\n",
    "    previous_experiment = None\n",
    "\n",
    "    directory = os.path.join(base_path, mouse)\n",
    "    files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "    sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "    # All this segment is to find the correct session without having the specific path\n",
    "    for file_name in sorted_files:\n",
    "        start_time = time.time()\n",
    "        # Find specific session sorted by date\n",
    "        session = file_name[-15:-7]\n",
    "        if datetime.datetime.strptime(session, \"%Y%m%d\").date() < date:\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        # Recover data streams\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session_path = Path(session_path)\n",
    "        try:\n",
    "            data = parse.load_session_data(session_path)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        if experiment not in list_experiments:\n",
    "            print(experiment)\n",
    "            continue\n",
    "        try:\n",
    "            friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        except TypeError:\n",
    "            friction = 0\n",
    "        rig_name = data['config'].streams.rig_input.data['rig_name']\n",
    "\n",
    "        # What was the friction applied if we have the friction of the schema? (We have the friction in the schema, we want the reality)\n",
    "        wheel = rig_name\n",
    "        resolved_torque = f.quadratic_model(65535 * friction, params_df.loc[params_df.wheel == wheel].a.values[0], params_df.loc[params_df.wheel == wheel].b.values[0], params_df.loc[params_df.wheel == wheel].c.values[0])    \n",
    "        actual_friction = (params_df.loc[params_df.wheel == wheel].c.values[0] - resolved_torque)/params_df.loc[params_df.wheel == wheel].c.values[0]    \n",
    "        actual_friction *=100    \n",
    "        torque_friction = params_df.loc[params_df.wheel == wheel].c.values[0] - resolved_torque\n",
    "        \n",
    "        if experiment == 'friction' or experiment == 'friction_15' or experiment == 'friction_optimized':\n",
    "            if actual_friction < 8:\n",
    "                experiment = 'friction_low'\n",
    "            elif actual_friction > 8 and actual_friction < 16:\n",
    "                experiment = 'friction_med'\n",
    "            else:\n",
    "                experiment = 'friction_high'\n",
    "        print(experiment, actual_friction)\n",
    "        \n",
    "        # Parse data into a dataframe with the main features\n",
    "        try:\n",
    "            reward_sites, active_site, config = parse.parse_dataframe(data)\n",
    "        except:\n",
    "            continue\n",
    "        # -- At this step you can save the data into a csv file\n",
    "        \n",
    "        if reward_sites.empty:\n",
    "            continue\n",
    "        \n",
    "        # Expand with extra columns\n",
    "        reward_sites = AddExtraColumns(reward_sites, active_site, run_on_init=True).reward_sites\n",
    "        active_site = AddExtraColumns(reward_sites, active_site, run_on_init=False).add_time_previous_intersite_interpatch()\n",
    "\n",
    "        # Load the encoder data separately\n",
    "        stream_data = parse.ContinuousData(data)\n",
    "        encoder_data = stream_data.encoder_data\n",
    "        \n",
    "        # Recover color palette\n",
    "        color_dict_label = {}\n",
    "        dict_odor = {}\n",
    "        list_patches = parse.TaskSchemaProperties(data).patches\n",
    "        for i, patches in enumerate(list_patches):\n",
    "            color_dict_label[patches['label']] = odor_list_color[i]\n",
    "            dict_odor[i] = patches['label']\n",
    "        \n",
    "        if active_site.loc[active_site.label == 'InterPatch'].length.min() == 50:\n",
    "            section = 'PostPatch'\n",
    "        else:\n",
    "            section = 'InterPatch'\n",
    "\n",
    "        if section == 'PostPatch':\n",
    "            active_site['active_patch'] = active_site['active_patch'].shift(-1)\n",
    "            \n",
    "        active_site['end_epoch'] = active_site.index.to_series().shift(-1)\n",
    "        active_site['epoch_duration'] = active_site['end_epoch'] - active_site.index\n",
    "\n",
    "        new_active_site = active_site[active_site['label'] == section]\n",
    "        \n",
    "        session_n += 1\n",
    "        new_active_site['session_n'] = session_n\n",
    "        new_active_site['experiment'] = experiment\n",
    "        try:\n",
    "            friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        except:\n",
    "            friction = 0\n",
    "            \n",
    "        experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        if previous_experiment != experiment:\n",
    "            within_session_number = 0\n",
    "            previous_experiment = experiment\n",
    "        else:\n",
    "            within_session_number += 1\n",
    "\n",
    "        if experiment == 'control':\n",
    "            control_experiment += 1\n",
    "            within_session_number = control_experiment\n",
    "                \n",
    "        new_active_site['within_session_number'] = within_session_number   \n",
    "        actual_friction = np.around(actual_friction,2)\n",
    "\n",
    "        new_active_site['actual_friction'] = actual_friction\n",
    "        new_active_site['torque_friction'] = torque_friction\n",
    "\n",
    "        new_active_site['friction'] = friction\n",
    "        new_active_site['mouse'] = mouse\n",
    "        new_active_site['session'] = session\n",
    "        new_active_site['wheel'] = wheel\n",
    "        \n",
    "        # cum_active_site = pd.concat([cum_active_site, new_active_site])\n",
    "        active_site_list.append(new_active_site)\n",
    "        \n",
    "        velocity = plotting.trial_collection(new_active_site, \n",
    "                                                        encoder_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,2],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col='filtered_velocity')\n",
    "\n",
    "        velocity_end = plotting.trial_collection(new_active_site, \n",
    "                                                        encoder_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,2],  \n",
    "                                                        aligned='end_epoch',\n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col='filtered_velocity')\n",
    "        \n",
    "        if velocity.empty:\n",
    "            continue\n",
    "        \n",
    "        velocity['cropped'] = velocity.times < min(velocity.groupby('active_patch').times.max())\n",
    "        velocity_end['cropped'] = velocity_end.times < min(velocity_end.groupby('active_patch').times.max())\n",
    "\n",
    "        velocity_list.append(velocity)\n",
    "        velocity_list_end.append(velocity_end)\n",
    "\n",
    "        torque_data = stream_data.torque_data\n",
    "        brake_data = stream_data.brake_data\n",
    "        \n",
    "        torque = plotting.trial_collection(new_active_site, \n",
    "                                                        torque_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,10],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col=['Torque'])\n",
    "\n",
    "        \n",
    "        torque_end = plotting.trial_collection(new_active_site, \n",
    "                                                        torque_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        aligned='end_epoch',\n",
    "                                                        window=[-2,1],  \n",
    "                                                        taken_col=['Torque'])\n",
    "        \n",
    "        # velocity['align'] = 'onset'\n",
    "        torque_end['align'] = 'offset'\n",
    "        torque_end['friction'] = actual_friction\n",
    "        torque['align'] = 'onset'\n",
    "        torque['friction'] = actual_friction\n",
    "        torque_list.append(torque)\n",
    "        torque_list.append(torque_end)\n",
    "\n",
    "    cum_active_site = pd.concat(active_site_list)\n",
    "    cum_velocity = pd.concat(velocity_list)\n",
    "    cum_velocity_end = pd.concat(velocity_list_end)\n",
    "    cum_torque = pd.concat(torque_list)\n",
    "    \n",
    "    with PdfPages(os.path.join(results_path, f'{mouse}_torque_velocity_across_sessions_experiments.pdf')) as pdf:\n",
    "        f.epoch_duration_plot(cum_active_site, mouse, save=pdf)\n",
    "        f.plot_velocity_across_sessions(cum_velocity, save=pdf)\n",
    "        f.plot_velocity_across_sessions(cum_velocity_end, save=pdf, xlim = [-2,2])\n",
    "        f.torque_plots(cum_torque, limits=[min(cum_torque.Torque), max(cum_torque.Torque)], save=pdf)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save the data but don't plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.DataFrame()\n",
    "# list_experiments = ['control', 'friction', 'friction_15', 'friction_optimized', 'distance_short', 'distance_long', 'distance_extra_short', 'distance_extra_long']\n",
    "for mouse in ['754570','754579','754567','754580','754559','754560','754577','754566','754570','754571','754574','754575', '754582','745302','745305','745301']:\n",
    "    print(mouse)\n",
    "    session_n = 0\n",
    "    active_site_list = []\n",
    "    velocity_list = []\n",
    "    velocity_list_end = []\n",
    "    torque_list = []\n",
    "    within_session_number = 0\n",
    "    control_experiment = 0\n",
    "    previous_experiment = None\n",
    "\n",
    "    directory = os.path.join(base_path, mouse)\n",
    "    files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "    sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "    # All this segment is to find the correct session without having the specific path\n",
    "    for file_name in sorted_files:\n",
    "        start_time = time.time()\n",
    "        # Find specific session sorted by date\n",
    "        session = file_name[-15:-7]\n",
    "        if datetime.datetime.strptime(session, \"%Y%m%d\").date() < date:\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        # Recover data streams\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session_path = Path(session_path)\n",
    "        try:\n",
    "            data = parse.load_session_data(session_path)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        \n",
    "        try:\n",
    "            friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        except TypeError:\n",
    "            friction = 0\n",
    "        rig_name = data['config'].streams.rig_input.data['rig_name']\n",
    "\n",
    "        # What was the friction applied if we have the friction of the schema? (We have the friction in the schema, we want the reality)\n",
    "        wheel = rig_name\n",
    "        resolved_torque = f.quadratic_model(65535 * friction, params_df.loc[params_df.wheel == wheel].a.values[0], params_df.loc[params_df.wheel == wheel].b.values[0], params_df.loc[params_df.wheel == wheel].c.values[0])    \n",
    "        torque_friction = params_df.loc[params_df.wheel == wheel].c.values[0] - resolved_torque\n",
    "    \n",
    "        if experiment == 'friction' or experiment == 'friction_15' or experiment == 'friction_optimized':\n",
    "            if torque_friction < 120:\n",
    "                experiment = 'friction_low'\n",
    "            elif torque_friction > 120 and torque_friction < 240:\n",
    "                experiment = 'friction_med'\n",
    "            else:\n",
    "                experiment = 'friction_high'\n",
    "        print(experiment, torque_friction)\n",
    "        \n",
    "        # Parse data into a dataframe with the main features\n",
    "        try:\n",
    "            reward_sites, active_site, config = parse.parse_dataframe(data)\n",
    "        except:\n",
    "            continue\n",
    "        # -- At this step you can save the data into a csv file\n",
    "        \n",
    "        if reward_sites.empty:\n",
    "            continue\n",
    "        \n",
    "        # Expand with extra columns\n",
    "        reward_sites = AddExtraColumns(reward_sites, active_site, run_on_init=True).reward_sites\n",
    "        active_site = AddExtraColumns(reward_sites, active_site, run_on_init=False).add_time_previous_intersite_interpatch()\n",
    "\n",
    "        # Load the encoder data separately\n",
    "        stream_data = parse.ContinuousData(data)\n",
    "        encoder_data = stream_data.encoder_data\n",
    "        \n",
    "        if active_site.loc[active_site.label == 'InterPatch'].length.unique()[0] == 50:\n",
    "            section = 'PostPatch'\n",
    "        else:\n",
    "            section = 'InterPatch'\n",
    "\n",
    "        if section == 'PostPatch':\n",
    "            active_site['active_patch'] = active_site['active_patch'].shift(-1)\n",
    "\n",
    "            \n",
    "        active_site['end_epoch'] = active_site.index.to_series().shift(-1)\n",
    "        active_site['epoch_duration'] = active_site['end_epoch'] - active_site.index\n",
    "\n",
    "        new_active_site = active_site[active_site['label'] == section]\n",
    "        new_active_site['experiment'] = experiment\n",
    "        new_active_site['torque_friction'] = torque_friction\n",
    "        new_active_site['friction'] = friction\n",
    "        new_active_site['mouse'] = mouse\n",
    "        new_active_site['session'] = session\n",
    "        new_active_site['wheel'] = wheel\n",
    "        \n",
    "        # cum_active_site = pd.concat([cum_active_site, new_active_site])\n",
    "        active_site_list.append(new_active_site)\n",
    "        \n",
    "        velocity = plotting.trial_collection(new_active_site, \n",
    "                                                        encoder_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,2],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col='filtered_velocity')\n",
    "        \n",
    "        if velocity.empty:\n",
    "            continue\n",
    "        \n",
    "        velocity_list.append(velocity)\n",
    "\n",
    "        torque_data = stream_data.torque_data\n",
    "        brake_data = stream_data.brake_data\n",
    "        \n",
    "        torque = plotting.trial_collection(new_active_site, \n",
    "                                                        torque_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-2,10],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col=['Torque'])\n",
    "\n",
    "        \n",
    "        torque_list.append(torque)\n",
    "\n",
    "    cum_active_site = pd.concat(active_site_list)\n",
    "    cum_velocity = pd.concat(velocity_list)\n",
    "    cum_torque = pd.concat(torque_list)\n",
    "        \n",
    "    group_list = ['mouse','session', 'experiment', 'friction', 'torque_friction', 'active_patch', 'wheel']\n",
    "    acc_df = pd.DataFrame()\n",
    "    \n",
    "    temp_df = cum_torque.loc[(cum_torque['times']> 0)].groupby(group_list).Torque.mean().reset_index()\n",
    "    temp_df.rename(columns={'Torque':'torque_interpatch'}, inplace=True)\n",
    "    acc_df = temp_df\n",
    "    \n",
    "    temp_df = cum_torque.loc[(cum_torque['times']< 0)&(cum_torque['times'] > -2)].groupby(group_list).Torque.mean().reset_index()\n",
    "    temp_df.rename(columns={'Torque':'torque_baseline'}, inplace=True)\n",
    "    acc_df = acc_df.merge(temp_df, on=group_list)\n",
    "\n",
    "    temp_df = cum_velocity.loc[(cum_velocity['times'] > 0)].groupby(group_list).speed.mean().reset_index()\n",
    "    temp_df.rename(columns={'speed':'speed_average'}, inplace=True)\n",
    "    acc_df = acc_df.merge(temp_df, on=group_list)\n",
    "\n",
    "    temp_df = cum_active_site.groupby(group_list).agg({\"epoch_duration\":\"mean\", \"length\":\"mean\"}).reset_index()\n",
    "    acc_df = acc_df.merge(temp_df, on=group_list)\n",
    "\n",
    "    sum_df = pd.concat([acc_df, sum_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = sum_df.sort_values(by=['mouse', 'session']).reset_index(drop=True)\n",
    "sum_df['session_n'] = sum_df.groupby('mouse')['session'].rank(method='dense').astype(int)\n",
    "sum_df.to_csv(os.path.join(results_path, 'batch4_velocity_torque_duration_summary.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Retrieve and plot results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.read_csv(os.path.join(results_path, 'batch4_velocity_torque_duration_summary.csv'), index_col = 0)\n",
    "\n",
    "list_experiments = ['control', 'friction_med', 'friction_low', 'friction_high', 'distance_short', 'distance_long', 'distance_extra_short', 'distance_extra_long']\n",
    "sum_df = sum_df.loc[sum_df.experiment.isin(list_experiments)]\n",
    "\n",
    "sum_df['torque_friction'] = sum_df['torque_friction'].round(2)\n",
    "sum_df['mouse'] = sum_df['mouse'].astype(int)\n",
    "sum_df['session_n'] = sum_df.groupby('mouse')['session_n'].transform(lambda x: x - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the distances in your dataset\n",
    "distances = sum_df['length'].unique()\n",
    "distances.sort()\n",
    "\n",
    "# Create a custom palette using tab20\n",
    "custom_palette = sns.color_palette(\"tab20\", len(distances))\n",
    "\n",
    "# Create a dictionary to map distances to colors\n",
    "distance_color_map = {distance: color for distance, color in zip(distances, custom_palette)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df = pd.read_csv(data_path + 'batch_4_session_df.csv', index_col=0)\n",
    "\n",
    "#Normalize the session number\n",
    "session_df = session_df.loc[session_df.experiment.isin(list_experiments)]\n",
    "session_df['session_n'] = session_df.groupby('mouse')['session_n'].transform(lambda x: x - x.min())\n",
    "\n",
    "mouse_df = pd.read_csv(data_path + 'batch_4_mouse_df.csv', index_col=0)\n",
    "mouse_df = mouse_df.loc[mouse_df.experiment.isin(list_experiments)]\n",
    "mouse_df['session_n'] = mouse_df.groupby('mouse')['session_n'].transform(lambda x: x - x.min())\n",
    "\n",
    "#Normalize the session number\n",
    "mouse_df.drop(columns=['session_n', 'experiment', 'friction'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = ['mouse', 'session', 'active_patch']\n",
    "sum_df = sum_df.merge(mouse_df, on=group_list, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Velocity changes with torque values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,5))\n",
    "\n",
    "test_df = sum_df.loc[(sum_df.mouse != 754570)&(sum_df.mouse != 754574)].groupby(['torque_friction', 'mouse', 'session', 'session_n']).speed_average.mean().reset_index()\n",
    "\n",
    "sns.scatterplot(data=test_df, x='session_n', y='speed_average', hue='torque_friction', palette='magma', ax=ax,  zorder=5)\n",
    "# sns.lineplot(data=test_df, x='session_n', y='speed_average', color='k', ax=ax, alpha=0.5, legend=False)\n",
    "ax.set_ylim(0,60)\n",
    "ax.set_xlabel('Session #')\n",
    "ax.set_ylabel('Speed (cm/s)')\n",
    "plt.legend(bbox_to_anchor=(1,0.9), title='Torque Friction')\n",
    "# ax.set_title(mouse)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(results_path, 'velocity_across_sessions.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,4, figsize=(26,20))\n",
    "\n",
    "for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "    test_df = sum_df.loc[sum_df.mouse == mouse].groupby(['torque_friction', 'session', 'session_n']).speed_average.mean().reset_index()\n",
    "\n",
    "    sns.scatterplot(data=test_df, x='session_n', y='speed_average', hue='torque_friction', palette='magma', ax=ax, legend=False, zorder=5)\n",
    "    sns.lineplot(data=test_df, x='session_n', y='speed_average', color='k', ax=ax, alpha=0.5, legend=False)\n",
    "    ax.set_ylim(0,60)\n",
    "    ax.set_xlabel('Session #')\n",
    "    ax.set_ylabel('Speed (cm/s)')\n",
    "    ax.set_title(mouse)\n",
    "    sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(results_path, 'velocity_across_sessions_mouse.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary torque and distance sessions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,4, figsize=(26,20))\n",
    "for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "    sns.scatterplot(data=sum_df.loc[sum_df.mouse == mouse], x='epoch_duration', y='length', hue='torque_friction', palette='viridis', ax=ax, alpha=0.8)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Distribution of interpatch durations per experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distribution of epoch durations across conditions\n",
    "with PdfPages(os.path.join(results_path, 'distribution of epoch_durations.pdf')) as pdf:\n",
    "    for mouse in sum_df.mouse.unique():\n",
    "        test_df = sum_df.loc[sum_df.mouse == mouse].groupby(['experiment', 'session', 'active_patch']).epoch_duration.median().reset_index()\n",
    "        fig, axes =  plt.subplots(2,3, figsize=(12,8))\n",
    "        for experiment, ax in zip(test_df.experiment.unique(), axes.flatten()):\n",
    "            adjust = sns.histplot(data=test_df.loc[test_df.experiment == experiment], x='epoch_duration', bins=np.arange(0,100,3), ax=ax, legend=False)\n",
    "            # Get the maximum count from the histogram\n",
    "            max_count = max([patch.get_height() for patch in adjust.patches])\n",
    "            ax.vlines(test_df.loc[(test_df.experiment == experiment)].epoch_duration.median(), 0, max_count, color='red')\n",
    "            ax.set_title(experiment)\n",
    "        sns.despine()\n",
    "        plt.suptitle(mouse)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        fig.savefig(pdf, format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(os.path.join(results_path, 'batch4_velocity_torque_duration_summary.pdf')) as pdf:\n",
    "    for mouse in sum_df.mouse.unique():\n",
    "        fig = plt.figure(figsize=(16,8))\n",
    "        fig.add_subplot(2,1,1)\n",
    "        sns.barplot(data=sum_df.loc[sum_df.mouse == mouse], x='session_n', y='epoch_duration', estimator='median', hue='length', palette=distance_color_map)\n",
    "        plot_df = sum_df.loc[sum_df.mouse == mouse].groupby(['session_n', 'experiment', 'torque_friction']).agg({'epoch_duration':'mean'}).reset_index()\n",
    "        sns.scatterplot(data=plot_df, x='session_n', y='epoch_duration', style='torque_friction', color='grey', zorder=5)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., ncol=2)\n",
    "        plt.xticks(ticks=plt.xticks()[0][::5])\n",
    "        plt.title(f'{mouse}')\n",
    "        plt.xlabel('')\n",
    "        plt.xlim(-1, session_df.loc[session_df.mouse == mouse, 'session_n'].max()+2)\n",
    "        plt.ylabel('Epoch \\n duration (s)')\n",
    "        for i in range(0, session_df.loc[session_df.mouse == mouse, 'session_n'].max(), 5):\n",
    "            plt.axvline(x=i, color='black', linestyle='--', alpha=0.5)\n",
    "            \n",
    "        fig.add_subplot(2,1,2)\n",
    "        experiments = session_df['experiment'].unique()\n",
    "        variable = 'reward_probability'\n",
    "        \n",
    "        # Create a style dictionary for each odor label\n",
    "        odor_labels = session_df['odor_label'].unique()\n",
    "        styles = ['o', 's', 'D', '^', 'v', '<', '>', 'p', '*', 'h']\n",
    "        style_dict_odor_label = dict(zip(odor_labels, styles))\n",
    "        \n",
    "        min_value = session_df[variable].min()\n",
    "        max_value = session_df[variable].max()\n",
    "        ax = sns.scatterplot(session_df.loc[(session_df.mouse == mouse)], x='session_n', size=\"visit_number\", hue='experiment', style='odor_label', sizes=(30, 500), y=variable, \n",
    "                palette=palette,  alpha=1,\n",
    "                markers=style_dict_odor_label)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        plt.legend(handles=handles[:len(palette)], labels=labels[:len(palette)], bbox_to_anchor=(1.05, 1), loc='upper left', ncol=1, title='Experiment')\n",
    "        for i in range(0, session_df.loc[session_df.mouse == mouse, 'session_n'].max(), 5):\n",
    "            plt.axvline(x=i, color='black', linestyle='--', alpha=0.5)\n",
    "        plt.ylim(min_value, max_value+0.1)\n",
    "        plt.xlabel('Session number')\n",
    "        plt.xlim(session_df.loc[session_df.mouse == mouse, 'session_n'].min()-1, session_df.loc[session_df.mouse == mouse, 'session_n'].max()+2)\n",
    "        plt.ylabel('Reward probability')\n",
    "        plt.tight_layout()\n",
    "        sns.despine()\n",
    "        pdf.savefig(fig)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "friction = ['control', 'friction_low', 'friction_med', 'friction_high']\n",
    "short = ['control','distance_short', 'distance_extra_short']\n",
    "long = ['control','distance_long', 'distance_extra_long']\n",
    "\n",
    "with PdfPages(os.path.join(results_path, 'batch4_test.pdf')) as pdf:\n",
    "    for plot_experiments, ax in zip([friction, short, long], axes.flatten()):\n",
    "        test_df = sum_df.loc[sum_df.experiment.isin(plot_experiments)]\n",
    "        sns.kdeplot(test_df, x='reward_probability', \n",
    "                    hue='experiment', palette=palette, ax=ax, legend=False,\n",
    "                        common_norm=False, alpha=0.8)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_xlabel('P(reward)')\n",
    "\n",
    "        # Get max y-value (height of the plot)\n",
    "        y_max = ax.get_ylim()[1]\n",
    "\n",
    "        # Plot vertical lines for each experiment\n",
    "        for experiment in test_df['experiment'].unique():\n",
    "            exp_data = test_df.loc[(test_df.experiment == experiment), 'reward_probability']\n",
    "            \n",
    "            if not exp_data.empty:\n",
    "                x_value = exp_data.mean()  # Use median (change to mean if needed)\n",
    "                ax.axvline(x=x_value, color=palette[experiment], linestyle='dashed', linewidth=2, ymax=1)\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(pdf, format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot_experiments in [friction, short, long]:\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "    with PdfPages(os.path.join(results_path, 'batch4_test.pdf')) as pdf:\n",
    "        test_df = sum_df.loc[sum_df.experiment.isin(plot_experiments)]\n",
    "        for mouse, ax in zip(test_df.mouse.unique(), axes.flatten()):\n",
    "            sns.kdeplot(test_df.loc[test_df.mouse == mouse], x='reward_probability', \n",
    "                        hue='experiment', palette=palette, ax=ax, legend=False,\n",
    "                        common_norm=False, alpha=0.8)\n",
    "            ax.set_title(f'{mouse}')\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_xlabel('P(reward)')\n",
    "\n",
    "            # Get max y-value (height of the plot)\n",
    "            y_max = ax.get_ylim()[1]\n",
    "\n",
    "            # Plot vertical lines for each experiment\n",
    "            for experiment in test_df['experiment'].unique():\n",
    "                exp_data = test_df.loc[(test_df.mouse == mouse) & (test_df.experiment == experiment), 'reward_probability']\n",
    "                \n",
    "                if not exp_data.empty:\n",
    "                    x_value = exp_data.median()  # Use median (change to mean if needed)\n",
    "                    ax.axvline(x=x_value, color=palette[experiment], linestyle='dashed', linewidth=1, ymax=1)\n",
    "        sns.despine()\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(pdf, format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7,6), sharey=True, sharex=True)\n",
    "df_results = sum_df.groupby([ 'experiment', 'mouse']).agg({'epoch_duration':'mean'}).reset_index()\n",
    "\n",
    "sns.boxplot(data=df_results, x='experiment', y='epoch_duration', palette=palette, hue='experiment', ax=ax, \n",
    "            order = ['control', 'friction_low', 'friction_med', 'friction_high', 'distance_short',  'distance_extra_short', 'distance_long','distance_extra_long'])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Epoch duration (s)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(results_path, 'epoch_duration_boxplot.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,4, figsize=(26,20), sharey=True, sharex=True)\n",
    "for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "    df_results = sum_df.loc[sum_df.mouse == mouse].groupby(['session', 'experiment']).agg({'epoch_duration':'mean'}).reset_index()\n",
    "\n",
    "    sns.boxplot(data=df_results, x='experiment', y='epoch_duration', palette='viridis', hue='experiment', ax=ax)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explore relationship between torque, distance and time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of epoch duration for control sessions\n",
    "sum_df['normalized_epoch_duration'] = sum_df['epoch_duration']\n",
    "for mouse in sum_df['mouse'].unique():\n",
    "    control_mean = sum_df.loc[(sum_df['mouse'] == mouse) & (sum_df['experiment'] == 'control')].groupby('session_n')['epoch_duration'].median()\n",
    "    mean = np.mean(control_mean)\n",
    "    \n",
    "    # Normalize the epoch duration values\n",
    "    sum_df['normalized_epoch_duration'] = sum_df.apply(\n",
    "        lambda row: (row['epoch_duration'] / mean) if row['mouse'] == mouse else row['normalized_epoch_duration'],\n",
    "        axis=1\n",
    "    )                                                                                                                                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of epoch duration for control sessions\n",
    "sum_df['normalized_torque_friction'] = sum_df['torque_friction']\n",
    "for mouse in sum_df['mouse'].unique():\n",
    "    control_mean = sum_df.loc[(sum_df['mouse'] == mouse)].groupby('session_n')['torque_friction'].max()\n",
    "    mean = np.max(control_mean)\n",
    "    \n",
    "    # Normalize the epoch duration values\n",
    "    sum_df['normalized_torque_friction'] = sum_df.apply(\n",
    "        lambda row: (row['torque_friction'] / mean) if row['mouse'] == mouse else row['normalized_torque_friction'],\n",
    "        axis=1\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the velocity change depending on the inserted torque and distance in the sessiuon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(16, 16))\n",
    "\n",
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_velocity.pdf')) as pdf:\n",
    "    for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "        loop_df = sum_df.loc[sum_df.mouse == mouse].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'speed_average':'mean'}).reset_index()\n",
    "        control_speed = np.mean(sum_df.loc[(sum_df.mouse == mouse)&(sum_df.experiment == 'control')].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'speed_average':'mean'})['speed_average'])\n",
    "        # Define the range for distance and torque\n",
    "        distance = loop_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = loop_df['torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = loop_df['speed_average'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # # Plot the scatter plot\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='viridis', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), loop_df['speed_average'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter = control_speed # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "\n",
    "        heatmap = ax.contourf(X, Y, Z, levels=100, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap, ax=ax)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "\n",
    "        ax.set_xlabel(\"Distance (cm)\")\n",
    "        ax.set_ylabel(\"Torque (a.u.)\")\n",
    "        ax.set_title(mouse)\n",
    "        cbar.set_label(\"Velocity (cm/s)\")\n",
    "        \n",
    "        # Show the plot\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    pdf.savefig(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_velocity_all.pdf')) as pdf:        \n",
    "        test_df = sum_df.groupby(['mouse', 'session_n']).agg({'epoch_duration':'mean', 'length':'mean', 'torque_friction':'mean', 'speed_average':'mean'}).reset_index()\n",
    "        control_speed = np.mean(sum_df.loc[(sum_df.experiment == 'control')].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'speed_average':'mean'})['speed_average'])\n",
    "        \n",
    "        # Define the range for distance and torque\n",
    "        distance = test_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = test_df['torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = test_df['speed_average'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # Plot the scatter plot\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(6, 5))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='coolwarm', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "        # axes[0].set_xlabel(\"Distance (meters)\")\n",
    "        # axes[0].set_ylabel(\"Torque (Nm)\")\n",
    "        # axes[0].set_title(\"Heatmap of Duration by Distance and Torque\")\n",
    "        # cbar.set_label(\"Duration (seconds)\")\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), test_df['speed_average'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter = control_speed  # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "        heatmap = axes.contourf(X, Y, Z, levels=50, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        # selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "        selected_ticks = np.arange(np.around(levels[0], 1), 3.05, 0.4)\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "        \n",
    "        plt.xlabel(\"Distance (cm)\")\n",
    "        plt.ylabel(\"Torque (a.u.)\")\n",
    "        cbar.set_label(\"Velocity (cm/s)\")\n",
    "        \n",
    "        sns.despine()\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        pdf.savefig(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the time it takes to travel change depending on the torque and the distance manipuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(16, 16))\n",
    "\n",
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_time.pdf')) as pdf:\n",
    "    for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "        loop_df = sum_df.loc[sum_df.mouse == mouse].groupby('session_n').agg({'length':'mean', 'normalized_torque_friction':'mean', 'normalized_epoch_duration':'mean'}).reset_index()\n",
    "        \n",
    "        # Define the range for distance and torque\n",
    "        distance = loop_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = loop_df['normalized_torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = loop_df['normalized_epoch_duration'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # # Plot the scatter plot\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='viridis', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), loop_df['normalized_epoch_duration'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter = 1  # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "\n",
    "        heatmap = ax.contourf(X, Y, Z, levels=100, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap, ax=ax)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "\n",
    "        ax.set_xlabel(\"Distance (cm)\")\n",
    "        ax.set_ylabel(\"Torque (a.u.)\")\n",
    "        ax.set_title(mouse)\n",
    "        cbar.set_label(\"Duration (seconds)\")\n",
    "        \n",
    "        # Show the plot\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    pdf.savefig(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_time_all.pdf')) as pdf:        \n",
    "        test_df = sum_df.groupby(['mouse', 'session_n']).agg({'epoch_duration':'mean', 'length':'mean', 'normalized_torque_friction':'mean', 'normalized_epoch_duration':'median'}).reset_index()\n",
    "        \n",
    "        # Define the range for distance and torque\n",
    "        distance = test_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = test_df['normalized_torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = test_df['normalized_epoch_duration'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # Plot the scatter plot\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(6, 5))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='coolwarm', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "        # axes[0].set_xlabel(\"Distance (meters)\")\n",
    "        # axes[0].set_ylabel(\"Torque (Nm)\")\n",
    "        # axes[0].set_title(\"Heatmap of Duration by Distance and Torque\")\n",
    "        # cbar.set_label(\"Duration (seconds)\")\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), test_df['normalized_epoch_duration'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter = 1  # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "        heatmap = axes.contourf(X, Y, Z, levels=50, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "        # selected_ticks = np.arange(np.around(levels[0], 1), 3.05, 0.4)\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "        \n",
    "        plt.xlabel(\"Distance (cm)\")\n",
    "        plt.ylabel(\"Torque (a.u.)\")\n",
    "        cbar.set_label(\"Duration (seconds)\")\n",
    "        \n",
    "        sns.despine()\n",
    "        plt.tight_layout()\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        pdf.savefig(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the preward when leaving change depending on the torque and the distance manipuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(16, 16))\n",
    "\n",
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_preward.pdf')) as pdf:\n",
    "    for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "        loop_df = sum_df.loc[sum_df.mouse == mouse].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'reward_probability':'mean'}).reset_index()\n",
    "        control_preward = np.mean(sum_df.loc[(sum_df.mouse == mouse)&(sum_df.experiment == 'control')].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'reward_probability':'mean'})['reward_probability'])\n",
    "        # Define the range for distance and torque\n",
    "        distance = loop_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = loop_df['torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = loop_df['reward_probability'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # # Plot the scatter plot\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='viridis', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), loop_df['reward_probability'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter =  control_preward # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "\n",
    "        heatmap = ax.contourf(X, Y, Z, levels=100, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap, ax=ax)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "\n",
    "        ax.set_xlabel(\"Distance (cm)\")\n",
    "        ax.set_ylabel(\"Torque (a.u.)\")\n",
    "        ax.set_title(mouse)\n",
    "        cbar.set_label(\"P(reward)\")\n",
    "        \n",
    "        # Show the plot\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    pdf.savefig(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_preward_all.pdf')) as pdf:        \n",
    "        test_df = sum_df.groupby(['mouse', 'session_n']).agg({'epoch_duration':'mean', 'length':'mean', 'normalized_torque_friction':'mean', 'reward_probability':'median'}).reset_index()\n",
    "        control_speed = np.mean(sum_df.loc[(sum_df.experiment == 'control')].groupby('session_n').agg({'length':'mean', 'normalized_torque_friction':'mean', 'reward_probability':'median'})['reward_probability'])\n",
    "        # Define the range for distance and torque\n",
    "        distance = test_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = test_df['normalized_torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = test_df['reward_probability'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # Plot the scatter plot\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(6, 5))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='coolwarm', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "        # axes[0].set_xlabel(\"Distance (meters)\")\n",
    "        # axes[0].set_ylabel(\"Torque (Nm)\")\n",
    "        # axes[0].set_title(\"Heatmap of Duration by Distance and Torque\")\n",
    "        # cbar.set_label(\"Duration (seconds)\")\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), test_df['reward_probability'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter = control_speed  # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "        heatmap = axes.contourf(X, Y, Z, levels=50, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "        # selected_ticks = np.arange(np.around(levels[0], 1), 3.05, 0.4)\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "        \n",
    "        plt.xlabel(\"Distance (cm)\")\n",
    "        plt.ylabel(\"Torque (a.u.)\")\n",
    "        cbar.set_label(\"P(reward)\")\n",
    "        \n",
    "        sns.despine()\n",
    "        plt.tight_layout()\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logitic models: what predicts the moment your will leave?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.genmod.families import links, family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_session(summary_df, predicted='has_choice',\n",
    "                              use_polynomial_features=True, \n",
    "                              orig_features = ['torque_friction', 'speed_average', 'epoch_duration', 'length']):\n",
    "    \n",
    "    for (mouse, session), mouse_df in summary_df.groupby(['mouse', 'session']):\n",
    "        print(f\"Mouse: {mouse}, Session: {session}\")\n",
    "        \n",
    "        # Select features and target variable\n",
    "        X_mouse = mouse_df[orig_features]\n",
    "        y_mouse = mouse_df['reward_probability'].astype(float)\n",
    "        \n",
    "        # Define the pipeline\n",
    "        if use_polynomial_features:\n",
    "            poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "            X_mouse = poly.fit_transform(X_mouse)\n",
    "            features = poly.get_feature_names_out()\n",
    "        else:\n",
    "            features = orig_features\n",
    "        \n",
    "        # Standardize the features\n",
    "        scaler = StandardScaler()\n",
    "        X_mouse_scaled = scaler.fit_transform(X_mouse)\n",
    "\n",
    "        # Perform 5-fold cross-validation\n",
    "        if len(X_mouse_scaled) < 20:\n",
    "            continue\n",
    "        \n",
    "        # if y_mouse.nunique() == 1:\n",
    "        #     continue   \n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True)  # random_state ensures reproducibility\n",
    "        log_reg = LogisticRegression()\n",
    "        # cv_scores = cross_val_score(log_reg, X_mouse_scaled, y_mouse, cv=cv, scoring='roc_auc')\n",
    "\n",
    "        # Fit Beta regression model\n",
    "        model = glm(\"reward_probability ~ torque_friction + speed_average + epoch_duration + length\", data=mouse_df, family=family.Binomial(link=links.logit())).fit()\n",
    "        \n",
    "        print(model.summary())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['torque_friction', 'speed_average', 'epoch_duration', 'length']\n",
    "logistic_session(sum_df.loc[sum_df.experiment == 'data_collection'],\n",
    "                              use_polynomial_features=False, \n",
    "                              orig_features = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.histplot(data=cv_results_df, x='cv_score', multiple='stack', bins=30, color='black', ax=ax[0])\n",
    "sns.histplot(data=cv_results_df, x='cv_std', multiple='stack', bins=30, color='black', ax=ax[1])\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.genmod.families import Gamma\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "features = [\"torque_friction\", \"length\", \"epoch_duration\"]\n",
    "design_matrix = sum_df.loc[sum_df.experiment != 'data_collection'].copy()\n",
    "\n",
    "# Standardize predictors\n",
    "scaler = StandardScaler()\n",
    "design_matrix[features] = scaler.fit_transform(design_matrix[features])\n",
    "\n",
    "# Fit the logistic regression model with standardized predictors\n",
    "formula = \"stops ~ torque_friction + length + epoch_duration\"\n",
    "model = glm(formula=formula, data=design_matrix, family=Gamma(sm.families.links.log())).fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Predicted values\n",
    "design_matrix[\"predicted_p_reward\"] = model.predict(design_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
