{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from aind_vr_foraging_analysis.utils import parse, plotting_utils as plotting, AddExtraColumns\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "color1='#d95f02'\n",
    "color2='#1b9e77'\n",
    "color3='#7570b3'\n",
    "color4='yellow'\n",
    "odor_list_color = [color1, color2, color3, color4]\n",
    "\n",
    "pdf_path = r'Z:\\scratch\\vr-foraging\\sessions'\n",
    "base_path = r'Z:/scratch/vr-foraging/data/'\n",
    "results_path = r'C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\experiments\\batch 4 - manipulating cost of travelling and global statistics\\results'\n",
    "data_path = r'../../../data/'\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import plotting_friction_experiment as f\n",
    "\n",
    "from statsmodels.formula.api import glm\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families import Binomial\n",
    "from statsmodels.genmod.families.links import logit\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **One shot evaluation of time and speed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "torque_data = {}\n",
    "date = datetime.date.today()\n",
    "date_string = \"12/03/2024\"\n",
    "date = datetime.datetime.strptime(date_string, \"%m/%d/%Y\").date()\n",
    "mouse = '754571'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df = pd.read_csv(data_path + 'torque_calibration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_n = 0\n",
    "cum_active_site = pd.DataFrame()\n",
    "cum_velocity = pd.DataFrame()\n",
    "cum_torque = pd.DataFrame()\n",
    "within_session_number = 0\n",
    "control_experiment = 0\n",
    "previous_experiment = None\n",
    "\n",
    "directory = os.path.join(base_path, mouse)\n",
    "files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "# All this segment is to find the correct session without having the specific path\n",
    "for file_name in sorted_files:\n",
    "    # Find specific session sorted by date\n",
    "    session = file_name[-15:-7]\n",
    "    if datetime.datetime.strptime(session, \"%Y%m%d\").date() != date:\n",
    "        continue\n",
    "\n",
    "        \n",
    "    # Recover data streams\n",
    "    session_path = os.path.join(base_path, mouse, file_name)\n",
    "    session_path = Path(session_path)\n",
    "    data = parse.load_session_data(session_path)\n",
    "    \n",
    "    # Parse data into a dataframe with the main features\n",
    "    try:\n",
    "        reward_sites, active_site, config = parse.parse_dataframe(data)\n",
    "    except:\n",
    "        continue\n",
    "    # -- At this step you can save the data into a csv file\n",
    "    \n",
    "    rig_name = data['config'].streams.rig_input.data['rig_name']\n",
    "    # Expand with extra columns\n",
    "    reward_sites = AddExtraColumns(reward_sites, active_site, run_on_init=True).reward_sites\n",
    "    active_site = AddExtraColumns(reward_sites, active_site, run_on_init=False).add_time_previous_intersite_interpatch()\n",
    "\n",
    "    # Load the encoder data separately\n",
    "    stream_data = parse.ContinuousData(data)\n",
    "    encoder_data = stream_data.encoder_data\n",
    "    odor_triggers = stream_data.odor_triggers\n",
    "    software_tone = data['software_events'].streams['ChoiceFeedback'].data.index\n",
    "    choice_tone = stream_data.choice_feedback.index\n",
    "\n",
    "    experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "    \n",
    "    # Recover color palette\n",
    "    color_dict_label = {}\n",
    "    dict_odor = {}\n",
    "    list_patches = parse.TaskSchemaProperties(data).patches\n",
    "    for i, patches in enumerate(list_patches):\n",
    "        color_dict_label[patches['label']] = odor_list_color[i]\n",
    "        dict_odor[i] = patches['label']\n",
    "    \n",
    "    if active_site.loc[active_site.label == 'InterPatch'].length.min() == 50:\n",
    "        section = 'PostPatch'\n",
    "    else:\n",
    "        print(experiment)\n",
    "        section = 'InterPatch'\n",
    "\n",
    "    if section == 'PostPatch':\n",
    "        active_site['active_patch'] = active_site['active_patch'].shift(-1)\n",
    "        \n",
    "    active_site['end_epoch'] = active_site.index.to_series().shift(-1)\n",
    "    active_site['epoch_duration'] = active_site['end_epoch'] - active_site.index\n",
    "    friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "    new_active_site = active_site[active_site['label'] == section]\n",
    "    \n",
    "    # What was the friction applied if we have the friction of the schema? (We have the friction in the schema, we want the reality)\n",
    "    wheel = rig_name\n",
    "    resolved_torque = f.quadratic_model(65535 * friction, params_df.loc[params_df.wheel == wheel].a.values[0], params_df.loc[params_df.wheel == wheel].b.values[0], params_df.loc[params_df.wheel == wheel].c.values[0])    \n",
    "    actual_friction = (params_df.loc[params_df.wheel == wheel].c.values[0] - resolved_torque)/params_df.loc[params_df.wheel == wheel].c.values[0]    \n",
    "    actual_friction *=100    \n",
    "    \n",
    "    session_n += 1\n",
    "    new_active_site['session_n'] = session_n\n",
    "    new_active_site['experiment'] = experiment\n",
    "    \n",
    "    experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "    if previous_experiment != experiment:\n",
    "        within_session_number = 0\n",
    "        previous_experiment = experiment\n",
    "    else:\n",
    "        within_session_number += 1\n",
    "\n",
    "    if experiment == 'control':\n",
    "        control_experiment += 1\n",
    "        within_session_number = control_experiment\n",
    "            \n",
    "    new_active_site['within_session_number'] = within_session_number   \n",
    "        \n",
    "    cum_active_site = pd.concat([cum_active_site, new_active_site])\n",
    "    \n",
    "    velocity = plotting.trial_collection(new_active_site, \n",
    "                                                    encoder_data, \n",
    "                                                    mouse, \n",
    "                                                    session, \n",
    "                                                    window=[-1,10],  \n",
    "                                                    cropped_to_length='epoch',\n",
    "                                                    taken_col='filtered_velocity')\n",
    "\n",
    "    velocity['cropped'] = velocity.times < min(velocity.groupby('active_patch').times.max())\n",
    "    cum_velocity = pd.concat([cum_velocity, velocity])\n",
    "\n",
    "    torque_data = stream_data.torque_data\n",
    "    brake_data = stream_data.brake_data\n",
    "    \n",
    "    velocity = plotting.trial_collection(new_active_site, \n",
    "                                                    torque_data, \n",
    "                                                    mouse, \n",
    "                                                    session, \n",
    "                                                    window=[-1,10],  \n",
    "                                                    cropped_to_length='epoch',\n",
    "                                                    taken_col=['Torque'])\n",
    "\n",
    "\n",
    "    velocity_end = plotting.trial_collection(new_active_site, \n",
    "                                                    torque_data, \n",
    "                                                    mouse, \n",
    "                                                    session, \n",
    "                                                    aligned='end_epoch',\n",
    "                                                    window=[-5,2],  \n",
    "                                                    taken_col=['Torque'])\n",
    "    \n",
    "    velocity['align'] = 'onset'\n",
    "    velocity_end['align'] = 'offset'\n",
    "    cum_torque = pd.concat([cum_torque, velocity])\n",
    "    cum_torque = pd.concat([cum_torque, velocity_end])\n",
    "    \n",
    "    data[cum_torque.mouse.unique()[0]] = (cum_torque.loc[(cum_torque['align'] =='onset')&(cum_torque.times>0)&(cum_torque.times<1)&(cum_torque.experiment == 'control')].Torque.mean() - \n",
    "    cum_torque.loc[(cum_torque['align'] =='onset')&(cum_torque.times>0)&(cum_torque.times<1)&(cum_torque.experiment == 'friction')].Torque.mean())\n",
    "    # plt.ylim(0, 40)\n",
    "    \n",
    "    fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "    ax = axes[0]\n",
    "    sns.lineplot(data=new_active_site, x='active_patch', y='epoch_duration', hue='active_patch',  marker='o', ax=ax, legend=False)\n",
    "\n",
    "    ax = axes[1]\n",
    "    sns.lineplot(data=cum_velocity.loc[(cum_velocity.cropped==True)&(cum_velocity.experiment==experiment)], x='times', y='speed', \n",
    "                hue='active_patch',  errorbar=None, alpha=0.8, ax=ax)\n",
    "    plt.xlim(-1, max(cum_velocity.loc[cum_velocity.cropped==True].times))\n",
    "    plt.ylim(-15, 60)\n",
    "    plt.fill_betweenx([-15, 60], -1, 0, color=color1, alpha=0.2)\n",
    "    plt.fill_betweenx([-15, 60],0, 15, color='grey', alpha=0.2)\n",
    "    plt.xlabel('Time from inter-patch start (s)')\n",
    "    plt.ylabel('Velocity (cm/s)')\n",
    "    plt.title(f'{experiment} { friction} {np.around(actual_friction,2)}')\n",
    "    plt.legend(bbox_to_anchor=(1,0.9), title='Patch #')\n",
    "    plt.suptitle(mouse)\n",
    "    sns.despine()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in ['754570','754579','754567','754580','754559','754560','754577','754566','754570','754571','754574','754575', '754582','745302','745305','745301']:\n",
    "    session_n = 0\n",
    "    cum_active_site = pd.DataFrame()\n",
    "    cum_velocity = pd.DataFrame()\n",
    "    cum_torque = pd.DataFrame()\n",
    "    within_session_number = 0\n",
    "    control_experiment = 0\n",
    "    previous_experiment = None\n",
    "\n",
    "    directory = os.path.join(base_path, mouse)\n",
    "    files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "    sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "    # All this segment is to find the correct session without having the specific path\n",
    "    for file_name in sorted_files:\n",
    "        # Find specific session sorted by date\n",
    "        session = file_name[-15:-7]\n",
    "        if datetime.datetime.strptime(session, \"%Y%m%d\").date() != date:\n",
    "            continue\n",
    "\n",
    "            \n",
    "        # Recover data streams\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session_path = Path(session_path)\n",
    "        data = parse.load_session_data(session_path)\n",
    "        \n",
    "        # Parse data into a dataframe with the main features\n",
    "        try:\n",
    "            reward_sites, active_site, config = parse.parse_dataframe(data)\n",
    "        except:\n",
    "            continue\n",
    "        # -- At this step you can save the data into a csv file\n",
    "        \n",
    "        rig_name = data['config'].streams.rig_input.data['rig_name']\n",
    "\n",
    "        # Expand with extra columns\n",
    "        reward_sites = AddExtraColumns(reward_sites, active_site, run_on_init=True).reward_sites\n",
    "        active_site = AddExtraColumns(reward_sites, active_site, run_on_init=False).add_time_previous_intersite_interpatch()\n",
    "\n",
    "        # Load the encoder data separately\n",
    "        stream_data = parse.ContinuousData(data)\n",
    "        encoder_data = stream_data.encoder_data\n",
    "        odor_triggers = stream_data.odor_triggers\n",
    "        software_tone = data['software_events'].streams['ChoiceFeedback'].data.index\n",
    "        choice_tone = stream_data.choice_feedback.index\n",
    "\n",
    "        friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        new_active_site = active_site[active_site['label'] == section]\n",
    "        \n",
    "        # What was the friction applied if we have the friction of the schema? (We have the friction in the schema, we want the reality)\n",
    "        wheel = rig_name\n",
    "        resolved_torque = f.quadratic_model(65535 * friction, params_df.loc[params_df.wheel == wheel].a.values[0], params_df.loc[params_df.wheel == wheel].b.values[0], params_df.loc[params_df.wheel == wheel].c.values[0])    \n",
    "        actual_friction = (params_df.loc[params_df.wheel == wheel].c.values[0] - resolved_torque)/params_df.loc[params_df.wheel == wheel].c.values[0]    \n",
    "        actual_friction *=100    \n",
    "        \n",
    "        experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        \n",
    "        if experiment == 'friction' or experiment == 'friction_15' or experiment == 'friction_optimized':\n",
    "            if actual_friction < 8:\n",
    "                experiment = 'friction_low'\n",
    "            elif actual_friction > 8 and actual_friction < 16:\n",
    "                experiment = 'friction_med'\n",
    "            else:\n",
    "                experiment = 'friction_high'\n",
    "            \n",
    "        # Recover color palette\n",
    "        color_dict_label = {}\n",
    "        dict_odor = {}\n",
    "        list_patches = parse.TaskSchemaProperties(data).patches\n",
    "        for i, patches in enumerate(list_patches):\n",
    "            color_dict_label[patches['label']] = odor_list_color[i]\n",
    "            dict_odor[i] = patches['label']\n",
    "        \n",
    "        if active_site.loc[active_site.label == 'InterPatch'].length.min() == 50:\n",
    "            section = 'PostPatch'\n",
    "        else:\n",
    "            print(experiment)\n",
    "            section = 'InterPatch'\n",
    "\n",
    "        if section == 'PostPatch':\n",
    "            active_site['active_patch'] = active_site['active_patch'].shift(-1)\n",
    "            \n",
    "        active_site['end_epoch'] = active_site.index.to_series().shift(-1)\n",
    "        active_site['epoch_duration'] = active_site['end_epoch'] - active_site.index\n",
    "        friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        new_active_site = active_site[active_site['label'] == section]\n",
    "        \n",
    "        session_n += 1\n",
    "        new_active_site['session_n'] = session_n\n",
    "        new_active_site['experiment'] = experiment\n",
    "        \n",
    "        experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        if previous_experiment != experiment:\n",
    "            within_session_number = 0\n",
    "            previous_experiment = experiment\n",
    "        else:\n",
    "            within_session_number += 1\n",
    "\n",
    "        if experiment == 'control':\n",
    "            control_experiment += 1\n",
    "            within_session_number = control_experiment\n",
    "                \n",
    "        new_active_site['within_session_number'] = within_session_number   \n",
    "        new_active_site['actual_friction'] = actual_friction\n",
    "        new_active_site['friction'] = friction\n",
    "        \n",
    "        cum_active_site = pd.concat([cum_active_site, new_active_site])\n",
    "        \n",
    "        velocity = plotting.trial_collection(new_active_site, \n",
    "                                                        encoder_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,10],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col='filtered_velocity')\n",
    "\n",
    "        velocity['cropped'] = velocity.times < min(velocity.groupby('active_patch').times.max())\n",
    "        cum_velocity = pd.concat([cum_velocity, velocity])\n",
    "\n",
    "        torque_data = stream_data.torque_data\n",
    "        brake_data = stream_data.brake_data\n",
    "        \n",
    "        velocity = plotting.trial_collection(new_active_site, \n",
    "                                                        torque_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,10],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col=['Torque'])\n",
    "\n",
    "\n",
    "        velocity_end = plotting.trial_collection(new_active_site, \n",
    "                                                        torque_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        aligned='end_epoch',\n",
    "                                                        window=[-5,2],  \n",
    "                                                        taken_col=['Torque'])\n",
    "        \n",
    "        velocity['align'] = 'onset'\n",
    "        velocity_end['align'] = 'offset'\n",
    "        cum_torque = pd.concat([cum_torque, velocity])\n",
    "        cum_torque = pd.concat([cum_torque, velocity_end])\n",
    "        \n",
    "        data[cum_torque.mouse.unique()[0]] = (cum_torque.loc[(cum_torque['align'] =='onset')&(cum_torque.times>0)&(cum_torque.times<1)&(cum_torque.experiment == 'control')].Torque.mean() - \n",
    "        cum_torque.loc[(cum_torque['align'] =='onset')&(cum_torque.times>0)&(cum_torque.times<1)&(cum_torque.experiment == 'friction')].Torque.mean())\n",
    "        # plt.ylim(0, 40)\n",
    "        \n",
    "        fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "        ax = axes[0]\n",
    "        sns.lineplot(data=new_active_site, x='active_patch', y='epoch_duration', hue='active_patch',  marker='o', ax=ax, legend=False)\n",
    "\n",
    "        ax = axes[1]\n",
    "        sns.lineplot(data=cum_velocity.loc[(cum_velocity.cropped==True)&(cum_velocity.experiment==experiment)], x='times', y='speed', \n",
    "                    hue='active_patch',  errorbar=None, alpha=0.8, ax=ax)\n",
    "        plt.xlim(-1, max(cum_velocity.loc[cum_velocity.cropped==True].times))\n",
    "        plt.ylim(-15, 60)\n",
    "        plt.fill_betweenx([-15, 60], -1, 0, color=color1, alpha=0.2)\n",
    "        plt.fill_betweenx([-15, 60],0, 15, color='grey', alpha=0.2)\n",
    "        plt.xlabel('Time from inter-patch start (s)')\n",
    "        plt.ylabel('Velocity (cm/s)')\n",
    "        plt.title(f'{experiment} { friction} {np.around(actual_friction,2)}')\n",
    "        plt.legend(bbox_to_anchor=(1,0.9), title='Patch #')\n",
    "        plt.suptitle(mouse)\n",
    "        sns.despine()\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.torque_plots(cum_torque, limits=[min(cum_torque.Torque), max(cum_torque.Torque)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.plot_velocity_across_sessions(cum_velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.epoch_duration_plot(cum_active_site, mouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parse velocity, time and speed for different sessions and animals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.date.today()\n",
    "date_string = \"08/28/2024\"\n",
    "date = datetime.datetime.strptime(date_string, \"%m/%d/%Y\").date()\n",
    "params_df = pd.read_csv(data_path + 'torque_calibration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plot the data but don't save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.DataFrame()\n",
    "list_experiments = ['control', 'friction', 'friction_15', 'friction_optimized', 'distance_short', 'distance_long', 'distance_extra_short', 'distance_extra_long']\n",
    "for mouse in ['754570','754579','754567','754580','754559','754560','754577','754566','754570','754571','754574','754575', '754582','745302','745305','745301']:\n",
    "    print(mouse)\n",
    "    session_n = 0\n",
    "    active_site_list = []\n",
    "    velocity_list = []\n",
    "    velocity_list_end = []\n",
    "    torque_list = []\n",
    "    within_session_number = 0\n",
    "    control_experiment = 0\n",
    "    previous_experiment = None\n",
    "\n",
    "    directory = os.path.join(base_path, mouse)\n",
    "    files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "    sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "    # All this segment is to find the correct session without having the specific path\n",
    "    for file_name in sorted_files:\n",
    "        start_time = time.time()\n",
    "        # Find specific session sorted by date\n",
    "        session = file_name[-15:-7]\n",
    "        if datetime.datetime.strptime(session, \"%Y%m%d\").date() < date:\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        # Recover data streams\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session_path = Path(session_path)\n",
    "        try:\n",
    "            data = parse.load_session_data(session_path)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        if experiment not in list_experiments:\n",
    "            print(experiment)\n",
    "            continue\n",
    "        try:\n",
    "            friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        except TypeError:\n",
    "            friction = 0\n",
    "        rig_name = data['config'].streams.rig_input.data['rig_name']\n",
    "\n",
    "        # What was the friction applied if we have the friction of the schema? (We have the friction in the schema, we want the reality)\n",
    "        wheel = rig_name\n",
    "        resolved_torque = f.quadratic_model(65535 * friction, params_df.loc[params_df.wheel == wheel].a.values[0], params_df.loc[params_df.wheel == wheel].b.values[0], params_df.loc[params_df.wheel == wheel].c.values[0])    \n",
    "        actual_friction = (params_df.loc[params_df.wheel == wheel].c.values[0] - resolved_torque)/params_df.loc[params_df.wheel == wheel].c.values[0]    \n",
    "        actual_friction *=100    \n",
    "        torque_friction = params_df.loc[params_df.wheel == wheel].c.values[0] - resolved_torque\n",
    "        \n",
    "        if experiment == 'friction' or experiment == 'friction_15' or experiment == 'friction_optimized':\n",
    "            if actual_friction < 8:\n",
    "                experiment = 'friction_low'\n",
    "            elif actual_friction > 8 and actual_friction < 16:\n",
    "                experiment = 'friction_med'\n",
    "            else:\n",
    "                experiment = 'friction_high'\n",
    "        print(experiment, actual_friction)\n",
    "        \n",
    "        # Parse data into a dataframe with the main features\n",
    "        try:\n",
    "            reward_sites, active_site, config = parse.parse_dataframe(data)\n",
    "        except:\n",
    "            continue\n",
    "        # -- At this step you can save the data into a csv file\n",
    "        \n",
    "        if reward_sites.empty:\n",
    "            continue\n",
    "        \n",
    "        # Expand with extra columns\n",
    "        reward_sites = AddExtraColumns(reward_sites, active_site, run_on_init=True).reward_sites\n",
    "        active_site = AddExtraColumns(reward_sites, active_site, run_on_init=False).add_time_previous_intersite_interpatch()\n",
    "\n",
    "        # Load the encoder data separately\n",
    "        stream_data = parse.ContinuousData(data)\n",
    "        encoder_data = stream_data.encoder_data\n",
    "        \n",
    "        # Recover color palette\n",
    "        color_dict_label = {}\n",
    "        dict_odor = {}\n",
    "        list_patches = parse.TaskSchemaProperties(data).patches\n",
    "        for i, patches in enumerate(list_patches):\n",
    "            color_dict_label[patches['label']] = odor_list_color[i]\n",
    "            dict_odor[i] = patches['label']\n",
    "        \n",
    "        if active_site.loc[active_site.label == 'InterPatch'].length.min() == 50:\n",
    "            section = 'PostPatch'\n",
    "        else:\n",
    "            section = 'InterPatch'\n",
    "\n",
    "        if section == 'PostPatch':\n",
    "            active_site['active_patch'] = active_site['active_patch'].shift(-1)\n",
    "            \n",
    "        active_site['end_epoch'] = active_site.index.to_series().shift(-1)\n",
    "        active_site['epoch_duration'] = active_site['end_epoch'] - active_site.index\n",
    "\n",
    "        new_active_site = active_site[active_site['label'] == section]\n",
    "        \n",
    "        session_n += 1\n",
    "        new_active_site['session_n'] = session_n\n",
    "        new_active_site['experiment'] = experiment\n",
    "        try:\n",
    "            friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        except:\n",
    "            friction = 0\n",
    "            \n",
    "        experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        if previous_experiment != experiment:\n",
    "            within_session_number = 0\n",
    "            previous_experiment = experiment\n",
    "        else:\n",
    "            within_session_number += 1\n",
    "\n",
    "        if experiment == 'control':\n",
    "            control_experiment += 1\n",
    "            within_session_number = control_experiment\n",
    "                \n",
    "        new_active_site['within_session_number'] = within_session_number   \n",
    "        actual_friction = np.around(actual_friction,2)\n",
    "\n",
    "        new_active_site['actual_friction'] = actual_friction\n",
    "        new_active_site['torque_friction'] = torque_friction\n",
    "\n",
    "        new_active_site['friction'] = friction\n",
    "        new_active_site['mouse'] = mouse\n",
    "        new_active_site['session'] = session\n",
    "        new_active_site['wheel'] = wheel\n",
    "        \n",
    "        # cum_active_site = pd.concat([cum_active_site, new_active_site])\n",
    "        active_site_list.append(new_active_site)\n",
    "        \n",
    "        velocity = plotting.trial_collection(new_active_site, \n",
    "                                                        encoder_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,2],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col='filtered_velocity')\n",
    "\n",
    "        velocity_end = plotting.trial_collection(new_active_site, \n",
    "                                                        encoder_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,2],  \n",
    "                                                        aligned='end_epoch',\n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col='filtered_velocity')\n",
    "        \n",
    "        if velocity.empty:\n",
    "            continue\n",
    "        \n",
    "        velocity['cropped'] = velocity.times < min(velocity.groupby('active_patch').times.max())\n",
    "        velocity_end['cropped'] = velocity_end.times < min(velocity_end.groupby('active_patch').times.max())\n",
    "\n",
    "        velocity_list.append(velocity)\n",
    "        velocity_list_end.append(velocity_end)\n",
    "\n",
    "        torque_data = stream_data.torque_data\n",
    "        brake_data = stream_data.brake_data\n",
    "        \n",
    "        torque = plotting.trial_collection(new_active_site, \n",
    "                                                        torque_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,10],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col=['Torque'])\n",
    "\n",
    "        \n",
    "        torque_end = plotting.trial_collection(new_active_site, \n",
    "                                                        torque_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        aligned='end_epoch',\n",
    "                                                        window=[-2,1],  \n",
    "                                                        taken_col=['Torque'])\n",
    "        \n",
    "        # velocity['align'] = 'onset'\n",
    "        torque_end['align'] = 'offset'\n",
    "        torque_end['friction'] = actual_friction\n",
    "        torque['align'] = 'onset'\n",
    "        torque['friction'] = actual_friction\n",
    "        torque_list.append(torque)\n",
    "        torque_list.append(torque_end)\n",
    "\n",
    "    cum_active_site = pd.concat(active_site_list)\n",
    "    cum_velocity = pd.concat(velocity_list)\n",
    "    cum_velocity_end = pd.concat(velocity_list_end)\n",
    "    cum_torque = pd.concat(torque_list)\n",
    "    \n",
    "    with PdfPages(os.path.join(results_path, f'{mouse}_torque_velocity_across_sessions_experiments.pdf')) as pdf:\n",
    "        f.epoch_duration_plot(cum_active_site, mouse, save=pdf)\n",
    "        f.plot_velocity_across_sessions(cum_velocity, save=pdf)\n",
    "        f.plot_velocity_across_sessions(cum_velocity_end, save=pdf, xlim = [-2,2])\n",
    "        f.torque_plots(cum_torque, limits=[min(cum_torque.Torque), max(cum_torque.Torque)], save=pdf)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save the data but don't plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.DataFrame()\n",
    "# list_experiments = ['control', 'friction', 'friction_15', 'friction_optimized', 'distance_short', 'distance_long', 'distance_extra_short', 'distance_extra_long']\n",
    "for mouse in ['754570','754579','754567','754580','754559','754560','754577','754566','754570','754571','754574','754575', '754582','745302','745305','745301']:\n",
    "    print(mouse)\n",
    "    session_n = 0\n",
    "    active_site_list = []\n",
    "    velocity_list = []\n",
    "    velocity_list_end = []\n",
    "    torque_list = []\n",
    "    within_session_number = 0\n",
    "    control_experiment = 0\n",
    "    previous_experiment = None\n",
    "\n",
    "    directory = os.path.join(base_path, mouse)\n",
    "    files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "    sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "    # All this segment is to find the correct session without having the specific path\n",
    "    for file_name in sorted_files:\n",
    "        start_time = time.time()\n",
    "        # Find specific session sorted by date\n",
    "        session = file_name[-15:-7]\n",
    "        if datetime.datetime.strptime(session, \"%Y%m%d\").date() < date:\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        # Recover data streams\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session_path = Path(session_path)\n",
    "        try:\n",
    "            data = parse.load_session_data(session_path)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        \n",
    "        try:\n",
    "            friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        except TypeError:\n",
    "            friction = 0\n",
    "        rig_name = data['config'].streams.rig_input.data['rig_name']\n",
    "\n",
    "        # What was the friction applied if we have the friction of the schema? (We have the friction in the schema, we want the reality)\n",
    "        wheel = rig_name\n",
    "        resolved_torque = f.quadratic_model(65535 * friction, params_df.loc[params_df.wheel == wheel].a.values[0], params_df.loc[params_df.wheel == wheel].b.values[0], params_df.loc[params_df.wheel == wheel].c.values[0])    \n",
    "        torque_friction = params_df.loc[params_df.wheel == wheel].c.values[0] - resolved_torque\n",
    "    \n",
    "        if experiment == 'friction' or experiment == 'friction_15' or experiment == 'friction_optimized':\n",
    "            if torque_friction < 120:\n",
    "                experiment = 'friction_low'\n",
    "            elif torque_friction > 120 and torque_friction < 240:\n",
    "                experiment = 'friction_med'\n",
    "            else:\n",
    "                experiment = 'friction_high'\n",
    "        print(experiment, torque_friction)\n",
    "        \n",
    "        # Parse data into a dataframe with the main features\n",
    "        try:\n",
    "            reward_sites, active_site, config = parse.parse_dataframe(data)\n",
    "        except:\n",
    "            continue\n",
    "        # -- At this step you can save the data into a csv file\n",
    "        \n",
    "        if reward_sites.empty:\n",
    "            continue\n",
    "        \n",
    "        # Expand with extra columns\n",
    "        reward_sites = AddExtraColumns(reward_sites, active_site, run_on_init=True).reward_sites\n",
    "        active_site = AddExtraColumns(reward_sites, active_site, run_on_init=False).add_time_previous_intersite_interpatch()\n",
    "\n",
    "        # Load the encoder data separately\n",
    "        stream_data = parse.ContinuousData(data)\n",
    "        encoder_data = stream_data.encoder_data\n",
    "        \n",
    "        if active_site.loc[active_site.label == 'InterPatch'].length.unique()[0] == 50:\n",
    "            section = 'PostPatch'\n",
    "        else:\n",
    "            section = 'InterPatch'\n",
    "\n",
    "        if section == 'PostPatch':\n",
    "            active_site['active_patch'] = active_site['active_patch'].shift(-1)\n",
    "\n",
    "        try:\n",
    "            friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        except:\n",
    "            friction = 0\n",
    "            \n",
    "        active_site['end_epoch'] = active_site.index.to_series().shift(-1)\n",
    "        active_site['epoch_duration'] = active_site['end_epoch'] - active_site.index\n",
    "\n",
    "        new_active_site = active_site[active_site['label'] == section]\n",
    "        new_active_site['experiment'] = experiment\n",
    "        new_active_site['torque_friction'] = torque_friction\n",
    "        new_active_site['friction'] = friction\n",
    "        new_active_site['mouse'] = mouse\n",
    "        new_active_site['session'] = session\n",
    "        new_active_site['wheel'] = wheel\n",
    "        \n",
    "        # cum_active_site = pd.concat([cum_active_site, new_active_site])\n",
    "        active_site_list.append(new_active_site)\n",
    "        \n",
    "        velocity = plotting.trial_collection(new_active_site, \n",
    "                                                        encoder_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,2],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col='filtered_velocity')\n",
    "        \n",
    "        if velocity.empty:\n",
    "            continue\n",
    "        \n",
    "        velocity_list.append(velocity)\n",
    "\n",
    "        torque_data = stream_data.torque_data\n",
    "        brake_data = stream_data.brake_data\n",
    "        \n",
    "        torque = plotting.trial_collection(new_active_site, \n",
    "                                                        torque_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-2,10],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col=['Torque'])\n",
    "\n",
    "        \n",
    "        torque_list.append(torque)\n",
    "\n",
    "    cum_active_site = pd.concat(active_site_list)\n",
    "    cum_velocity = pd.concat(velocity_list)\n",
    "    cum_torque = pd.concat(torque_list)\n",
    "        \n",
    "    group_list = ['mouse','session', 'experiment', 'friction', 'torque_friction', 'active_patch', 'wheel']\n",
    "    acc_df = pd.DataFrame()\n",
    "    \n",
    "    temp_df = cum_torque.loc[(cum_torque['times']> 0)].groupby(group_list).Torque.mean().reset_index()\n",
    "    temp_df.rename(columns={'Torque':'torque_interpatch'}, inplace=True)\n",
    "    acc_df = temp_df\n",
    "    \n",
    "    temp_df = cum_torque.loc[(cum_torque['times']< 0)&(cum_torque['times'] > -2)].groupby(group_list).Torque.mean().reset_index()\n",
    "    temp_df.rename(columns={'Torque':'torque_baseline'}, inplace=True)\n",
    "    acc_df = acc_df.merge(temp_df, on=group_list)\n",
    "\n",
    "    temp_df = cum_velocity.loc[(cum_velocity['times'] > 0)].groupby(group_list).speed.mean().reset_index()\n",
    "    temp_df.rename(columns={'speed':'speed_average'}, inplace=True)\n",
    "    acc_df = acc_df.merge(temp_df, on=group_list)\n",
    "\n",
    "    temp_df = cum_active_site.groupby(group_list).agg({\"epoch_duration\":\"mean\", \"length\":\"mean\"}).reset_index()\n",
    "    acc_df = acc_df.merge(temp_df, on=group_list)\n",
    "\n",
    "    sum_df = pd.concat([acc_df, sum_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = sum_df.sort_values(by=['mouse', 'session']).reset_index(drop=True)\n",
    "sum_df['session_n'] = sum_df.groupby('mouse')['session'].rank(method='dense').astype(int)\n",
    "sum_df.to_csv(os.path.join(results_path, 'batch4_velocity_torque_duration_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the distances in your dataset\n",
    "torques = sum_df['torque_baseline'].unique()\n",
    "torques.sort()\n",
    "\n",
    "# Create a custom palette using tab20\n",
    "custom_palette = sns.color_palette(\"tab20\", len(torques))\n",
    "\n",
    "# Create a dictionary to map distances to colors\n",
    "distance_color_map = {torques: color for torques, color in zip(torques, custom_palette)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3, figsize=(16,10))\n",
    "for wheel, ax in zip(sum_df.wheel.unique(), axes.flatten()):\n",
    "    test = sum_df.loc[sum_df.wheel == wheel].groupby(['session_enum', 'experiment']).torque_baseline.mean().reset_index()\n",
    "    sns.boxplot(data=test, x='session_enum', y='torque_baseline', hue='experiment', ax=ax, palette='tab20', legend=False)\n",
    "    ax.set_ylim(0, 2500)\n",
    "    ax.set_title(wheel)\n",
    "# # Manually create the legend\n",
    "# sum_df.groupby(['mouse', 'session_enum', 'experiment']).torque_baseline.mean().reset_index()\n",
    "# handles = []\n",
    "# for regressor, color in zip(distance_color_map, sns.color_palette('tab20', sum_df.torque_baseline.nunique())):\n",
    "#     handles.append(mpatches.Patch(color=color, label=regressor))\n",
    "# fig.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc=1, borderaxespad=0., title='Features', prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3, figsize=(16,10))\n",
    "for wheel, ax in zip(sum_df.wheel.unique(), axes.flatten()):\n",
    "    test = sum_df.loc[sum_df.wheel == wheel].groupby(['session_enum', 'mouse']).torque_baseline.mean().reset_index()\n",
    "    sns.boxplot(data=test, x='session_enum', y='torque_baseline', ax=ax, palette='tab20', legend=False)\n",
    "    ax.set_ylim(1500, 2500)\n",
    "    ax.set_title(wheel)\n",
    "    ax.set_xticks(np.arange(0, len(test.session_enum.unique()),10))\n",
    "# # Manually create the legend\n",
    "# sum_df.groupby(['mouse', 'session_enum', 'experiment']).torque_baseline.mean().reset_index()\n",
    "# handles = []\n",
    "# for regressor, color in zip(distance_color_map, sns.color_palette('tab20', sum_df.torque_baseline.nunique())):\n",
    "#     handles.append(mpatches.Patch(color=color, label=regressor))\n",
    "# fig.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc=1, borderaxespad=0., title='Features', prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Retrieve and plot results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.read_csv(os.path.join(results_path, 'batch4_velocity_torque_duration_summary.csv'), index_col = 0)\n",
    "\n",
    "list_experiments = ['control', 'friction_med', 'friction_low', 'friction_high', 'distance_short', 'distance_long', 'distance_extra_short', 'distance_extra_long']\n",
    "sum_df = sum_df.loc[sum_df.experiment.isin(list_experiments)]\n",
    "\n",
    "sum_df['torque_friction'] = sum_df['torque_friction'].round(2)\n",
    "sum_df['mouse'] = sum_df['mouse'].astype(int)\n",
    "\n",
    "sum_df['session_n'] = sum_df.groupby('mouse')['session_n'].transform(lambda x: x - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the distances in your dataset\n",
    "distances = sum_df['length'].unique()\n",
    "distances.sort()\n",
    "\n",
    "# Create a custom palette using tab20\n",
    "custom_palette = sns.color_palette(\"tab20\", len(distances))\n",
    "\n",
    "# Create a dictionary to map distances to colors\n",
    "distance_color_map = {distance: color for distance, color in zip(distances, custom_palette)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,4, figsize=(26,20))\n",
    "\n",
    "for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "    test_df = sum_df.loc[sum_df.mouse == mouse].groupby(['torque_friction', 'session', 'session_n']).speed_average.mean().reset_index()\n",
    "\n",
    "    sns.scatterplot(data=test_df, x='session_n', y='speed_average', hue='torque_friction', palette='magma', ax=ax, legend=False, zorder=5)\n",
    "    sns.lineplot(data=test_df, x='session_n', y='speed_average', color='k', ax=ax, alpha=0.5, legend=False)\n",
    "    ax.set_ylim(0,60)\n",
    "    ax.set_title(mouse)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(results_path, 'batch4_velocity_across_sessions.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df = pd.read_csv(data_path + 'batch_4_session_df.csv', index_col=0)\n",
    "#Normalize the session number\n",
    "session_df = session_df.loc[session_df.experiment.isin(list_experiments)]\n",
    "session_df['session_n'] = session_df.groupby('mouse')['session_n'].transform(lambda x: x - x.min())\n",
    "\n",
    "mouse_df = pd.read_csv(data_path + 'batch_4_mouse_df.csv', index_col=0)\n",
    "mouse_df = mouse_df.loc[mouse_df.experiment.isin(list_experiments)]\n",
    "#Normalize the session number\n",
    "mouse_df.drop(columns=['session_n', 'experiment', 'friction'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = ['mouse', 'session', 'active_patch']\n",
    "sum_df = sum_df.merge(mouse_df, on=group_list, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary torque and distance sessions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,4, figsize=(26,20))\n",
    "for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "    sns.scatterplot(data=sum_df.loc[sum_df.mouse == mouse], x='epoch_duration', y='length', hue='torque_friction', palette='viridis', ax=ax, alpha=0.8)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Distribution of interpatch durations per experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distribution of epoch durations across conditions\n",
    "with PdfPages(os.path.join(results_path, f'distribution of epoch_durations.pdf')) as pdf:\n",
    "    for mouse in sum_df.mouse.unique():\n",
    "        test_df = sum_df.loc[sum_df.mouse == mouse].groupby(['experiment', 'session', 'active_patch']).epoch_duration.median().reset_index()\n",
    "        fig, axes =  plt.subplots(2,3, figsize=(12,8))\n",
    "        for experiment, ax in zip(test_df.experiment.unique(), axes.flatten()):\n",
    "            adjust = sns.histplot(data=test_df.loc[test_df.experiment == experiment], x='epoch_duration', bins=np.arange(0,100,3), ax=ax, legend=False)\n",
    "            # Get the maximum count from the histogram\n",
    "            max_count = max([patch.get_height() for patch in adjust.patches])\n",
    "            ax.vlines(test_df.loc[(test_df.experiment == experiment)].epoch_duration.median(), 0, max_count, color='red')\n",
    "            ax.set_title(experiment)\n",
    "        sns.despine()\n",
    "        plt.suptitle(mouse)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        fig.savefig(pdf, format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(os.path.join(results_path, 'batch4_velocity_torque_duration_summary.pdf')) as pdf:\n",
    "    for mouse in sum_df.mouse.unique():\n",
    "        fig = plt.figure(figsize=(16,8))\n",
    "        fig.add_subplot(2,1,1)\n",
    "        sns.barplot(data=sum_df.loc[sum_df.mouse == mouse], x='session_n', y='epoch_duration', estimator='median', hue='length', palette=distance_color_map)\n",
    "        plot_df = sum_df.loc[sum_df.mouse == mouse].groupby(['session_n', 'experiment', 'torque_friction']).agg({'epoch_duration':'mean'}).reset_index()\n",
    "        sns.scatterplot(data=plot_df, x='session_n', y='epoch_duration', style='torque_friction', color='grey', zorder=5)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., ncol=2)\n",
    "        plt.xticks(ticks=plt.xticks()[0][::5])\n",
    "        plt.title(f'{mouse}')\n",
    "        plt.xlabel('')\n",
    "        plt.xlim(-1, session_df.loc[session_df.mouse == mouse, 'session_n'].max()+2)\n",
    "        plt.ylabel('Epoch \\n duration (s)')\n",
    "        for i in range(0, session_df.loc[session_df.mouse == mouse, 'session_n'].max(), 5):\n",
    "            plt.axvline(x=i, color='black', linestyle='--', alpha=0.5)\n",
    "            \n",
    "        fig.add_subplot(2,1,2)\n",
    "        experiments = session_df['experiment'].unique()\n",
    "        palette = sns.color_palette(\"tab10\", len(experiments))\n",
    "        color_dict_experiment = dict(zip(experiments, palette))\n",
    "        variable = 'reward_probability'\n",
    "        \n",
    "        # Create a style dictionary for each odor label\n",
    "        odor_labels = session_df['odor_label'].unique()\n",
    "        styles = ['o', 's', 'D', '^', 'v', '<', '>', 'p', '*', 'h']\n",
    "        style_dict_odor_label = dict(zip(odor_labels, styles))\n",
    "        \n",
    "        min_value = session_df[variable].min()\n",
    "        max_value = session_df[variable].max()\n",
    "        ax = sns.scatterplot(session_df.loc[(session_df.mouse == mouse)], x='session_n', size=\"visit_number\", hue='experiment', style='odor_label', sizes=(30, 500), y=variable, \n",
    "                palette=color_dict_experiment,  alpha=0.7,\n",
    "                markers=style_dict_odor_label)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        plt.legend(handles=handles[:len(color_dict_experiment)], labels=labels[:len(color_dict_experiment)], bbox_to_anchor=(1.05, 1), loc='upper left', ncol=1, title='Experiment')\n",
    "        for i in range(0, session_df.loc[session_df.mouse == mouse, 'session_n'].max(), 5):\n",
    "            plt.axvline(x=i, color='black', linestyle='--', alpha=0.5)\n",
    "        plt.ylim(min_value, max_value)\n",
    "        plt.xlabel('Session number')\n",
    "        plt.xlim(session_df.loc[session_df.mouse == mouse, 'session_n'].min()-1, session_df.loc[session_df.mouse == mouse, 'session_n'].max()+2)\n",
    "        plt.ylabel('Reward probability')\n",
    "        plt.tight_layout()\n",
    "        sns.despine()\n",
    "        pdf.savefig(fig)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,4, figsize=(26,20), sharey=True, sharex=True)\n",
    "for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "    df_results = sum_df.loc[sum_df.mouse == mouse].groupby(['session', 'experiment']).agg({'epoch_duration':'mean'}).reset_index()\n",
    "\n",
    "    sns.boxplot(data=df_results, x='experiment', y='epoch_duration', palette='viridis', hue='experiment', ax=ax)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explore relationship between torque, distance and time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of epoch duration for control sessions\n",
    "sum_df['normalized_epoch_duration'] = sum_df['epoch_duration']\n",
    "for mouse in sum_df['mouse'].unique():\n",
    "    control_mean = sum_df.loc[(sum_df['mouse'] == mouse) & (sum_df['experiment'] == 'control')].groupby('session_n')['epoch_duration'].median()\n",
    "    mean = np.mean(control_mean)\n",
    "    \n",
    "    # Normalize the epoch duration values\n",
    "    sum_df['normalized_epoch_duration'] = sum_df.apply(\n",
    "        lambda row: (row['epoch_duration'] / mean) if row['mouse'] == mouse else row['normalized_epoch_duration'],\n",
    "        axis=1\n",
    "    )                                                                                                                                                                                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the velocity change depending on the inserted torque and distance in the sessiuon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(16, 16))\n",
    "\n",
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_velocity.pdf')) as pdf:\n",
    "    for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "        loop_df = sum_df.loc[sum_df.mouse == mouse].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'speed_average':'mean'}).reset_index()\n",
    "        control_speed = np.mean(sum_df.loc[(sum_df.mouse == mouse)&(sum_df.experiment == 'control')].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'speed_average':'mean'})['speed_average'])\n",
    "        # Define the range for distance and torque\n",
    "        distance = loop_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = loop_df['torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = loop_df['speed_average'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # # Plot the scatter plot\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='viridis', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), loop_df['speed_average'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter = control_speed # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "\n",
    "        heatmap = ax.contourf(X, Y, Z, levels=100, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap, ax=ax)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "\n",
    "        ax.set_xlabel(\"Distance (cm)\")\n",
    "        ax.set_ylabel(\"Torque (a.u.)\")\n",
    "        ax.set_title(mouse)\n",
    "        cbar.set_label(\"Velocity (cm/s)\")\n",
    "        \n",
    "        # Show the plot\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    pdf.savefig(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_velocity_all.pdf')) as pdf:        \n",
    "        test_df = sum_df.groupby(['mouse', 'session_n']).agg({'epoch_duration':'mean', 'length':'mean', 'torque_friction':'mean', 'speed_average':'mean'}).reset_index()\n",
    "        control_speed = np.mean(sum_df.loc[(sum_df.experiment == 'control')].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'speed_average':'mean'})['speed_average'])\n",
    "        \n",
    "        # Define the range for distance and torque\n",
    "        distance = test_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = test_df['torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = test_df['speed_average'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # Plot the scatter plot\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(6, 5))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='coolwarm', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "        # axes[0].set_xlabel(\"Distance (meters)\")\n",
    "        # axes[0].set_ylabel(\"Torque (Nm)\")\n",
    "        # axes[0].set_title(\"Heatmap of Duration by Distance and Torque\")\n",
    "        # cbar.set_label(\"Duration (seconds)\")\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), test_df['speed_average'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter = control_speed  # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "        heatmap = axes.contourf(X, Y, Z, levels=50, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        # selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "        selected_ticks = np.arange(np.around(levels[0], 1), 3.05, 0.4)\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "        \n",
    "        plt.xlabel(\"Distance (cm)\")\n",
    "        plt.ylabel(\"Torque (a.u.)\")\n",
    "        cbar.set_label(\"Velocity (cm/s)\")\n",
    "        \n",
    "        sns.despine()\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        pdf.savefig(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the time it takes to travel change depending on the torque and the distance manipuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(16, 16))\n",
    "\n",
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_time.pdf')) as pdf:\n",
    "    for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "        loop_df = sum_df.loc[sum_df.mouse == mouse].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'normalized_epoch_duration':'mean'}).reset_index()\n",
    "        \n",
    "        # Define the range for distance and torque\n",
    "        distance = loop_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = loop_df['torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = loop_df['normalized_epoch_duration'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # # Plot the scatter plot\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='viridis', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), loop_df['normalized_epoch_duration'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter = 1  # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "\n",
    "        heatmap = ax.contourf(X, Y, Z, levels=100, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap, ax=ax)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "\n",
    "        ax.set_xlabel(\"Distance (cm)\")\n",
    "        ax.set_ylabel(\"Torque (a.u.)\")\n",
    "        ax.set_title(mouse)\n",
    "        cbar.set_label(\"Duration (seconds)\")\n",
    "        \n",
    "        # Show the plot\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    pdf.savefig(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_time_all.pdf')) as pdf:        \n",
    "        test_df = sum_df.groupby(['mouse', 'session_n']).agg({'epoch_duration':'mean', 'length':'mean', 'torque_friction':'mean', 'normalized_epoch_duration':'median'}).reset_index()\n",
    "        \n",
    "        # Define the range for distance and torque\n",
    "        distance = test_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = test_df['torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = test_df['normalized_epoch_duration'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # Plot the scatter plot\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(6, 5))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='coolwarm', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "        # axes[0].set_xlabel(\"Distance (meters)\")\n",
    "        # axes[0].set_ylabel(\"Torque (Nm)\")\n",
    "        # axes[0].set_title(\"Heatmap of Duration by Distance and Torque\")\n",
    "        # cbar.set_label(\"Duration (seconds)\")\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), test_df['normalized_epoch_duration'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter = 1  # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "        heatmap = axes.contourf(X, Y, Z, levels=50, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "        # selected_ticks = np.arange(np.around(levels[0], 1), 3.05, 0.4)\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "        \n",
    "        plt.xlabel(\"Distance (cm)\")\n",
    "        plt.ylabel(\"Torque (a.u.)\")\n",
    "        cbar.set_label(\"Duration (seconds)\")\n",
    "        \n",
    "        sns.despine()\n",
    "        plt.tight_layout()\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        pdf.savefig(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the preward when leaving change depending on the torque and the distance manipuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(16, 16))\n",
    "\n",
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_preward.pdf')) as pdf:\n",
    "    for mouse, ax in zip(sum_df.mouse.unique(), axes.flatten()):\n",
    "        loop_df = sum_df.loc[sum_df.mouse == mouse].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'reward_probability':'mean'}).reset_index()\n",
    "        control_preward = np.mean(sum_df.loc[(sum_df.mouse == mouse)&(sum_df.experiment == 'control')].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'reward_probability':'mean'})['reward_probability'])\n",
    "        # Define the range for distance and torque\n",
    "        distance = loop_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = loop_df['torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = loop_df['reward_probability'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # # Plot the scatter plot\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='viridis', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), loop_df['reward_probability'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter =  control_preward # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "\n",
    "        heatmap = ax.contourf(X, Y, Z, levels=100, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap, ax=ax)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "\n",
    "        ax.set_xlabel(\"Distance (cm)\")\n",
    "        ax.set_ylabel(\"Torque (a.u.)\")\n",
    "        ax.set_title(mouse)\n",
    "        cbar.set_label(\"P(reward)\")\n",
    "        \n",
    "        # Show the plot\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    pdf.savefig(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(os.path.join(results_path, 'batch4_heatmap_distance_torque_preward_all.pdf')) as pdf:        \n",
    "        test_df = sum_df.groupby(['mouse', 'session_n']).agg({'epoch_duration':'mean', 'length':'mean', 'torque_friction':'mean', 'reward_probability':'median'}).reset_index()\n",
    "        control_speed = np.mean(sum_df.loc[(sum_df.experiment == 'control')].groupby('session_n').agg({'length':'mean', 'torque_friction':'mean', 'reward_probability':'median'})['reward_probability'])\n",
    "        # Define the range for distance and torque\n",
    "        distance = test_df['length'].values  # Distance values from the 'length' column\n",
    "        torque = test_df['torque_friction'].values  # Torque values from the 'torque_friction' column\n",
    "        duration = test_df['reward_probability'].values  # Duration values from the 'epoch_duration' column\n",
    "\n",
    "        # Plot the scatter plot\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(6, 5))\n",
    "        # scatter = sns.scatterplot(x=distance, y=torque, hue=duration, palette='coolwarm', s=100, edgecolor='w', alpha=0.7, ax=axes[0])\n",
    "        # # cbar = plt.colorbar(scatter.collections[0])\n",
    "\n",
    "        # # Add labels and title\n",
    "        # axes[0].set_xlabel(\"Distance (meters)\")\n",
    "        # axes[0].set_ylabel(\"Torque (Nm)\")\n",
    "        # axes[0].set_title(\"Heatmap of Duration by Distance and Torque\")\n",
    "        # cbar.set_label(\"Duration (seconds)\")\n",
    "\n",
    "        # Create a grid of X (distance) and Y (torque)\n",
    "        X, Y = np.meshgrid(np.linspace(distance.min(), distance.max(), 50), np.linspace(torque.min(), torque.max(), 50))\n",
    "\n",
    "        # Interpolate Z as a function of distance and torque using epoch_duration\n",
    "        # Z = loop_df['epoch_duration'].values\n",
    "        Z = griddata((distance, torque), test_df['reward_probability'].values, (X, Y), method='linear')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        vmin = np.nanmin(Z)\n",
    "        vmax = np.nanmax(Z)\n",
    "        vcenter = control_speed  # You can change this value as needed\n",
    "\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "        heatmap = axes.contourf(X, Y, Z, levels=50, cmap='coolwarm', norm=norm)  # Adjust 'coolwarm' as needed\n",
    "        cbar = plt.colorbar(heatmap)\n",
    "        \n",
    "        # Get available levels from the heatmap\n",
    "        levels = heatmap.levels\n",
    "\n",
    "        # Select specific levels: first, center, and last\n",
    "        selected_ticks = [levels[0], levels[len(levels) // 2], levels[-1]]\n",
    "        # selected_ticks = np.arange(np.around(levels[0], 1), 3.05, 0.4)\n",
    "        # Set the colorbar ticks to the selected values\n",
    "        cbar.set_ticks(selected_ticks)\n",
    "        cbar.set_ticklabels([f\"{tick:.2f}\" for tick in selected_ticks])\n",
    "        \n",
    "        plt.xlabel(\"Distance (cm)\")\n",
    "        plt.ylabel(\"Torque (a.u.)\")\n",
    "        cbar.set_label(\"P(reward)\")\n",
    "        \n",
    "        sns.despine()\n",
    "        plt.tight_layout()\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logitic models: what predicts the moment your will leave?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"torque_friction\", \"length\", \"epoch_duration\"]\n",
    "test_df = merge_df.copy()\n",
    "# Initialize dataframes to store weights and cross-validation results\n",
    "weights_df = pd.DataFrame(columns=['regressors', 'weights', 'mouse', 'session'])\n",
    "cv_results_df = pd.DataFrame(columns=['mouse', 'cv_score'])\n",
    "\n",
    "for (mouse, session), mouse_df in merged_df.groupby(['mouse', 'session']):\n",
    "    print(f\"Mouse: {mouse}, Session: {session}\")\n",
    "    \n",
    "    # Select features and target variable\n",
    "    X_mouse = mouse_df[features]\n",
    "    y_mouse = mouse_df['reward_probabilities'].astype(int)\n",
    "    \n",
    "    # Define the pipeline\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    scaler = StandardScaler()\n",
    "    log_reg = LogisticRegression(C=1, max_iter=1000)\n",
    "    \n",
    "    pipeline = make_pipeline(poly, scaler, log_reg)\n",
    "    \n",
    "    # Perform 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, X_mouse, y_mouse, cv=5)\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_mouse, y_mouse)\n",
    "    \n",
    "    # Extract the feature names after applying PolynomialFeatures\n",
    "    poly_features = poly.fit(X_mouse).get_feature_names_out(features)\n",
    "    \n",
    "    # Get the weights for each feature\n",
    "    log_reg_model = pipeline.named_steps['logisticregression']\n",
    "    feature_weights = pd.Series(log_reg_model.coef_[0], index=poly_features)\n",
    "    feature_weights = feature_weights.reset_index()\n",
    "    feature_weights.rename(columns={'index': 'regressors', 0: 'weights'}, inplace=True)\n",
    "    feature_weights['mouse'] = mouse\n",
    "    feature_weights['session'] = session\n",
    "\n",
    "    # Append the weights and cv scores to the respective dataframes\n",
    "    weights_df = pd.concat([weights_df, feature_weights], ignore_index=True)\n",
    "    cv_results_df = pd.concat([cv_results_df, pd.DataFrame({'session': [session], 'mouse': [mouse], 'cv_score': [cv_scores.mean()]})], ignore_index=True)\n",
    "\n",
    "    # Print the cross-validation scores and their mean\n",
    "    print(f\"Mean cross-validation score: {cv_scores.mean():.2f}\")\n",
    "    print('\\n')\n",
    "\n",
    "weights_df['mouse'] = weights_df['mouse'].round(0).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame\n",
    "y = merge_df['reward_probability']\n",
    "features = [\"torque_friction\", \"length\", \"epoch_duration\"]\n",
    "design_matrix = merge_df.copy()\n",
    "\n",
    "# Standardize predictors\n",
    "scaler = StandardScaler()\n",
    "design_matrix[features] = scaler.fit_transform(design_matrix[features])\n",
    "# Fit the logistic regression model with standardized predictors\n",
    "formula = \"reward_probability ~ torque_friction * length + epoch_duration\"\n",
    "model = glm(formula=formula, data=design_matrix, family=Binomial(link=logit())).fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Predicted values\n",
    "design_matrix[\"predicted_p_reward\"] = model.predict(design_matrix)\n",
    "\n",
    "# Evaluate predictions\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(design_matrix[[\"reward_probability\", \"predicted_p_reward\"]].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
