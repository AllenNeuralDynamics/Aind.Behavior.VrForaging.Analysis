{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "from aind_vr_foraging_analysis.utils.plotting import plotting_friction_experiment as f\n",
    "from aind_vr_foraging_analysis.utils.parsing import  parse, AddExtraColumns\n",
    "import aind_vr_foraging_analysis.utils.plotting as plotting\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # Ignore SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "pdf_path = r'Z:\\scratch\\vr-foraging\\sessions'\n",
    "base_path = r'Z:/scratch/vr-foraging/data/'\n",
    "results_path = r'C:\\Users\\tiffany.ona\\OneDrive - Allen Institute\\Documents\\VR foraging\\experiments\\batch 4 - manipulating cost of travelling and global statistics\\results'\n",
    "data_path = r'../../../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parse velocity, time and speed for different sessions and animals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.date.today()\n",
    "date_string = \"08/28/2024\"\n",
    "date = datetime.datetime.strptime(date_string, \"%m/%d/%Y\").date()\n",
    "params_df = pd.read_csv(data_path + 'torque_calibration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.DataFrame()\n",
    "# list_experiments = ['control', 'friction', 'friction_15', 'friction_optimized', 'distance_short', 'distance_long', 'distance_extra_short', 'distance_extra_long']\n",
    "for mouse in ['754570','754579','754567','754580','754559','754560','754577','754566','754570','754571','754574','754575', '754582','745302','745305','745301']:\n",
    "    print(mouse)\n",
    "    session_n = 0\n",
    "    active_site_list = []\n",
    "    velocity_list = []\n",
    "    velocity_list_end = []\n",
    "    torque_list = []\n",
    "    within_session_number = 0\n",
    "    control_experiment = 0\n",
    "    previous_experiment = None\n",
    "\n",
    "    directory = os.path.join(base_path, mouse)\n",
    "    files = os.listdir(os.path.join(base_path, mouse))\n",
    "\n",
    "    sorted_files = sorted(files, key=lambda x: os.path.getctime(os.path.join(directory, x)), reverse=False)\n",
    "\n",
    "    # All this segment is to find the correct session without having the specific path\n",
    "    for file_name in sorted_files:\n",
    "        start_time = time.time()\n",
    "        # Find specific session sorted by date\n",
    "        session = file_name[-15:-7]\n",
    "        if datetime.datetime.strptime(session, \"%Y%m%d\").date() < date:\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        # Recover data streams\n",
    "        session_path = os.path.join(base_path, mouse, file_name)\n",
    "        session_path = Path(session_path)\n",
    "        try:\n",
    "            data = parse.load_session_data(session_path)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        experiment = data['config'].streams.tasklogic_input.data['stage_name']\n",
    "        \n",
    "        try:\n",
    "            friction = data['config'].streams.tasklogic_input.data['task_parameters']['environment_statistics']['patches'][0]['virtual_site_generation']['post_patch']['treadmill_specification']['friction']['distribution_parameters']['value']\n",
    "        except TypeError:\n",
    "            friction = 0\n",
    "        rig_name = data['config'].streams.rig_input.data['rig_name']\n",
    "\n",
    "        # What was the friction applied if we have the friction of the schema? (We have the friction in the schema, we want the reality)\n",
    "        wheel = rig_name\n",
    "        resolved_torque = f.quadratic_model(65535 * friction, params_df.loc[params_df.wheel == wheel].a.values[0], params_df.loc[params_df.wheel == wheel].b.values[0], params_df.loc[params_df.wheel == wheel].c.values[0])    \n",
    "        torque_friction = params_df.loc[params_df.wheel == wheel].c.values[0] - resolved_torque\n",
    "    \n",
    "        if experiment == 'friction' or experiment == 'friction_15' or experiment == 'friction_optimized':\n",
    "            if torque_friction < 120:\n",
    "                experiment = 'friction_low'\n",
    "            elif torque_friction > 120 and torque_friction < 240:\n",
    "                experiment = 'friction_med'\n",
    "            else:\n",
    "                experiment = 'friction_high'\n",
    "        print(experiment, torque_friction)\n",
    "        \n",
    "        # Parse data into a dataframe with the main features\n",
    "        try:\n",
    "            all_epochs = parse.parse_dataframe(data)\n",
    "        except:\n",
    "            continue\n",
    "        # -- At this step you can save the data into a csv file\n",
    "        \n",
    "        if reward_sites.empty:\n",
    "            continue\n",
    "        \n",
    "        # Expand with extra columns\n",
    "        active_site = AddExtraColumns(all_epochs).get_all_epochs\n",
    "\n",
    "        # Load the encoder data separately\n",
    "        stream_data = parse.ContinuousData(data)\n",
    "        encoder_data = stream_data.encoder_data\n",
    "        \n",
    "        if active_site.loc[active_site.label == 'InterPatch'].length.unique()[0] == 50:\n",
    "            section = 'PostPatch'\n",
    "        else:\n",
    "            section = 'InterPatch'\n",
    "\n",
    "        if section == 'PostPatch':\n",
    "            active_site['patch_number'] = active_site['patch_number'].shift(-1)\n",
    "\n",
    "        active_site['end_epoch'] = active_site.index.to_series().shift(-1)\n",
    "        active_site['epoch_duration'] = active_site['end_epoch'] - active_site.index\n",
    "\n",
    "        new_active_site = active_site[active_site['label'] == section]\n",
    "        new_active_site['experiment'] = experiment\n",
    "        new_active_site['torque_friction'] = torque_friction\n",
    "        new_active_site['friction'] = friction\n",
    "        new_active_site['mouse'] = mouse\n",
    "        new_active_site['session'] = session\n",
    "        new_active_site['wheel'] = wheel\n",
    "        \n",
    "        # cum_active_site = pd.concat([cum_active_site, new_active_site])\n",
    "        active_site_list.append(new_active_site)\n",
    "        \n",
    "        velocity = plotting.trial_collection(new_active_site, \n",
    "                                                        encoder_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-1,2],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col='filtered_velocity')\n",
    "        \n",
    "        if velocity.empty:\n",
    "            continue\n",
    "        \n",
    "        velocity_list.append(velocity)\n",
    "\n",
    "        torque_data = stream_data.torque_data\n",
    "        brake_data = stream_data.brake_data\n",
    "        \n",
    "        torque = plotting.trial_collection(new_active_site, \n",
    "                                                        torque_data, \n",
    "                                                        mouse, \n",
    "                                                        session, \n",
    "                                                        window=[-2,10],  \n",
    "                                                        cropped_to_length='epoch',\n",
    "                                                        taken_col=['Torque'])\n",
    "\n",
    "        \n",
    "        torque_list.append(torque)\n",
    "\n",
    "    cum_active_site = pd.concat(active_site_list)\n",
    "    cum_velocity = pd.concat(velocity_list)\n",
    "    cum_torque = pd.concat(torque_list)\n",
    "        \n",
    "    group_list = ['mouse','session', 'experiment', 'friction', 'torque_friction', 'patch_number', 'wheel']\n",
    "    acc_df = pd.DataFrame()\n",
    "    \n",
    "    temp_df = cum_torque.loc[(cum_torque['times']> 0)].groupby(group_list).Torque.mean().reset_index()\n",
    "    temp_df.rename(columns={'Torque':'torque_interpatch'}, inplace=True)\n",
    "    acc_df = temp_df\n",
    "    \n",
    "    temp_df = cum_torque.loc[(cum_torque['times']< 0)&(cum_torque['times'] > -2)].groupby(group_list).Torque.mean().reset_index()\n",
    "    temp_df.rename(columns={'Torque':'torque_baseline'}, inplace=True)\n",
    "    acc_df = acc_df.merge(temp_df, on=group_list)\n",
    "\n",
    "    temp_df = cum_velocity.loc[(cum_velocity['times'] > 0)].groupby(group_list).speed.mean().reset_index()\n",
    "    temp_df.rename(columns={'speed':'speed_average'}, inplace=True)\n",
    "    acc_df = acc_df.merge(temp_df, on=group_list)\n",
    "\n",
    "    temp_df = cum_active_site.groupby(group_list).agg({\"epoch_duration\":\"mean\", \"length\":\"mean\"}).reset_index()\n",
    "    acc_df = acc_df.merge(temp_df, on=group_list)\n",
    "\n",
    "    sum_df = pd.concat([acc_df, sum_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = sum_df.sort_values(by=['mouse', 'session']).reset_index(drop=True)\n",
    "sum_df['session_n'] = sum_df.groupby('mouse')['session'].rank(method='dense').astype(int)\n",
    "sum_df.to_csv(os.path.join(results_path, 'batch4_velocity_torque_duration_summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
